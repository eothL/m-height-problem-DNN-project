{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objectif of this project is to use Deep Learning techniques to resolve m-height Problem faster than traditional LP-based algorithm with the minimal error possible.  \n",
    "To tackle this problem, the first part is to generate data to train our model using LP-based algorithm.\n",
    "Then we are going to train different model to which architecture fit the best the problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/user/theo.lin/torch-env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cu118\n",
      "CUDA available: True\n",
      "Num GPUs: 1\n",
      "GPU name: NVIDIA A100-PCIE-40GB\n",
      "Default device: cuda\n",
      "CPU cores available: 64\n"
     ]
    }
   ],
   "source": [
    "# --- Libraries ---\n",
    "# Standard libraries\n",
    "import os\n",
    "import time\n",
    "import uuid\n",
    "import itertools\n",
    "import traceback\n",
    "import glob\n",
    "import multiprocessing\n",
    "import sys\n",
    "import math\n",
    "import copy\n",
    "\n",
    "\n",
    "# Data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "# import pulp not useful anymore as we already generated all the data\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset, random_split\n",
    "from torchvision import transforms\n",
    "import optuna \n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Utility checks\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Num GPUs:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0))\n",
    "print(\"Default device:\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "# Example: Parallel multiprocessing\n",
    "print(\"CPU cores available:\", multiprocessing.cpu_count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below this line are the code of the PROJET 3: we keeping only the cell that we are interested in like the class \"PickleDataLoader\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the plan for this project: \n",
    "\n",
    "- Try to change the regression problem into a classification problem\n",
    "- Try MoE with hard gate and medium gate\n",
    "- Train 21 different model for each (n,k,m) or 6 model for each (n,k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------      \n",
    "Below this line are the code of the PROJECT 2: we are keeping only the cell that we are interested in like the class \"PickleDataLoader\", \"FlexibleDenseNetworkWithParams\",\"MoE_FCN_SoftGate\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the plan for this project:  \n",
    "- Increase the number of data used by 2 to see its influence on the cost\n",
    "- Try deeper FCN with Residual connection\n",
    "- Try Transformers\n",
    "- Try batch normalization\n",
    "- try ResNet architecture to see its performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define the class \"PickleFolderDataset\" to load the data from pkl files ---\n",
    "\n",
    "# --- Normalisation function ---\n",
    "EPS = 1e-9\n",
    "def norm_none(t):\n",
    "    return t                                      # raw P\n",
    "\n",
    "def norm_row_standard(t):\n",
    "    mu  = t.mean(dim=1, keepdim=True)\n",
    "    std = t.std (dim=1, keepdim=True) + EPS\n",
    "    return (t - mu) / std                         # each row N(0,1)\n",
    "\n",
    "def norm_col_minmax(t, to=(-1., 1.)):\n",
    "    lo, hi = to\n",
    "    col_min = t.min(dim=0, keepdim=True).values\n",
    "    col_max = t.max(dim=0, keepdim=True).values\n",
    "    rng = (col_max - col_min).clamp_min(EPS)\n",
    "    return (t - col_min) / rng * (hi - lo) + lo   # columns -> [-1,1]\n",
    "\n",
    "NORMALISERS = {\n",
    "    \"none\":           norm_none,\n",
    "    \"row_standard\":   norm_row_standard,\n",
    "    \"col_minmax\":     norm_col_minmax,\n",
    "}\n",
    "\n",
    "# --- Data Loader class from Pickle files ---\n",
    "class PickleFolderDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for loading data from a **list of .pkl file paths**.\n",
    "\n",
    "    Assumes each .pkl file contains a Pandas DataFrame with columns\n",
    "    'n', 'k', 'm', 'result', 'P'.\n",
    "    Handles cases where 'P' might be a 2D array OR a flattened 1D array.\n",
    "    Reshapes 1D 'P' arrays to 2D using 'n' and 'k' before padding.\n",
    "    Handles padding P_matrices. \n",
    "    Returns data as (params, h, P).\n",
    "    \"\"\"\n",
    "    def __init__(self, file_paths: list, max_k :int = 6, max_nk:int = 6, transform:callable=None, p_normaliser:str = \"none\", return_col_indices=False): \n",
    "        \"\"\"\n",
    "        Args:\n",
    "            file_paths (list[str]): A list of full paths to the .pkl files.\n",
    "            max_k (int): The height to pad P matrices to.\n",
    "            max_nk (int): The width to pad P matrices to.\n",
    "            p_normaliser (str): key in NORMALISERS (str) – 'none', 'row_standard', 'col_minmax', ...\n",
    "            return_col_indices (bool): if True -> __getitem__ returns an extra tensor [n‑k] with 0…n‑k‑1\n",
    "            transform (callable): additional callable applied AFTER padding & normalisation\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        if p_normaliser not in NORMALISERS:\n",
    "            raise ValueError(f\"Invalid p_normaliser: {p_normaliser}. Must be one of: {list(NORMALISERS.keys())}\")\n",
    "        \n",
    "        self._normalise = NORMALISERS[p_normaliser]\n",
    "        self.return_col_indices = return_col_indices\n",
    "        self.max_k,self.max_nk = max_k,max_nk\n",
    "        self.transform = transform\n",
    "\n",
    "        if not file_paths:\n",
    "            raise ValueError(\"The provided file_paths list is empty.\")\n",
    "\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        # LOAD DATA  \n",
    "        # ------------------------------------------------------------------        \n",
    "        # Store data directly as loaded from pickle (P can be 1D or 2D)\n",
    "        self.P_raw, self.h_vals, self.n_vals, self.k_vals, self.m_vals = \\\n",
    "            [], [], [], [], []\n",
    "\n",
    "        print(f\"Loading data from {len(file_paths)} specified pickle files (expecting DataFrames)...\")\n",
    "        required = ['n', 'k', 'm', 'result', 'P']\n",
    "\n",
    "        for fp in file_paths: # Iterate through the provided list\n",
    "            # print(f\"  Loading: {os.path.basename(file_path)}\") # Keep print concise\n",
    "            try:\n",
    "                with open(fp, \"rb\") as f:\n",
    "                    df = pickle.load(f)\n",
    "                if not all(col in df.columns for col in required):\n",
    "                    continue\n",
    "\n",
    "                self.P_raw.extend([np.array(p) for p in df['P']])\n",
    "                self.h_vals.extend(df['result'].astype(float).tolist())\n",
    "                self.n_vals.extend(df['n'].astype(int).tolist())\n",
    "                self.k_vals.extend(df['k'].astype(int).tolist())\n",
    "                self.m_vals.extend(df['m'].astype(int).tolist())\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                    print(f\"Error: File not found {fp}. Skipping.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading/processing {fp}: {type(e).__name__} - {e}. Skipping file.\")\n",
    "                # print(traceback.format_exc()) # Uncomment for more detail\n",
    "\n",
    "        if not self.h_vals:\n",
    "                raise ValueError(\"No valid data loaded from any pickle files.\")\n",
    "\n",
    "        if not self.h_vals:\n",
    "                raise ValueError(\"No valid data loaded from any pickle files.\")\n",
    "\n",
    "        print(f\"Finished initial loading. Total samples found: {len(self.h_vals)}\")\n",
    "\n",
    "        # --- Convert non-P lists to tensors ---\n",
    "        self.h_vals  = torch.tensor(self.h_vals , dtype=torch.float32)\n",
    "        self.n_vals  = torch.tensor(self.n_vals , dtype=torch.float32)\n",
    "        self.k_vals  = torch.tensor(self.k_vals , dtype=torch.float32)\n",
    "        self.m_vals  = torch.tensor(self.m_vals , dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.h_vals)\n",
    "\n",
    "    def _pad(self, p2d: torch.Tensor):\n",
    "        k_act, nk_act = p2d.shape\n",
    "        pad = (0, self.max_nk - nk_act, 0, self.max_k - k_act)  # (W_left,W_right,H_top,H_bottom)\n",
    "        return F.pad(p2d, pad, value=0.)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # --- reshape / pad ---\n",
    "        p_np   = self.P_raw[idx]\n",
    "        n, k   = int(self.n_vals[idx]), int(self.k_vals[idx])\n",
    "        target = (k, n - k)\n",
    "        if p_np.ndim == 1:\n",
    "            p_np = p_np.reshape(*target)  # raises if shape mismatched\n",
    "        p_t = torch.tensor(p_np, dtype=torch.float32)\n",
    "        p_t = self._pad(p_t)\n",
    "\n",
    "        # --- normalise ---\n",
    "        p_t = self._normalise(p_t)\n",
    "\n",
    "        # --- extra transform hook ---\n",
    "        if self.transform:\n",
    "            p_t = self.transform(p_t)\n",
    "\n",
    "        # --- build output ---\n",
    "        params  = torch.tensor([self.n_vals[idx], self.k_vals[idx], self.m_vals[idx]],\n",
    "                               dtype=torch.float32)\n",
    "        h       = self.h_vals[idx].unsqueeze(0)\n",
    "\n",
    "        if self.return_col_indices:\n",
    "            col_idx = torch.arange(target[1], dtype=torch.long)      # 0 … n‑k‑1\n",
    "            if target[1] < self.max_nk:\n",
    "                 col_idx = F.pad(col_idx, (0, self.max_nk - target[1]), value = 0)\n",
    "            return params, h, p_t, col_idx\n",
    "\n",
    "        return params, h, p_t\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "--- Preparing Data ---\n",
      "Found 42 total .pkl files.\n",
      "Loading data from 42 specified pickle files (expecting DataFrames)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n",
      "/tmp/job.2218891/ipykernel_2930863/3832338467.py:75: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  df = pickle.load(f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished initial loading. Total samples found: 840000\n",
      "Total samples loaded from combined files: 840000\n",
      "Splitting data: Training=672000 (80.0%), Validation=168000 (20.0%)\n",
      "\n",
      "Final DataLoaders created successfully.\n",
      "Training batches: 1313, Validation batches: 329\n"
     ]
    }
   ],
   "source": [
    "# --- Data Loading and Preparation ---\n",
    "# --- Configuration ---\n",
    "TRAIN_DATA_FOLDERS = ['./split_data_train_20000_random']\n",
    "VALIDATION_DATA_FOLDERS = ['./split_data_validation_20000_random']\n",
    "max_k = 6\n",
    "max_nk = 6\n",
    "batch_size = 512 \n",
    "val_split_ratio = 0.2 # 80/20 split\n",
    "NUM_WORKERS = 0 # Safer default for Windows\n",
    "PIN_MEMORY = True # Generally good if using GPU\n",
    "\n",
    "# --- Variables to store loaders (so they are accessible by the next cell) ---\n",
    "train_loader = None\n",
    "val_loader = None\n",
    "\n",
    "# --- Device Setup ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- Load and Split Data ---\n",
    "try:\n",
    "    print(\"--- Preparing Data ---\")\n",
    "    all_files = []\n",
    "    for folder in TRAIN_DATA_FOLDERS + VALIDATION_DATA_FOLDERS:\n",
    "         files = glob.glob(os.path.join(folder, '*.pkl'))\n",
    "         if not files:\n",
    "              print(f\"Warning: No .pkl files found in folder: {folder}\")\n",
    "         all_files.extend(files)\n",
    "\n",
    "    if not all_files:\n",
    "        raise FileNotFoundError(\"No .pkl files found in any specified train/validation folders.\")\n",
    "\n",
    "    print(f\"Found {len(all_files)} total .pkl files.\")\n",
    "\n",
    "    # Instantiate the dataset with the combined list of files\n",
    "    combined_dataset = PickleFolderDataset(\n",
    "        file_paths=all_files,\n",
    "        max_k=max_k,\n",
    "        max_nk=max_nk,\n",
    "    )\n",
    "\n",
    "    total_samples = len(combined_dataset)\n",
    "    print(f\"Total samples loaded from combined files: {total_samples}\")\n",
    "\n",
    "    # Perform random split\n",
    "    val_size = int(total_samples * val_split_ratio)\n",
    "    train_size = total_samples - val_size\n",
    "\n",
    "    if train_size <= 0 or val_size <= 0:\n",
    "         raise ValueError(f\"Calculated train ({train_size}) or validation ({val_size}) size is zero or less.\")\n",
    "\n",
    "    print(f\"Splitting data: Training={train_size} ({100*(1-val_split_ratio):.1f}%), Validation={val_size} ({100*val_split_ratio:.1f}%)\")\n",
    "    train_dataset, val_dataset = random_split(combined_dataset, [train_size, val_size])\n",
    "\n",
    "    # Create DataLoaders and store them in global scope for this cell block\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=PIN_MEMORY\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=PIN_MEMORY\n",
    "    )\n",
    "    print(\"\\nFinal DataLoaders created successfully.\")\n",
    "    print(f\"Training batches: {len(train_loader)}, Validation batches: {len(val_loader)}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\nData Loading Error: {e}\")\n",
    "    print(\"Please ensure the TRAIN_DATA_FOLDERS and VALIDATION_DATA_FOLDERS paths are correct.\")\n",
    "except ValueError as e:\n",
    "     print(f\"\\nData Loading/Splitting Error: {e}\")\n",
    "     print(\"Check data contents, split ratio, or if the dataset ended up empty.\")\n",
    "except NameError as e:\n",
    "     print(f\"\\nDefinition Error: {e}. Make sure 'PickleFolderDatasetWithParams' class is defined and executed first.\")\n",
    "except ImportError as e:\n",
    "     print(f\"\\nImport Error: {e}. Make sure required libraries (torch, pickle, pandas etc.) are imported.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn unexpected error occurred during data loading/splitting: {type(e).__name__} - {e}\")\n",
    "    print(\"Traceback:\")\n",
    "    print(traceback.format_exc())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "--- Preparing Data ---\n",
      "Found 42 total .pkl files.\n",
      "Loading data from 42 specified pickle files (expecting DataFrames)...\n",
      "Finished initial loading. Total samples found: 840000\n",
      "Total samples loaded from combined files: 840000\n",
      "Splitting data: Training=672000 (80.0%), Validation=168000 (20.0%)\n",
      "\n",
      "Final DataLoaders created successfully.\n",
      "Training batches: 1313, Validation batches: 329\n"
     ]
    }
   ],
   "source": [
    "# --- Data Loading and Preparation Embedded data---\n",
    "# --- Configuration ---\n",
    "TRAIN_DATA_FOLDERS = ['./split_data_train_20000_random']\n",
    "VALIDATION_DATA_FOLDERS = ['./split_data_validation_20000_random']\n",
    "max_k = 6\n",
    "max_nk = 6\n",
    "batch_size = 512 \n",
    "val_split_ratio = 0.2 # 80/20 split\n",
    "NUM_WORKERS = 0 # Safer default for Windows\n",
    "PIN_MEMORY = True # Generally good if using GPU\n",
    "\n",
    "# --- Variables to store loaders (so they are accessible by the next cell) ---\n",
    "train_loader_embed = None\n",
    "val_loader_embed = None\n",
    "\n",
    "# --- Device Setup ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- Load and Split Data ---\n",
    "try:\n",
    "    print(\"--- Preparing Data ---\")\n",
    "    all_files = []\n",
    "    for folder in TRAIN_DATA_FOLDERS + VALIDATION_DATA_FOLDERS:\n",
    "         files = glob.glob(os.path.join(folder, '*.pkl'))\n",
    "         if not files:\n",
    "              print(f\"Warning: No .pkl files found in folder: {folder}\")\n",
    "         all_files.extend(files)\n",
    "\n",
    "    if not all_files:\n",
    "        raise FileNotFoundError(\"No .pkl files found in any specified train/validation folders.\")\n",
    "\n",
    "    print(f\"Found {len(all_files)} total .pkl files.\")\n",
    "\n",
    "    # Instantiate the dataset with the combined list of files\n",
    "    combined_dataset_embed = PickleFolderDataset(\n",
    "        file_paths=all_files,\n",
    "        max_k=max_k,\n",
    "        max_nk=max_nk,\n",
    "        p_normaliser= \"col_minmax\",\n",
    "        return_col_indices= True\n",
    "    )\n",
    "\n",
    "    total_samples = len(combined_dataset_embed)\n",
    "    print(f\"Total samples loaded from combined files: {total_samples}\")\n",
    "\n",
    "    # Perform random split\n",
    "    val_size = int(total_samples * val_split_ratio)\n",
    "    train_size = total_samples - val_size\n",
    "\n",
    "    if train_size <= 0 or val_size <= 0:\n",
    "         raise ValueError(f\"Calculated train ({train_size}) or validation ({val_size}) size is zero or less.\")\n",
    "\n",
    "    print(f\"Splitting data: Training={train_size} ({100*(1-val_split_ratio):.1f}%), Validation={val_size} ({100*val_split_ratio:.1f}%)\")\n",
    "    train_dataset_embed, val_dataset_embed = random_split(combined_dataset_embed, [train_size, val_size])\n",
    "\n",
    "    # Create DataLoaders and store them in global scope for this cell block\n",
    "    train_loader_embed = DataLoader(\n",
    "        train_dataset_embed,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=PIN_MEMORY\n",
    "    )\n",
    "    val_loader_embed = DataLoader(\n",
    "        val_dataset_embed,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=PIN_MEMORY\n",
    "    )\n",
    "    print(\"\\nFinal DataLoaders created successfully.\")\n",
    "    print(f\"Training batches: {len(train_loader_embed)}, Validation batches: {len(val_loader_embed)}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\nData Loading Error: {e}\")\n",
    "    print(\"Please ensure the TRAIN_DATA_FOLDERS and VALIDATION_DATA_FOLDERS paths are correct.\")\n",
    "except ValueError as e:\n",
    "     print(f\"\\nData Loading/Splitting Error: {e}\")\n",
    "     print(\"Check data contents, split ratio, or if the dataset ended up empty.\")\n",
    "except NameError as e:\n",
    "     print(f\"\\nDefinition Error: {e}. Make sure 'PickleFolderDatasetWithParams' class is defined and executed first.\")\n",
    "except ImportError as e:\n",
    "     print(f\"\\nImport Error: {e}. Make sure required libraries (torch, pickle, pandas etc.) are imported.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn unexpected error occurred during data loading/splitting: {type(e).__name__} - {e}\")\n",
    "    print(\"Traceback:\")\n",
    "    print(traceback.format_exc())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define functions for training and testing the model and data pre processing, plotting---\n",
    "\n",
    "# --- Define the custom MSE loss function on the log2 scale --- \n",
    "class LogMSELoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Calculates the Mean Squared Error on the log2 scale.\n",
    "    Loss = mean( (log2(y_true) - log2(y_pred))^2 )\n",
    "    Adds a small epsilon to prevent log2(0).\n",
    "    \"\"\"\n",
    "    def __init__(self, eps=1e-9):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            y_pred (torch.Tensor): Predictions from the model.\n",
    "            y_true (torch.Tensor): Ground truth values.\n",
    "        \"\"\"\n",
    "        # Clamp inputs to be positive to avoid log2(<=0)\n",
    "        y_pred_safe = torch.clamp(y_pred, min=self.eps)\n",
    "        y_true_safe = torch.clamp(y_true, min=self.eps) # Clamp true values too for safety\n",
    "\n",
    "        # Calculate log base 2\n",
    "        log2_pred = torch.log2(y_pred_safe)\n",
    "        log2_true = torch.log2(y_true_safe)\n",
    "\n",
    "        # Calculate the squared difference and mean over the batch\n",
    "        loss = torch.mean((log2_true - log2_pred) ** 2)\n",
    "        return loss\n",
    "\n",
    "def train_epoch_with_params(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"Trains the model (accepting params, h, P) for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    # Make sure this unpacking order matches the Dataset's __getitem__ return order\n",
    "    for i, batch_data in enumerate(dataloader):\n",
    "        # Unpack data correctly based on Dataset return order (params, h, P)\n",
    "        params, targets, p_matrices = batch_data\n",
    "        params, targets, p_matrices = params.to(device), targets.to(device), p_matrices.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Pass data to the model in the order its forward method expects\n",
    "        # Assuming models expect (p_matrix, params)\n",
    "        outputs = model(p_matrices, params)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss correctly using the actual batch size\n",
    "        running_loss += loss.item() * params.size(0)\n",
    "        total_samples += params.size(0)\n",
    "\n",
    "        ## --- Batch-level print ---\n",
    "        # if (i + 1) % 100 == 0:\n",
    "        #      print(f'  Batch {i+1}/{len(dataloader)}, Loss: {loss.item():.4f}')\n",
    "\n",
    "    # Calculate average loss for the epoch\n",
    "    epoch_loss = running_loss / total_samples if total_samples > 0 else 0.0\n",
    "    return epoch_loss\n",
    "\n",
    "def train_epoch_with_params_embed(model, dataloader, criterion, optimizer, device):\n",
    "    model.train(); running_loss = 0; total = 0\n",
    "    for batch in dataloader:\n",
    "        params, targets, P, col_idx = batch           # <- 4 tensors\n",
    "        params, targets, P, col_idx = [t.to(device) for t in (params, targets, P, col_idx)]\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(P, params, col_idx)           # pass 3rd arg\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward(); optimizer.step()\n",
    "        running_loss += loss.item()*params.size(0); total += params.size(0)\n",
    "    return running_loss/total\n",
    "\n",
    "def validate_epoch_with_params_embed(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        params, targets, P, col_idx = batch\n",
    "        params, targets, P, col_idx = [t.to(device) for t in (params, targets, P, col_idx)]\n",
    "        outputs = model(P, params, col_idx)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        running_loss += loss.item() * params.size(0)\n",
    "        total_samples += params.size(0)\n",
    "\n",
    "    epoch_loss = running_loss = total_samples if total_samples > 0 else 0.0\n",
    "    return epoch_loss\n",
    "\n",
    "# --- Keep validate_epoch_with_params as is (it doesn't have batch printing) ---\n",
    "def validate_epoch_with_params(model, dataloader, criterion, device):\n",
    "    \"\"\"Evaluates the model (accepting params, h, P) on the validation set.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Make sure this unpacking order matches the Dataset's __getitem__ return order\n",
    "        for batch_data in dataloader:\n",
    "            # Unpack data correctly (params, h, P)\n",
    "            params, targets, p_matrices = batch_data\n",
    "            params, targets, p_matrices = params.to(device), targets.to(device), p_matrices.to(device)\n",
    "\n",
    "            # Pass data to the model in the order its forward method expects\n",
    "            # Assuming models expect (p_matrix, params)\n",
    "            outputs = model(p_matrices, params)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            running_loss += loss.item() * params.size(0) # Use actual batch size\n",
    "            total_samples += params.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total_samples if total_samples > 0 else 0.0\n",
    "    return epoch_loss\n",
    "\n",
    "\n",
    "\n",
    "def load_and_split_data(train_folders, val_folders, max_k, max_nk, batch_size, val_split_ratio=0.2, num_workers=0, pin_memory=True, dataset_class=PickleFolderDataset):\n",
    "    \"\"\"\n",
    "    Loads data from specified folders, combines them, performs a random split,\n",
    "    and returns training and validation DataLoaders.\n",
    "\n",
    "    Args:\n",
    "        train_folders (list[str]): List of paths to folders containing training .pkl files.\n",
    "        val_folders (list[str]): List of paths to folders containing validation .pkl files.\n",
    "                                  (Data will be combined before splitting).\n",
    "        max_k (int): Max height for padding P matrices.\n",
    "        max_nk (int): Max width for padding P matrices.\n",
    "        batch_size (int): Batch size for DataLoaders.\n",
    "        val_split_ratio (float): Proportion of the *combined* data to use for validation (e.g., 0.2 for 20%).\n",
    "        num_workers (int): Number of worker processes for DataLoader.\n",
    "        pin_memory (bool): Whether to use pin_memory for DataLoader.\n",
    "        dataset_class (Dataset): The Dataset class to use (e.g., PickleFolderDataset).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (train_loader, val_loader)\n",
    "    \"\"\"\n",
    "    print(\"--- Preparing Data ---\")\n",
    "    all_files = []\n",
    "    for folder in train_folders + val_folders: # Combine paths from both lists\n",
    "         files = glob.glob(os.path.join(folder, '*.pkl'))\n",
    "         if not files:\n",
    "              print(f\"Warning: No .pkl files found in folder: {folder}\")\n",
    "         all_files.extend(files)\n",
    "\n",
    "    if not all_files:\n",
    "        raise FileNotFoundError(\"No .pkl files found in any of the specified train/validation folders.\")\n",
    "\n",
    "    print(f\"Found {len(all_files)} total .pkl files.\")\n",
    "\n",
    "    # Instantiate the dataset with the combined list of files\n",
    "    # Note: This loads ALL data into memory. May be an issue for extremely large datasets.\n",
    "    combined_dataset = dataset_class(\n",
    "        file_paths=all_files,\n",
    "        max_k=max_k,\n",
    "        max_nk=max_nk\n",
    "        # transform can be added here if needed\n",
    "    )\n",
    "\n",
    "    total_samples = len(combined_dataset)\n",
    "    print(f\"Total samples loaded from combined files: {total_samples}\")\n",
    "\n",
    "    # Perform random split\n",
    "    val_size = int(total_samples * val_split_ratio)\n",
    "    train_size = total_samples - val_size\n",
    "\n",
    "    if train_size <= 0 or val_size <= 0:\n",
    "         raise ValueError(f\"Calculated train ({train_size}) or validation ({val_size}) size is zero or less. Check data or split ratio.\")\n",
    "\n",
    "    print(f\"Splitting data: Training={train_size} ({100*(1-val_split_ratio):.1f}%), Validation={val_size} ({100*val_split_ratio:.1f}%)\")\n",
    "    train_dataset, val_dataset = random_split(combined_dataset, [train_size, val_size])\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory\n",
    "    )\n",
    "    print(\"DataLoaders created.\")\n",
    "    print(f\"Training batches: {len(train_loader)}, Validation batches: {len(val_loader)}\")\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "def run_training(model, train_loader, val_loader, criterion, optimizer, epochs, device, model_name=\"Model\",patience=5):\n",
    "    \"\"\"\n",
    "    Runs the training and validation loop for a given model.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to train.\n",
    "        train_loader (DataLoader): DataLoader for training data.\n",
    "        val_loader (DataLoader): DataLoader for validation data.\n",
    "        criterion (nn.Module): The loss function.\n",
    "        optimizer (Optimizer): The optimizer.\n",
    "        epochs (int): Number of epochs to train.\n",
    "        device (torch.device): Device to train on ('cuda' or 'cpu').\n",
    "        model_name (str): Name of the model for printing logs.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (train_losses, val_losses) lists containing loss per epoch.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Starting Training Loop for {model_name} ---\")\n",
    "    train_losses, val_losses = [], []\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start = time.time()\n",
    "        print(f\"\\nEpoch {epoch}/{epochs} ({model_name})\")\n",
    "\n",
    "        train_loss = train_epoch_with_params(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss   = validate_epoch_with_params(model, val_loader, criterion, device)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        duration = time.time() - epoch_start\n",
    "        print(f\"Epoch {epoch} Summary ({model_name}): \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
    "              f\"Duration: {duration:.2f}s\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            print(f\"  {model_name} Val loss improved \"\n",
    "                  f\"({best_val_loss:.4f} -> {val_loss:.4f}). Saving checkpoint.\")\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(),\n",
    "                       f\"best_{model_name.lower().replace(' ', '_')}.pth\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"  No improvement for {epochs_no_improve} epoch(s).\")\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"Early stopping triggered after {patience} epochs with no improvement.\")\n",
    "                break\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\n{model_name} Training Finished. Total time: {total_time:.2f}s. \"\n",
    "          f\"Best Val Loss: {best_val_loss:.4f}\")\n",
    "    return train_losses, val_losses\n",
    "\n",
    "def run_training_embed_data(model, train_loader, val_loader, criterion, optimizer, epochs, device, model_name=\"Model\",patience=10,scheduler = None):\n",
    "    \"\"\"\n",
    "    Runs the training and validation loop for a given model.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to train.\n",
    "        train_loader (DataLoader): DataLoader for training data.\n",
    "        val_loader (DataLoader): DataLoader for validation data.\n",
    "        criterion (nn.Module): The loss function.\n",
    "        optimizer (Optimizer): The optimizer.\n",
    "        epochs (int): Number of epochs to train.\n",
    "        device (torch.device): Device to train on ('cuda' or 'cpu').\n",
    "        model_name (str): Name of the model for printing logs.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (train_losses, val_losses) lists containing loss per epoch.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Starting Training Loop for {model_name} ---\")\n",
    "    train_losses, val_losses = [], []\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start = time.time()\n",
    "        print(f\"\\nEpoch {epoch}/{epochs} ({model_name})\")\n",
    "\n",
    "        train_loss = train_epoch_with_params_embed(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss   = validate_epoch_with_params_embed(model, val_loader, criterion, device= device)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        duration = time.time() - epoch_start\n",
    "        print(f\"Epoch {epoch} Summary ({model_name}): \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
    "              f\"Duration: {duration:.2f}s\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            print(f\"  {model_name} Val loss improved \"\n",
    "                  f\"({best_val_loss:.4f} -> {val_loss:.4f}). Saving checkpoint.\")\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(),\n",
    "                       f\"best_{model_name.lower().replace(' ', '_')}.pth\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"  No improvement for {epochs_no_improve} epoch(s).\")\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"Early stopping triggered after {patience} epochs with no improvement.\")\n",
    "                break\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\n{model_name} Training Finished. Total time: {total_time:.2f}s. \"\n",
    "          f\"Best Val Loss: {best_val_loss:.4f}\")\n",
    "    return train_losses, val_losses\n",
    "\n",
    "def plot_losses(results_dict):\n",
    "    \"\"\"\n",
    "    Plots training and validation losses for multiple models.\n",
    "\n",
    "    Args:\n",
    "        results_dict (dict): A dictionary where keys are model names and\n",
    "                             values are tuples of (train_losses, val_losses).\n",
    "                             Example: {'Dense': ([...], [...]), 'CNN': ([...], [...])}\n",
    "    \"\"\"\n",
    "    num_models = len(results_dict)\n",
    "    if num_models == 0:\n",
    "        print(\"No results to plot.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nPlotting losses...\")\n",
    "    cols = 2\n",
    "    rows = (num_models + cols - 1) // cols\n",
    "    plt.figure(figsize=(6 * cols, 5 * rows))\n",
    "\n",
    "    for idx, (model_name, (train_losses, val_losses)) in enumerate(results_dict.items(), start=1):\n",
    "        if not train_losses or not val_losses:\n",
    "            print(f\"Skipping plot for {model_name} (no data).\")\n",
    "            continue\n",
    "\n",
    "        epochs = list(range(1, len(train_losses) + 1))\n",
    "        best_loss  = min(val_losses)\n",
    "        best_epoch = val_losses.index(best_loss) + 1\n",
    "\n",
    "        plt.subplot(rows, cols, idx)\n",
    "        plt.plot(epochs,\n",
    "                 train_losses,\n",
    "                 label=f\"{model_name} Train Loss\")\n",
    "        plt.plot(epochs,\n",
    "                 val_losses,\n",
    "                 label=(f\"{model_name} Val Loss \"\n",
    "                        f\"(best: {best_loss:.4f} @ epoch {best_epoch})\"))\n",
    "\n",
    "        plt.title(f\"{model_name} Loss\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Log2 MSE Loss\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device for FCN tuning: cuda\n",
      "Setup Complete: Flexible FCN class and tuning trial function are defined.\n"
     ]
    }
   ],
   "source": [
    "# --- fine tuning FCN ---\n",
    "# --- configuration ---\n",
    "fcn_padded_p_matrix_flat_size = max_k * max_nk\n",
    "fcn_params_size = 3\n",
    "\n",
    "# --- Device ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device for FCN tuning: {device}\")\n",
    "\n",
    "# --- Flexible Dense Network Definition ---\n",
    "class FlexibleDenseNetworkWithParams(nn.Module):\n",
    "    \"\"\"\n",
    "    Dense Network accepting flattened padded P matrix and n, k, m parameters.\n",
    "    Hidden layers are defined by a list of dimensions.\n",
    "    \"\"\"\n",
    "    def __init__(self, p_input_size, param_input_size, hidden_dims=[128, 64, 32], output_size=1, dropout_prob=0.2):\n",
    "        super().__init__()\n",
    "        self.param_input_size = param_input_size\n",
    "        combined_input_size = p_input_size + param_input_size\n",
    "\n",
    "        layers = []\n",
    "        prev_dim = combined_input_size\n",
    "        # Input layer check: Ensure first hidden dim connects to combined input\n",
    "        if not hidden_dims: # Handle case of no hidden layers (direct linear)\n",
    "             layers.append(nn.Linear(combined_input_size, output_size))\n",
    "        else:\n",
    "            # First hidden layer\n",
    "            layers.append(nn.Linear(combined_input_size, hidden_dims[0]))\n",
    "            layers.append(nn.ReLU())\n",
    "            if dropout_prob > 0:\n",
    "                layers.append(nn.Dropout(dropout_prob))\n",
    "            prev_dim = hidden_dims[0]\n",
    "\n",
    "            # Subsequent hidden layers\n",
    "            for i in range(1, len(hidden_dims)):\n",
    "                h_dim = hidden_dims[i]\n",
    "                layers.append(nn.Linear(prev_dim, h_dim))\n",
    "                layers.append(nn.ReLU())\n",
    "                if dropout_prob > 0:\n",
    "                    layers.append(nn.Dropout(dropout_prob))\n",
    "                prev_dim = h_dim\n",
    "\n",
    "            # Final output layer connects from the last hidden layer\n",
    "            layers.append(nn.Linear(prev_dim, output_size))\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        print(f\"Initialized FlexibleDenseNetworkWithParams:\")\n",
    "        print(f\"  Input Size (Flat P + Params): {combined_input_size}\")\n",
    "        print(f\"  Hidden Dims: {hidden_dims}\")\n",
    "        print(f\"  Output Size: {output_size}\")\n",
    "        # print(self.network) # Optional: print the layer structure\n",
    "\n",
    "    def forward(self, p_matrix, params):\n",
    "        batch_size = p_matrix.size(0)\n",
    "        p_flat = p_matrix.view(batch_size, -1) # Flatten P matrix\n",
    "\n",
    "        # Ensure params tensor has the correct shape (batch_size, num_params)\n",
    "        if params.dim() == 1: # If it's a single sample (batch size 1 during inference maybe?)\n",
    "             params = params.unsqueeze(0)\n",
    "        if params.size(1) != self.param_input_size:\n",
    "             raise ValueError(f\"Params tensor second dimension ({params.size(1)}) != expected param_input_size ({self.param_input_size})\")\n",
    "\n",
    "        combined_input = torch.cat((p_flat, params), dim=1)\n",
    "        return self.network(combined_input)\n",
    "\n",
    "# --- Training Function for One Tuning Trial ---\n",
    "def run_fcn_tuning_trial(config, train_loader, val_loader, p_input_size, param_input_size, epochs, device):\n",
    "    \"\"\"Trains and evaluates one FCN configuration.\"\"\"\n",
    "    print(f\"\\n--- Starting Trial: {config.get('name', config)} ---\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Extract config\n",
    "    hidden_dims = config['hidden_dims']\n",
    "    learning_rate = config['lr']\n",
    "    dropout_prob = config.get('dropout', 0.2) # Use default if not specified\n",
    "    weight_decay = config.get('weight_decay', 0) # Get weight_decay from config, default to 0\n",
    "\n",
    "    # Ensure Loss function is defined (should be LogMSELoss)\n",
    "    if 'LogMSELoss' not in globals():\n",
    "         raise NameError(\"LogMSELoss class is not defined.\")\n",
    "    criterion = LogMSELoss()\n",
    "\n",
    "    # Instantiate model, criterion, optimizer\n",
    "    model = FlexibleDenseNetworkWithParams(\n",
    "        p_input_size=p_input_size,\n",
    "        param_input_size=param_input_size,\n",
    "        hidden_dims=hidden_dims,\n",
    "        dropout_prob=dropout_prob\n",
    "    ).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay = weight_decay)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    # Check if training functions are defined\n",
    "    if 'train_epoch_with_params' not in globals() or 'validate_epoch_with_params' not in globals():\n",
    "         raise NameError(\"train_epoch_with_params or validate_epoch_with_params function is not defined.\")\n",
    "\n",
    "    print(f\"  Training for {epochs} epochs...\")\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_epoch_with_params(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss = validate_epoch_with_params(model, val_loader, criterion, device)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        print(f\"  Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"--- Trial Finished: {config.get('name', config)} ---\")\n",
    "    print(f\"  Best Val Loss during trial: {best_val_loss:.4f}\")\n",
    "    print(f\"  Total Time: {end_time - start_time:.2f}s\")\n",
    "\n",
    "    # Return the minimum validation loss achieved during this trial\n",
    "    return {'config': config, 'best_val_loss': best_val_loss, 'train_losses': train_losses, 'val_losses': val_losses}\n",
    "\n",
    "print(\"Setup Complete: Flexible FCN class and tuning trial function are defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Final Training for Selected FCN ---\n",
      "Using Configuration: {'name': 'FCN_128_64_32_lr5e-4', 'hidden_dims': [512, 256, 128], 'lr': 0.0005, 'dropout': 0.3, 'weight_decay': 1e-05}\n",
      "Training for 40 epochs.\n",
      "Best model weights will be saved to: best_fcn_pretrained_weights.pth\n",
      "Initialized FlexibleDenseNetworkWithParams:\n",
      "  Input Size (Flat P + Params): 39\n",
      "  Hidden Dims: [512, 256, 128]\n",
      "  Output Size: 1\n",
      "Starting final training run...\n",
      "Epoch 1/40 | Train Loss: 13.1391 | Val Loss: 10.8700 | Time: 53.16s\n",
      "  -> Val loss improved to 10.8700. Model weights saved to best_fcn_pretrained_weights.pth\n",
      "Epoch 2/40 | Train Loss: 10.0961 | Val Loss: 7.9521 | Time: 52.25s\n",
      "  -> Val loss improved to 7.9521. Model weights saved to best_fcn_pretrained_weights.pth\n",
      "Epoch 3/40 | Train Loss: 5.2197 | Val Loss: 2.9379 | Time: 52.65s\n",
      "  -> Val loss improved to 2.9379. Model weights saved to best_fcn_pretrained_weights.pth\n",
      "Epoch 4/40 | Train Loss: 2.8051 | Val Loss: 2.0519 | Time: 57.54s\n",
      "  -> Val loss improved to 2.0519. Model weights saved to best_fcn_pretrained_weights.pth\n",
      "Epoch 5/40 | Train Loss: 2.1814 | Val Loss: 1.6929 | Time: 48.93s\n",
      "  -> Val loss improved to 1.6929. Model weights saved to best_fcn_pretrained_weights.pth\n",
      "Epoch 6/40 | Train Loss: 1.9156 | Val Loss: 1.5944 | Time: 50.66s\n",
      "  -> Val loss improved to 1.5944. Model weights saved to best_fcn_pretrained_weights.pth\n",
      "Epoch 7/40 | Train Loss: 1.7855 | Val Loss: 1.5547 | Time: 54.82s\n",
      "  -> Val loss improved to 1.5547. Model weights saved to best_fcn_pretrained_weights.pth\n",
      "Epoch 8/40 | Train Loss: 1.7040 | Val Loss: 1.5068 | Time: 51.21s\n",
      "  -> Val loss improved to 1.5068. Model weights saved to best_fcn_pretrained_weights.pth\n",
      "Epoch 9/40 | Train Loss: 1.6517 | Val Loss: 1.4861 | Time: 53.60s\n",
      "  -> Val loss improved to 1.4861. Model weights saved to best_fcn_pretrained_weights.pth\n",
      "Epoch 10/40 | Train Loss: 1.6089 | Val Loss: 1.4546 | Time: 51.64s\n",
      "  -> Val loss improved to 1.4546. Model weights saved to best_fcn_pretrained_weights.pth\n",
      "Epoch 11/40 | Train Loss: 1.5792 | Val Loss: 1.4372 | Time: 49.12s\n",
      "  -> Val loss improved to 1.4372. Model weights saved to best_fcn_pretrained_weights.pth\n",
      "Epoch 12/40 | Train Loss: 1.5573 | Val Loss: 1.4412 | Time: 51.57s\n",
      "Epoch 13/40 | Train Loss: 1.5381 | Val Loss: 1.4174 | Time: 52.93s\n",
      "  -> Val loss improved to 1.4174. Model weights saved to best_fcn_pretrained_weights.pth\n",
      "Epoch 14/40 | Train Loss: 1.5252 | Val Loss: 1.4118 | Time: 53.64s\n",
      "  -> Val loss improved to 1.4118. Model weights saved to best_fcn_pretrained_weights.pth\n",
      "Epoch 15/40 | Train Loss: 1.5151 | Val Loss: 1.4155 | Time: 50.70s\n",
      "Epoch 16/40 | Train Loss: 1.5041 | Val Loss: 1.3988 | Time: 50.85s\n",
      "  -> Val loss improved to 1.3988. Model weights saved to best_fcn_pretrained_weights.pth\n",
      "Epoch 17/40 | Train Loss: 1.4973 | Val Loss: 1.3983 | Time: 52.79s\n",
      "  -> Val loss improved to 1.3983. Model weights saved to best_fcn_pretrained_weights.pth\n",
      "Epoch 18/40 | Train Loss: 1.4868 | Val Loss: 1.3847 | Time: 53.20s\n",
      "  -> Val loss improved to 1.3847. Model weights saved to best_fcn_pretrained_weights.pth\n",
      "Epoch 19/40 | Train Loss: 1.4792 | Val Loss: 1.3954 | Time: 48.97s\n",
      "Epoch 20/40 | Train Loss: 1.4757 | Val Loss: 1.3763 | Time: 49.80s\n",
      "  -> Val loss improved to 1.3763. Model weights saved to best_fcn_pretrained_weights.pth\n",
      "Epoch 21/40 | Train Loss: 1.4680 | Val Loss: 1.3771 | Time: 49.84s\n",
      "Epoch 22/40 | Train Loss: 1.4836 | Val Loss: 1.3910 | Time: 48.90s\n",
      "Epoch 23/40 | Train Loss: 1.4970 | Val Loss: 1.3822 | Time: 50.35s\n",
      "Epoch 24/40 | Train Loss: 1.4717 | Val Loss: 1.3810 | Time: 48.25s\n",
      "Epoch 25/40 | Train Loss: 1.4705 | Val Loss: 1.3830 | Time: 51.88s\n",
      "Epoch 26/40 | Train Loss: 1.4661 | Val Loss: 1.3733 | Time: 50.54s\n",
      "  -> Val loss improved to 1.3733. Model weights saved to best_fcn_pretrained_weights.pth\n",
      "Epoch 27/40 | Train Loss: 1.4574 | Val Loss: 1.3778 | Time: 49.52s\n",
      "Epoch 28/40 | Train Loss: 1.4574 | Val Loss: 1.3714 | Time: 48.14s\n",
      "  -> Val loss improved to 1.3714. Model weights saved to best_fcn_pretrained_weights.pth\n",
      "Epoch 29/40 | Train Loss: 1.4677 | Val Loss: 1.3830 | Time: 50.25s\n",
      "Epoch 30/40 | Train Loss: 1.4496 | Val Loss: 1.3776 | Time: 53.81s\n",
      "Epoch 31/40 | Train Loss: 1.4456 | Val Loss: 1.3737 | Time: 50.90s\n",
      "Epoch 32/40 | Train Loss: 1.4467 | Val Loss: 1.3760 | Time: 46.55s\n",
      "Epoch 33/40 | Train Loss: 1.4511 | Val Loss: 1.3829 | Time: 47.17s\n",
      "Epoch 34/40 | Train Loss: 1.4415 | Val Loss: 1.3771 | Time: 53.76s\n",
      "Epoch 35/40 | Train Loss: 1.4403 | Val Loss: 1.3870 | Time: 56.03s\n",
      "Epoch 36/40 | Train Loss: 1.4404 | Val Loss: 1.3778 | Time: 52.03s\n",
      "Epoch 37/40 | Train Loss: 1.4385 | Val Loss: 1.3822 | Time: 47.63s\n",
      "Epoch 38/40 | Train Loss: 1.4478 | Val Loss: 1.3803 | Time: 51.11s\n",
      "Epoch 39/40 | Train Loss: 1.4391 | Val Loss: 1.3741 | Time: 45.82s\n",
      "Epoch 40/40 | Train Loss: 1.4303 | Val Loss: 1.3836 | Time: 49.46s\n",
      "\n",
      "Final FCN Training Finished.\n",
      "  Total time: 2042.11 seconds\n",
      "  Best Validation Loss achieved during training: 1.3714\n",
      "  Best model weights saved to: best_fcn_pretrained_weights.pth\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step A (FCN Pre-training) Complete. Weights are saved in: best_fcn_pretrained_weights.pth\n"
     ]
    }
   ],
   "source": [
    "# --- Final Training of the Best FCN Configuration ---\n",
    "print(\"Default device:\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "best_fcn_config = {\n",
    "    'name': 'FCN_128_64_32_lr5e-4', \n",
    "    'hidden_dims': [512, 256, 128],    \n",
    "    'lr': 0.0005,                  \n",
    "    'dropout': 0.3,                  \n",
    "    'weight_decay': 1e-5  # I added L2 regularization as it improves a little bit the generalization of the model when I test with and without it\n",
    "}\n",
    "\n",
    "# --- Training Parameters for Final Run ---\n",
    "epochs = 40 #\n",
    "model_save_path = 'best_fcn_pretrained_weights.pth' # Filename for saved weights\n",
    "\n",
    "# --- Prerequisites Check ---\n",
    "if 'FlexibleDenseNetworkWithParams' not in locals():\n",
    "    print(\"ERROR: FlexibleDenseNetworkWithParams class definition not found. Run Cell 1.\")\n",
    "elif 'LogMSELoss' not in locals():\n",
    "    print(\"ERROR: LogMSELoss class definition not found.\")\n",
    "elif 'train_epoch_with_params' not in locals() or 'validate_epoch_with_params' not in locals():\n",
    "     print(\"ERROR: Training loop epoch functions not found.\")\n",
    "elif 'train_loader' not in locals() or 'val_loader' not in locals():\n",
    "    print(\"ERROR: train_loader or val_loader not found.\")\n",
    "else:\n",
    "    print(f\"\\n--- Starting Final Training for Selected FCN ---\")\n",
    "    print(f\"Using Configuration: {best_fcn_config}\")\n",
    "    print(f\"Training for {epochs} epochs.\")\n",
    "    print(f\"Best model weights will be saved to: {model_save_path}\")\n",
    "\n",
    "    # --- Instantiate the Best Model ---\n",
    "    fcn_model = FlexibleDenseNetworkWithParams(\n",
    "        p_input_size=fcn_padded_p_matrix_flat_size, # Should be defined in previous cell\n",
    "        param_input_size=fcn_params_size,           # Should be defined in previous cell\n",
    "        hidden_dims=best_fcn_config['hidden_dims'],\n",
    "        dropout_prob=best_fcn_config.get('dropout', 0.2) # Use dropout if specified\n",
    "    ).to(device)\n",
    "\n",
    "    # --- Criterion and Optimizer ---\n",
    "    criterion = LogMSELoss()\n",
    "    optimizer = optim.Adam(fcn_model.parameters(), lr=best_fcn_config['lr'],weight_decay = best_fcn_config['weight_decay'])\n",
    "\n",
    "    # --- Training Loop (with saving best model) ---\n",
    "    best_val_loss = float('inf')\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(\"Starting final training run...\")\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        # Perform one epoch of training and validation\n",
    "        train_loss = train_epoch_with_params(fcn_model, train_loader, criterion, optimizer, device)\n",
    "        val_loss = validate_epoch_with_params(fcn_model, val_loader, criterion, device)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        epoch_duration = time.time() - epoch_start_time\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Time: {epoch_duration:.2f}s\")\n",
    "\n",
    "        # Save the model if validation loss improves\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            # Save the model's state dictionary\n",
    "            torch.save(fcn_model.state_dict(), model_save_path)\n",
    "            print(f\"  -> Val loss improved to {best_val_loss:.4f}. Model weights saved to {model_save_path}\")\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nFinal FCN Training Finished.\")\n",
    "    print(f\"  Total time: {total_time:.2f} seconds\")\n",
    "    print(f\"  Best Validation Loss achieved during training: {best_val_loss:.4f}\")\n",
    "    print(f\"  Best model weights saved to: {model_save_path}\")\n",
    "\n",
    "    # --- Optional: Plot Training Curve ---\n",
    "    if train_losses and val_losses and 'matplotlib' in sys.modules:\n",
    "        try:\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.plot(train_losses, label='Train Loss')\n",
    "            plt.plot(val_losses, label=f'Val Loss (Best: {best_val_loss:.4f})')\n",
    "            # Mark the best validation point\n",
    "            best_epoch_idx = np.argmin(val_losses)\n",
    "            plt.scatter([best_epoch_idx], [best_val_loss], color='red', s=50, zorder=5, label=f'Best Val @ Epoch {best_epoch_idx+1}')\n",
    "            plt.title(f'Final Training: Best FCN ({best_fcn_config.get(\"name\", \"Config\")})')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Log2 MSE Loss')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "        except Exception as plot_err:\n",
    "            print(f\"\\nWarning: Plotting curve failed - {plot_err}\")\n",
    "\n",
    "\n",
    "print(\"\\nStep A (FCN Pre-training) Complete. Weights are saved in:\", model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by doubling the number of samples, we achieve a loss of 1.37 with a fine tuned FCN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are trying to see which static normalisation is the best one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that thanks to the normalisation, the model is converging faster and we have better loss values.  \n",
    "\n",
    "with min_max normalization, we have a validation loss of 1.3496 with only 20 epochs and with the standard normalization (mu and standard deviation), we obtain 1.355"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FCN + residual block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 1. Fully‑connected Residual Net -----------------\n",
    "class ResidualFCNBlock(nn.Module):\n",
    "    def __init__(self, dim, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(dim, dim)\n",
    "        self.lin2 = nn.Linear(dim, dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.lin1(x))\n",
    "        h = self.dropout(h)\n",
    "        h = self.lin2(h)\n",
    "        return F.relu(x + h)\n",
    "\n",
    "class ResidualFCNWithParams(nn.Module):\n",
    "    \"\"\"\n",
    "    Deep FCN with N residual blocks.  Works with flattened P.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 k_max=6, nk_max=6,               # padding sizes\n",
    "                 n_params=3,\n",
    "                 hidden_dim=512,\n",
    "                 num_blocks=6,\n",
    "                 dropout=0.1):\n",
    "        super().__init__()\n",
    "        in_dim = k_max * nk_max + n_params\n",
    "\n",
    "        self.input = nn.Linear(in_dim, hidden_dim)\n",
    "        self.blocks = nn.Sequential(\n",
    "            *[ResidualFCNBlock(hidden_dim, dropout) for _ in range(num_blocks)]\n",
    "        )\n",
    "        self.out = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, P, params):\n",
    "        b = P.size(0)\n",
    "        x = torch.cat([P.view(b, -1), params.float()], dim=1)\n",
    "        x = F.relu(self.input(x))\n",
    "        x = self.blocks(x)\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the ResidualFCN‐based model\n",
    "model = ResidualFCNWithParams(\n",
    "            k_max=max_k, nk_max=max_nk,\n",
    "            hidden_dim=512, num_blocks=8, dropout=0.2).to(device)\n",
    "\n",
    "# Loss and optimiser\n",
    "criterion = LogMSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-3, weight_decay=1e-4)\n",
    "\n",
    "# training\n",
    "train_losses, val_losses = run_training(\n",
    "        model, train_loader, val_loader,\n",
    "        criterion, optimizer,\n",
    "        epochs=30, device=device,\n",
    "        model_name='ResFCN')\n",
    "\n",
    "# Plotting\n",
    "results[\"ResFCN\"] = (train_losses, val_losses)\n",
    "plot_losses(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results : best accuracy : 1.3437"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 2. Column‑wise Transformer ---------------------\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=16):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div = torch.exp(torch.arange(0, d_model, 2).float() *\n",
    "                        (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(pos * div)\n",
    "        pe[:, 1::2] = torch.cos(pos * div)\n",
    "        pe = pe.unsqueeze(0)                       # (1, L, D)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]\n",
    "\n",
    "class ColumnTransformerWithParams(nn.Module):\n",
    "    \"\"\"\n",
    "    Treats each column of P as a token, embeds it, runs a Transformer encoder,\n",
    "    then pools and regresses to the m‑height.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 k_max=6, nk_max=6,\n",
    "                 n_params=3,\n",
    "                 d_model=128,\n",
    "                 n_heads=8,\n",
    "                 num_layers=3,\n",
    "                 dim_ff=256,\n",
    "                 dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.nk_max = nk_max\n",
    "        self.embed_col = nn.Linear(k_max, d_model)\n",
    "        self.pos_enc   = PositionalEncoding(d_model, max_len=nk_max)\n",
    "        encoder_layer  = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=dim_ff,\n",
    "            dropout=dropout,\n",
    "            batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer,\n",
    "                                                 num_layers=num_layers)\n",
    "        self.param_proj = nn.Linear(n_params, d_model)\n",
    "        self.regressor  = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model//2, 1)\n",
    "        )\n",
    "        self.col_id_emb = nn.Embedding(nk_max, d_model)\n",
    "\n",
    "    def forward(self, P, params, col_idx):\n",
    "        # P : (B, k_max, nk_max)  ->  (B, nk_max, k_max)\n",
    "        col_tokens = P.transpose(1, 2)\n",
    "        col_tokens = self.embed_col(col_tokens)            # (B, nk_max, D)\n",
    "        col_tokens += self.col_id_emb(col_idx)\n",
    "        col_tokens = self.pos_enc(col_tokens)\n",
    "        h = self.transformer(col_tokens)                   # same shape\n",
    "        h = h.mean(dim=1)                                  # pool over columns\n",
    "\n",
    "        h_params = self.param_proj(params.float())         # (B, D)\n",
    "        h = h + h_params                                   # fuse\n",
    "\n",
    "        return self.regressor(h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the transformer‐based model\n",
    "model = ColumnTransformerWithParams(\n",
    "    k_max=max_k,\n",
    "    nk_max=max_nk,\n",
    "    n_params=3,      \n",
    "    d_model=128,\n",
    "    n_heads=8,\n",
    "    num_layers=3,\n",
    "    dim_ff=512,\n",
    "    dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer,\n",
    "    T_0=10,\n",
    "    T_mult=2\n",
    ")\n",
    "# Loss & optimizer\n",
    "criterion = LogMSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "\n",
    "# Training\n",
    "train_losses, val_losses = run_training_embed_data(\n",
    "    model, train_loader_embed, val_loader_embed,\n",
    "    criterion, optimizer,\n",
    "    epochs=50, device=device,\n",
    "    model_name='Transformer',\n",
    "    scheduler = scheduler\n",
    ")\n",
    "# Record & plot\n",
    "results[\"Transformer\"] = (train_losses, val_losses)\n",
    "plot_losses(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 3. Small 2‑D ResNet on P “image” ---------------\n",
    "class ConvResBlock(nn.Module):\n",
    "    def __init__(self, ch):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(ch, ch, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(ch, ch, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(ch)\n",
    "        self.bn2 = nn.BatchNorm2d(ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.bn1(self.conv1(x)))\n",
    "        h = self.bn2(self.conv2(h))\n",
    "        return F.relu(x + h)\n",
    "\n",
    "class ResNet2DWithParams(nn.Module):\n",
    "    \"\"\"\n",
    "    Interprets padded P as a single‑channel image (k_max×nk_max).\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 k_max=6, nk_max=6,\n",
    "                 n_params=3,\n",
    "                 base_ch=32,\n",
    "                 num_blocks=3):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(1, base_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_ch),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.blocks = nn.Sequential(\n",
    "            *[ConvResBlock(base_ch) for _ in range(num_blocks)]\n",
    "        )\n",
    "        flat_dim = base_ch * k_max * nk_max\n",
    "        self.param_proj = nn.Linear(n_params, 64)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(flat_dim + 64, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, P, params):\n",
    "        x = P.unsqueeze(1)                  # (B, 1, k_max, nk_max)\n",
    "        x = self.blocks(self.stem(x))\n",
    "        x = x.flatten(1)\n",
    "        p = F.relu(self.param_proj(params.float()))\n",
    "        x = torch.cat([x, p], dim=1)\n",
    "        return self.head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the 2D‑ResNet‑based model\n",
    "model = ResNet2DWithParams(\n",
    "    k_max=max_k,\n",
    "    nk_max=max_nk,\n",
    "    n_params=3,     # number of extra numerical features\n",
    "    base_ch=32,     # number of channels in the stem and residual blocks\n",
    "    num_blocks=3    # number of ConvResBlock’s\n",
    ").to(device)\n",
    "\n",
    "# Loss & optimizer\n",
    "criterion = LogMSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-3, weight_decay=1e-4)\n",
    "\n",
    "# Training\n",
    "train_losses, val_losses = run_training(\n",
    "    model, train_loader, val_loader,\n",
    "    criterion, optimizer,\n",
    "    epochs=30, device=device,\n",
    "    model_name='ResNet2D'\n",
    ")\n",
    "# Record & plot\n",
    "results[\"ResNet2D\"] = (train_losses, val_losses)\n",
    "plot_losses(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results : best accuracy : 1.2887"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 4. Fully‑connected Residual Net with batchnormalisation -----------------\n",
    "class ResidualFCNBlockBN(nn.Module):\n",
    "    def __init__(self, dim, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.bn1      = nn.BatchNorm1d(dim)\n",
    "        self.lin1     = nn.Linear(dim, dim)\n",
    "        self.dropout  = nn.Dropout(dropout)\n",
    "        self.bn2      = nn.BatchNorm1d(dim)\n",
    "        self.lin2     = nn.Linear(dim, dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # BN → ReLU → Linear → Dropout → BN → ReLU → Linear → add → ReLU\n",
    "        h = self.bn1(x)\n",
    "        h = F.relu(h)\n",
    "        h = self.lin1(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.bn2(h)\n",
    "        h = F.relu(h)\n",
    "        h = self.lin2(h)\n",
    "        return F.relu(x + h)\n",
    "\n",
    "\n",
    "class ResidualFCNWithParamsBN(nn.Module):\n",
    "    \"\"\"\n",
    "    Same as ResidualFCNWithParams, but uses BatchNorm inside each block.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 k_max=6, nk_max=6,\n",
    "                 n_params=3,\n",
    "                 hidden_dim=512,\n",
    "                 num_blocks=6,\n",
    "                 dropout=0.1):\n",
    "        super().__init__()\n",
    "        in_dim = k_max * nk_max + n_params\n",
    "\n",
    "        # initial projection\n",
    "        self.input = nn.Linear(in_dim, hidden_dim)\n",
    "        # stack of BN‑residual blocks\n",
    "        self.blocks = nn.Sequential(\n",
    "            *[ResidualFCNBlockBN(hidden_dim, dropout) for _ in range(num_blocks)]\n",
    "        )\n",
    "        # final regressor head\n",
    "        self.out = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, P, params):\n",
    "        # P: (B, k_max, nk_max), params: (B, n_params)\n",
    "        b = P.size(0)\n",
    "        # flatten P and concat numeric params\n",
    "        x = torch.cat([P.view(b, -1), params.float()], dim=1)\n",
    "        # initial feed‑forward\n",
    "        x = F.relu(self.input(x))\n",
    "        # deep residual stack\n",
    "        x = self.blocks(x)\n",
    "        # regression output\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the fully‐connected residual‐BN model\n",
    "model = ResidualFCNWithParamsBN(\n",
    "    k_max=max_k,\n",
    "    nk_max=max_nk,\n",
    "    n_params=3,        # number of extra numerical features\n",
    "    hidden_dim=512,    # dimension of each FC layer\n",
    "    num_blocks=6,      # number of ResidualFCNBlockBN’s\n",
    "    dropout=0.2        # dropout probability inside each block\n",
    ").to(device)\n",
    "\n",
    "# Loss & optimizer\n",
    "criterion = LogMSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-3, weight_decay=1e-4)\n",
    "\n",
    "# Training\n",
    "train_losses, val_losses = run_training(\n",
    "    model, train_loader, val_loader,\n",
    "    criterion, optimizer,\n",
    "    epochs=40, device=device,\n",
    "    model_name='ResFCN_BN'\n",
    ")\n",
    "\n",
    "# Record & plot\n",
    "results[\"ResFCN_BN\"] = (train_losses, val_losses)\n",
    "plot_losses(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results : best loss values : 1.38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 5. Conv Auto encoder class -----------------\n",
    "class ConvAutoEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Symmetric conv AE for 6×6 padded P‑matrices.\n",
    "\n",
    "    Encoder  : same conv stem + residual blocks the winning ResNet uses\n",
    "    Decoder  : transposed‑conv mirror that reconstructs P\n",
    "    latent_dim controls the bottleneck size fed later to a regressor head.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 k_max=6, nk_max=6,\n",
    "                 base_ch=32,\n",
    "                 num_blocks=3,\n",
    "                 latent_dim=128):\n",
    "        super().__init__()\n",
    "        # ---- encoder (reuse weights later) ----\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(1, base_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(base_ch),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.enc_res = nn.Sequential(*[ConvResBlock(base_ch)\n",
    "                                       for _ in range(num_blocks)])\n",
    "        self.enc_flat = nn.Flatten()\n",
    "        self.latent   = nn.Linear(base_ch * k_max * nk_max, latent_dim)\n",
    "\n",
    "        # ---- decoder ----\n",
    "        self.dec_fc   = nn.Linear(latent_dim, base_ch * k_max * nk_max)\n",
    "        self.dec_res  = nn.Sequential(*[ConvResBlock(base_ch)\n",
    "                                        for _ in range(num_blocks)])\n",
    "        self.out      = nn.Conv2d(base_ch, 1, 3, padding=1)\n",
    "\n",
    "    # -------- helper used later --------\n",
    "    def encode(self, P):                      # P: (B,1,6,6)\n",
    "        h = self.stem(P)\n",
    "        h = self.enc_res(h)\n",
    "        h = self.enc_flat(h)\n",
    "        return self.latent(h)                 # (B, latent_dim)\n",
    "\n",
    "    def forward(self, P):                     # P: (B,1,6,6)\n",
    "        z = self.encode(P)\n",
    "        h = self.dec_fc(z).view_as(P.repeat(1, 32, 1, 1))\n",
    "        h = self.dec_res(h)\n",
    "        recon = self.out(h)                   # (B,1,6,6)\n",
    "        return recon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Instantiate the auto‑encoder\n",
    "model = ConvAutoEncoder(\n",
    "    k_max=max_k,\n",
    "    nk_max=max_nk,\n",
    "    base_ch=32,\n",
    "    num_blocks=3,\n",
    "    latent_dim=128\n",
    ").to(device)\n",
    "\n",
    "# 2) Criterion & optimizer\n",
    "criterion = LogMSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "# 3) Training loop\n",
    "train_losses, val_losses = [], []\n",
    "best_val_loss = float('inf')\n",
    "epochs_ae = 30\n",
    "\n",
    "for epoch in range(1, epochs_ae + 1):\n",
    "    # ——— Train ———\n",
    "    model.train()\n",
    "    train_running = 0.0\n",
    "    for _, _, p_matrices in train_loader:\n",
    "        P = p_matrices.unsqueeze(1).to(device)   # (B,1,k_max,nk_max)\n",
    "        optimizer.zero_grad()\n",
    "        recon = model(P)\n",
    "        loss = criterion(recon, P)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_running += loss.item() * P.size(0)\n",
    "    train_loss = train_running / len(train_loader.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # ——— Validate ———\n",
    "    model.eval()\n",
    "    val_running = 0.0\n",
    "    with torch.no_grad():\n",
    "        for _, _, p_matrices in val_loader:\n",
    "            P = p_matrices.unsqueeze(1).to(device)\n",
    "            recon = model(P)\n",
    "            loss = criterion(recon, P)\n",
    "            val_running += loss.item() * P.size(0)\n",
    "    val_loss = val_running / len(val_loader.dataset)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    print(f\"AE Epoch {epoch}/{epochs_ae}  Train Loss: {train_loss:.4f}  Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # ——— Checkpoint best ———\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"conv_autoencoder.pth\")\n",
    "        print(f\"  → Best AE model saved (Val Loss {best_val_loss:.4f})\")\n",
    "\n",
    "print(\"Auto‑encoder training complete. Best validation loss:\", best_val_loss)\n",
    "\n",
    "# 4) Record & plot\n",
    "results[\"ConvAutoEncoder\"] = (train_losses, val_losses)\n",
    "plot_losses(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetRegressorFromAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Loads encoder from a trained ConvAutoEncoder and fine‑tunes\n",
    "    end‑to‑end for m‑height regression.\n",
    "    \"\"\"\n",
    "    def __init__(self, ae_checkpoint,\n",
    "                 k_max=6, nk_max=6,\n",
    "                 n_params=3,\n",
    "                 latent_dim=128):\n",
    "        super().__init__()\n",
    "        # ----- load pretrained encoder -----\n",
    "        backbone = ConvAutoEncoder(k_max=k_max, nk_max=nk_max,\n",
    "                                   latent_dim=latent_dim)\n",
    "        backbone.load_state_dict(torch.load(ae_checkpoint,\n",
    "                                            map_location=\"cpu\"))\n",
    "        self.encoder = nn.Sequential(backbone.stem,\n",
    "                                     backbone.enc_res,\n",
    "                                     nn.Flatten(),\n",
    "                                     backbone.latent)      # (B, latent_dim)\n",
    "\n",
    "        # ----- regression head -----\n",
    "        self.param_proj = nn.Linear(n_params, latent_dim)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(latent_dim, latent_dim//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(latent_dim//2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, P, params):\n",
    "        z_img = self.encoder(P.unsqueeze(1))          # (B, latent)\n",
    "        z_par = self.param_proj(params.float())       # (B, latent)\n",
    "        return self.head(F.relu(z_img + z_par))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Instantiate the AE‑based ResNet regressor ---\n",
    "ae_checkpoint = '/conv_autoencoder.pth'  # set this to wherever you saved your AE weights\n",
    "model = ResNetRegressorFromAE(\n",
    "    ae_checkpoint,\n",
    "    k_max=max_k,\n",
    "    nk_max=max_nk,\n",
    "    n_params=3,        # same as in your dataset\n",
    "    latent_dim=128     # must match the AE's latent_dim\n",
    ").to(device)\n",
    "\n",
    "# --- Loss & optimizer ---\n",
    "criterion = LogMSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "\n",
    "# --- Training ---\n",
    "train_losses, val_losses = run_training(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    epochs=30,\n",
    "    device=device,\n",
    "    model_name='ResNetFromAE'\n",
    ")\n",
    "\n",
    "# --- Record & plot ---\n",
    "results[\"ResNetFromAE\"] = (train_losses, val_losses)\n",
    "plot_losses(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet showed the best loss values, we are going to fine tune it using optuna framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- objective -----------------------\n",
    "def objective(trial: optuna.Trial):\n",
    "    # ----- search space (patch) ---------------------------------\n",
    "    base_ch    = trial.suggest_categorical(\"base_ch\", [8, 16, 32, 48, 64])\n",
    "\n",
    "    # use categorical for specific counts of residual blocks\n",
    "    n_blocks   = trial.suggest_categorical(\"num_blocks\", [2, 3, 5, 7])\n",
    "\n",
    "    # dropout as a discrete set of values\n",
    "    dropout    = trial.suggest_categorical(\"dropout\", [0.0, 0.1, 0.25, 0.3])\n",
    "\n",
    "    lr         = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True)\n",
    "    wd         = trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n",
    "\n",
    "    scheduler  = trial.suggest_categorical(\"scheduler\", [\"none\", \"cosine\"])\n",
    "\n",
    "\n",
    "    # ----- model -----\n",
    "    model = ResNet2DWithParams(\n",
    "                k_max=max_k, nk_max=max_nk,\n",
    "                base_ch=base_ch, num_blocks=n_blocks).to(device)\n",
    "\n",
    "    criterion = LogMSELoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "    if scheduler == \"cosine\":\n",
    "        sched = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=6, T_mult=2)\n",
    "    else:\n",
    "        sched = None\n",
    "\n",
    "    best_val = math.inf\n",
    "    for epoch in range(epochs):\n",
    "        train_epoch_with_params(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss = validate_epoch_with_params(model, val_loader, criterion, device)\n",
    "        best_val = min(best_val, val_loss)\n",
    "\n",
    "        if sched: sched.step()\n",
    "\n",
    "        # report & prune\n",
    "        trial.report(val_loss, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    # save checkpoint for the best trial only (done outside)\n",
    "    trial.set_user_attr(\"state_dict\", copy.deepcopy(model.state_dict()))\n",
    "    return best_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-18 03:17:13,643] A new study created in memory with name: no-name-c9dec29f-8c7a-45c5-b256-a9c6d2103412\n",
      "[I 2025-04-18 03:34:20,236] Trial 0 finished with value: 1.415998617762611 and parameters: {'base_ch': 32, 'num_blocks': 5, 'dropout': 0.25, 'lr': 0.0002777715907121776, 'weight_decay': 0.0006087547516694186, 'scheduler': 'cosine'}. Best is trial 0 with value: 1.415998617762611.\n",
      "[I 2025-04-18 03:50:43,816] Trial 1 finished with value: 5.95932033429827 and parameters: {'base_ch': 64, 'num_blocks': 3, 'dropout': 0.1, 'lr': 0.00011247440733216735, 'weight_decay': 0.0007902355990825514, 'scheduler': 'cosine'}. Best is trial 0 with value: 1.415998617762611.\n",
      "[I 2025-04-18 04:07:49,979] Trial 2 finished with value: 3.951272326424008 and parameters: {'base_ch': 48, 'num_blocks': 5, 'dropout': 0.1, 'lr': 0.0002040872037209723, 'weight_decay': 3.841055527395037e-06, 'scheduler': 'none'}. Best is trial 0 with value: 1.415998617762611.\n",
      "[I 2025-04-18 04:25:05,547] Trial 3 finished with value: 3.4776147457304454 and parameters: {'base_ch': 16, 'num_blocks': 7, 'dropout': 0.3, 'lr': 0.00010866106387320391, 'weight_decay': 1.0135027870061314e-06, 'scheduler': 'none'}. Best is trial 0 with value: 1.415998617762611.\n",
      "[I 2025-04-18 04:44:00,467] Trial 4 finished with value: 1.1528423660823277 and parameters: {'base_ch': 64, 'num_blocks': 7, 'dropout': 0.25, 'lr': 0.0016954971391530502, 'weight_decay': 0.00045509803348398476, 'scheduler': 'cosine'}. Best is trial 4 with value: 1.1528423660823277.\n",
      "[I 2025-04-18 05:01:32,397] Trial 5 finished with value: 1.2787429380871 and parameters: {'base_ch': 64, 'num_blocks': 5, 'dropout': 0.25, 'lr': 0.00018171922302490963, 'weight_decay': 9.883210876794644e-05, 'scheduler': 'none'}. Best is trial 4 with value: 1.1528423660823277.\n",
      "[I 2025-04-18 05:05:58,079] Trial 6 pruned. \n",
      "[I 2025-04-18 05:10:44,788] Trial 7 pruned. \n",
      "[I 2025-04-18 05:26:29,790] Trial 8 finished with value: 1.1861702604293822 and parameters: {'base_ch': 32, 'num_blocks': 3, 'dropout': 0.25, 'lr': 0.0009498061287516505, 'weight_decay': 1.8941283646989015e-05, 'scheduler': 'none'}. Best is trial 4 with value: 1.1528423660823277.\n",
      "[I 2025-04-18 05:30:50,377] Trial 9 pruned. \n",
      "[I 2025-04-18 05:45:52,049] Trial 10 finished with value: 1.1498817755381265 and parameters: {'base_ch': 16, 'num_blocks': 2, 'dropout': 0.0, 'lr': 0.0031382483369686576, 'weight_decay': 0.00018664656235686027, 'scheduler': 'cosine'}. Best is trial 10 with value: 1.1498817755381265.\n",
      "[I 2025-04-18 06:00:50,629] Trial 11 finished with value: 1.1491274542581467 and parameters: {'base_ch': 16, 'num_blocks': 2, 'dropout': 0.0, 'lr': 0.003731917796038261, 'weight_decay': 0.00018129427560801756, 'scheduler': 'cosine'}. Best is trial 11 with value: 1.1491274542581467.\n",
      "[I 2025-04-18 06:15:48,765] Trial 12 finished with value: 1.149548342750186 and parameters: {'base_ch': 16, 'num_blocks': 2, 'dropout': 0.0, 'lr': 0.004386619498240078, 'weight_decay': 0.0001306421185630708, 'scheduler': 'cosine'}. Best is trial 11 with value: 1.1491274542581467.\n",
      "[I 2025-04-18 06:19:54,511] Trial 13 pruned. \n",
      "[I 2025-04-18 06:24:05,645] Trial 14 pruned. \n",
      "[I 2025-04-18 06:39:14,341] Trial 15 finished with value: 1.2030892462957472 and parameters: {'base_ch': 16, 'num_blocks': 2, 'dropout': 0.0, 'lr': 0.0019032926891134198, 'weight_decay': 0.00018756454956532387, 'scheduler': 'cosine'}. Best is trial 11 with value: 1.1491274542581467.\n",
      "[I 2025-04-18 06:43:21,874] Trial 16 pruned. \n",
      "[I 2025-04-18 06:58:21,945] Trial 17 finished with value: 1.1697239992050898 and parameters: {'base_ch': 16, 'num_blocks': 2, 'dropout': 0.0, 'lr': 0.0018973483192872914, 'weight_decay': 0.0002226109945284175, 'scheduler': 'cosine'}. Best is trial 11 with value: 1.1491274542581467.\n",
      "[I 2025-04-18 07:02:27,217] Trial 18 pruned. \n",
      "[I 2025-04-18 07:17:45,955] Trial 19 finished with value: 1.1319665959221976 and parameters: {'base_ch': 48, 'num_blocks': 2, 'dropout': 0.0, 'lr': 0.004962634598036981, 'weight_decay': 0.00029373701980247907, 'scheduler': 'cosine'}. Best is trial 19 with value: 1.1319665959221976.\n",
      "[I 2025-04-18 07:33:12,692] Trial 20 finished with value: 1.132618492308117 and parameters: {'base_ch': 48, 'num_blocks': 2, 'dropout': 0.0, 'lr': 0.002606446258927404, 'weight_decay': 0.0003170082722100362, 'scheduler': 'cosine'}. Best is trial 19 with value: 1.1319665959221976.\n",
      "[I 2025-04-18 07:48:45,272] Trial 21 finished with value: 1.140421803292774 and parameters: {'base_ch': 48, 'num_blocks': 2, 'dropout': 0.0, 'lr': 0.002708485307324439, 'weight_decay': 0.0002597352763053513, 'scheduler': 'cosine'}. Best is trial 19 with value: 1.1319665959221976.\n",
      "[I 2025-04-18 08:04:07,824] Trial 22 finished with value: 1.1326953181766328 and parameters: {'base_ch': 48, 'num_blocks': 2, 'dropout': 0.0, 'lr': 0.0025632404370484535, 'weight_decay': 0.00034366880370073004, 'scheduler': 'cosine'}. Best is trial 19 with value: 1.1319665959221976.\n"
     ]
    }
   ],
   "source": [
    "epochs = 22\n",
    "study = optuna.create_study(direction=\"minimize\",\n",
    "                                pruner=optuna.pruners.MedianPruner(n_startup_trials=4, n_warmup_steps=5))\n",
    "study.optimize(objective, n_trials=25, timeout=None)   # adjust n_trials as GPU budget allows\n",
    "\n",
    "print(\"Best value :\", study.best_value)\n",
    "print(\"Best params:\", study.best_params)\n",
    "\n",
    "# save weights\n",
    "best_state_dict = study.best_trial.user_attrs[\"state_dict\"]\n",
    "torch.save(best_state_dict, \"best_resnet_rawP.pth\")\n",
    "print(\"Saved best model ➜ best_resnet_rawP.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoE_ResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Mixture-of-Experts with hard gating, using ResNet2DWithParams as each expert.\n",
    "    Routes each sample to exactly one ResNet expert based on its (n, k) params.\n",
    "    \"\"\"\n",
    "    def __init__(self, unique_nk_pairs, expert_config, params_size=3):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            unique_nk_pairs (list[tuple]): List of distinct (n, k) tuples in your dataset.\n",
    "            expert_config (dict): kwargs for ResNet2DWithParams \n",
    "                                  (e.g. {'k_max':6,'nk_max':6,'n_params':3,'base_ch':32,'num_blocks':3}).\n",
    "            params_size (int):   Dimensionality of the params vector (should match n_params in expert_config).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        if not unique_nk_pairs:\n",
    "            raise ValueError(\"unique_nk_pairs cannot be empty.\")\n",
    "\n",
    "        # Sort and de-dupe\n",
    "        self.unique_nk_pairs = sorted(set(unique_nk_pairs))\n",
    "        self.num_experts     = len(self.unique_nk_pairs)\n",
    "        self.params_size     = params_size\n",
    "\n",
    "        # Map each (n,k) to an expert index\n",
    "        self.nk_to_expert_idx = {\n",
    "            pair: idx for idx, pair in enumerate(self.unique_nk_pairs)\n",
    "        }\n",
    "\n",
    "        # Instantiate one ResNet expert per (n,k)\n",
    "        self.experts = nn.ModuleList([\n",
    "            ResNet2DWithParams(**expert_config)\n",
    "            for _ in range(self.num_experts)\n",
    "        ])\n",
    "\n",
    "\n",
    "    def forward(self, p_matrix, params):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            p_matrix (Tensor): shape (batch, max_k, max_nk)\n",
    "            params   (Tensor): shape (batch, params_size), with params[:,0]=n, params[:,1]=k, params[:,2]=m\n",
    "\n",
    "        Returns:\n",
    "            Tensor of shape (batch, 1): each row is the output of the single chosen expert.\n",
    "        \"\"\"\n",
    "        batch_size = params.size(0)\n",
    "        device     = params.device\n",
    "\n",
    "        # --- 1) Determine expert index per sample ---\n",
    "        n_vals = params[:, 0].long().tolist()\n",
    "        k_vals = params[:, 1].long().tolist()\n",
    "        try:\n",
    "            expert_indices = [ self.nk_to_expert_idx[(n,k)]\n",
    "                               for n,k in zip(n_vals, k_vals) ]\n",
    "        except KeyError as e:\n",
    "            raise KeyError(f\"Unknown (n,k) pair {e} – not in unique_nk_pairs {self.unique_nk_pairs}.\")\n",
    "\n",
    "        expert_idx_tensor = torch.tensor(expert_indices, dtype=torch.long, device=device)\n",
    "        # shape (batch,)\n",
    "\n",
    "        # --- 2) Compute every expert’s output on the full batch ---\n",
    "        all_outputs = []\n",
    "        for expert in self.experts:\n",
    "            out = expert(p_matrix, params)   # ➞ (batch, 1)\n",
    "            all_outputs.append(out)\n",
    "\n",
    "        # stack ⇒ (batch, num_experts, 1)\n",
    "        stacked = torch.stack(all_outputs, dim=1)\n",
    "\n",
    "        # --- 3) Gather the chosen expert’s output per sample ---\n",
    "        # build an index tensor of shape (batch,1,1)\n",
    "        idx = expert_idx_tensor.unsqueeze(1).unsqueeze(2)\n",
    "        idx = idx.expand(-1, 1, stacked.size(2))  # (batch,1,1)\n",
    "\n",
    "        # gather along dim=1, then squeeze\n",
    "        selected = torch.gather(stacked, 1, idx).squeeze(1)  # (batch,1)\n",
    "\n",
    "        return selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training cell for hard‐gated MoE_ResNet ---------------\n",
    "\n",
    "# 1) configure hyper‐parameters\n",
    "# (make sure you have `unique_nk_pairs`, e.g. from your dataset)\n",
    "# unique_nk_pairs = sorted(set((int(p[0]), int(p[1])) for _, p in train_dataset))\n",
    "k_max, nk_max   = max_k, max_nk\n",
    "n_params        = 3\n",
    "base_ch, n_blocks = 32, 3\n",
    "epochs_hard     = 30\n",
    "lr_hard         = 3e-4\n",
    "wd_hard         = 1e-4\n",
    "\n",
    "unique_nk_pairs = sorted([\n",
    "    (9, 4), (9, 5), (9, 6),\n",
    "    (10, 4), (10, 5), (10, 6)\n",
    "])\n",
    "\n",
    "# 2) instantiate hard‐gated MoE with ResNet experts\n",
    "moe_model_hard = MoE_ResNet(\n",
    "    unique_nk_pairs=unique_nk_pairs,\n",
    "    expert_config={\n",
    "        'k_max':   k_max,\n",
    "        'nk_max':  nk_max,\n",
    "        'n_params': n_params,\n",
    "        'base_ch':  base_ch,\n",
    "        'num_blocks': n_blocks\n",
    "    },\n",
    "    params_size=n_params\n",
    ").to(device)\n",
    "\n",
    "# 3) loss & optimizer\n",
    "criterion_hard = LogMSELoss()\n",
    "optimizer_hard = torch.optim.AdamW(\n",
    "    moe_model_hard.parameters(), lr=lr_hard, weight_decay=wd_hard\n",
    ")\n",
    "\n",
    "# 4) train & validate using your helper\n",
    "hard_train_losses, hard_val_losses = run_training(\n",
    "    model=moe_model_hard,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion_hard,\n",
    "    optimizer=optimizer_hard,\n",
    "    epochs=epochs_hard,\n",
    "    device=device,\n",
    "    model_name=\"MoE_ResNet_HardGate\"\n",
    ")\n",
    "\n",
    "# 5) record & plot\n",
    "results[\"MoE_ResNet_HardGate\"] = (hard_train_losses, hard_val_losses)\n",
    "plot_losses(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------    \n",
    "Below this line are the code of the PROJECT 1 where we tested 4 different base model with 420,000 total datas and then choose MoE to fine tune it.\n",
    "\n",
    "We achieve a cost of 1.3 on the validation set and 1.5 on the test set on average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a list of architecture we are going to test :\n",
    "- fully dense neural network\n",
    "- CNN\n",
    "- RNN using LSTM\n",
    "- RNN using GRU "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIrst of all, we are going to generate the dataset using a LP-based algorithm with the libraries PuLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Class definition LP_based_solution to generate data ---\n",
    "class LP_based_solution:\n",
    "    def __init__(self,n : int ,k : int,m : int):\n",
    "        \"\"\" \n",
    "        Initializes the LP_based_solution instance\n",
    "        Generates a generator matrix G  of dimension n,k  with k<n\n",
    "        with entries uniformly sampled from [-100, 100] (and ensuring no all-zeros columns)\n",
    "        \"\"\"\n",
    "        self.n = n\n",
    "        self.k = k\n",
    "        self.m = m\n",
    "        self.P = self.create_generator_matrix()\n",
    "\n",
    "    def create_generator_matrix(self):\n",
    "        \"\"\" \n",
    "        Create the P matrix, which is a k x (n-k) matrix with entries sampled uniformly from [-100, 100].\n",
    "\n",
    "        Ensures that no column of P is the all-zero vector.\n",
    "\n",
    "        return:\n",
    "            P : (k x (n-k)) numpy array\n",
    "        \"\"\"\n",
    "        P = np.random.uniform(-100, 100, (self.k, self.n - self.k))\n",
    "        if np.any(np.all(P == 0, axis = 0)):\n",
    "            for j in range(P.shape[1]):\n",
    "                while np.allclose(P[:, j], 0):\n",
    "                    P[:, j] = np.random.uniform(-100, 100, self.k)\n",
    "\n",
    "        return P # we only need P to form G and train the model, so we don't concatenate with identity matrix\n",
    "    \n",
    "    def build_lp_problem(self, G, a, b, X, psi, k, m, s, Y):\n",
    "        \"\"\"\n",
    "        Build and return a PuLP LP problem for a given tuple (a, b, X, psi).\n",
    "\n",
    "        Args: \n",
    "            G   : The full generator matrix [I_k | P].\n",
    "            a   : An index chosen as the first element in the quasi-sorted order.\n",
    "            b   : An index chosen to occupy the m-th position.\n",
    "            X   : A tuple (list) of indices of size m-1.\n",
    "            psi : A tuple of m signs (s_0, s_1, ..., s_{m-1}).\n",
    "            k   : The dimension of the code (number of rows in G)\n",
    "            m   : The height parameter (position of b in the quasi-sorted order)\n",
    "            s   : A tuple of m signs (s_0, s_1, ..., s_{m-1})\n",
    "            Y   : A tuple (list) of indices not in {a} U X U {b}\n",
    "\n",
    "        Returns:\n",
    "            prob: A PuLP LP problem instance with the defined objective and constraints.\n",
    "        \"\"\"\n",
    "\n",
    "        # --- Define the LP problem using PuLP ---\n",
    "        X_str = '_'.join(map(str, X))\n",
    "        psi_str = '_'.join(map(str, psi))\n",
    "        prob = pulp.LpProblem(f\"LP_{a}_{b}_{X_str}_{psi_str}\", pulp.LpMaximize)\n",
    "            \n",
    "\n",
    "        # Define variable u_0, ..., u_{k-1}\n",
    "        u_vars = pulp.LpVariable.dicts(\"u\", range(k))\n",
    "\n",
    "        # Define objective function: maximize sum(s_0 * g_ia * ui) for i in k\n",
    "        objective = pulp.lpSum(s[0] * G[i, a] * u_vars[i] for i in range(k))\n",
    "        prob += objective\n",
    "\n",
    "        # --- Add Constraints ---\n",
    "        # Constraint 1: sum((s_{tau_inv(j)}*g_ij - s_0*g_ia)*ui) <= 0 for j in X\n",
    "        # Constraint 2: sum((-s_{tau_inv(j)}*g_ij)*ui) <= -1 for j in X\n",
    "        # Map X indices to s indices (s_1 to s_{m-1})\n",
    "        X_sorted = sorted(X)\n",
    "        s_map_X = {X_sorted[idx]: s[idx+1] for idx in range(m-1)}\n",
    "\n",
    "        for j in X:\n",
    "            s_j = s_map_X[j] # Get the s value corresponding to index j in X\n",
    "            # Constraint 1\n",
    "            prob += pulp.lpSum((s_j * G[i, j] - s[0] * G[i, a]) * u_vars[i] for i in range(k)) <= 0, f\"Constraint1_j{j}\"\n",
    "            # Constraint 2\n",
    "            prob += pulp.lpSum((s_j * G[i, j]) * u_vars[i] for i in range(k)) <= -1, f\"Constraint2_j{j}\"\n",
    "\n",
    "        # Constraint 3: sum(g_ib * ui) = 1\n",
    "        prob += pulp.lpSum(G[i, b] * u_vars[i] for i in range(k)) == 1, \"Constraint3_b\"\n",
    "\n",
    "        # Constraint 4: sum(g_ij * ui) <= 1 for j in Y\n",
    "        # Constraint 5: sum(-g_ij * ui) <= 1 for j in Y\n",
    "        for j in Y:\n",
    "            prob += pulp.lpSum(G[i, j] * u_vars[i] for i in range(k)) <= 1, f\"Constraint4_j{j}\"\n",
    "            prob += pulp.lpSum(-G[i, j] * u_vars[i] for i in range(k)) <= 1, f\"Constraint5_j{j}\"\n",
    "\n",
    "        return prob\n",
    "\n",
    "    def calculate_m_height(self, num_cores = 1):\n",
    "        \"\"\"\n",
    "        Compute the m-height of the analog code given the generator matrix G by using linear programming\n",
    "\n",
    "        \"\"\"\n",
    "        # Initialization of parameters\n",
    "        n, k, m = self.n, self.k, self.m\n",
    "        P = self.P\n",
    "\n",
    "        # --- Construct of the full G matrix ---\n",
    "        identity_k = np.identity(k)\n",
    "        G = np.hstack([identity_k, P])\n",
    "\n",
    "        max_objective_found = 1.0\n",
    "        lp_tasks = []\n",
    "\n",
    "        indices = list(range(n)) # we create an array of integers from 0 to n-1 : [0, 1, ..., n-1]\n",
    "        try: \n",
    "            for a in indices : # a is an index respresenting a column in G            \n",
    "                indices_minus_a = [idx for idx in indices if idx != a]\n",
    "                for b in indices_minus_a: # b is another column index different from a\n",
    "                    indices_minus_ab = [idx for idx in indices_minus_a if idx != b]\n",
    "\n",
    "                    # Check if enought elements remain for X\n",
    "                    if len(indices_minus_ab) < m - 1:\n",
    "                        continue # cannot form X of size m-1\n",
    "                    \n",
    "                    for X_tuple in itertools.combinations(indices_minus_ab, m - 1):\n",
    "                        # create an array of size m-1 \n",
    "                        X = list(X_tuple)\n",
    "                        # ~ not logical and np.isin to exclude every values of X from the set_excluded_ab\n",
    "                        Y = [idx for idx in indices_minus_ab if idx not in X]\n",
    "\n",
    "                        for psi in itertools.product([-1, 1], repeat = m):\n",
    "                            s = list(psi) # s = [s_0, s_1, ..., s_{m-1}]\n",
    "                            \n",
    "                            # --- Solve the LP ---\n",
    "                            prob = self.build_lp_problem(G, a, b, X, psi, k, m, s, Y)\n",
    "                            status = prob.solve(pulp.PULP_CBC_CMD(msg=0)) # suppress the messages of pulp\n",
    "\n",
    "                            # --- Check Status and Update Max Objective ---\n",
    "                            if status == pulp.LpStatusOptimal:\n",
    "                                current_z = pulp.value(prob.objective)\n",
    "                                if current_z > max_objective_found:\n",
    "                                    max_objective_found = current_z\n",
    "                            elif status == pulp.LpStatusUnbounded:\n",
    "                                # If any LP is unbounded, the m-height is infinite for this G\n",
    "                                print(f\"Unbounded LP found for G with (n={n},k={k},m={m}), tuple ({a},{b},{X},{psi}). Skipping this G.\")\n",
    "                                return (None, None) # Signal to skip this P matrix\n",
    "                            elif status == pulp.LpStatusInfeasible:\n",
    "                                # This doesn't affect the max unless all others are also infeasible.\n",
    "                                pass \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during LP solving for (n={n},k={k},m={m}): {e}\")\n",
    "            # if we have an error skip this P matrix\n",
    "            return (None, None)\n",
    "\n",
    "        # After checking all tuples\n",
    "        if max_objective_found < 1: \n",
    "             # m-height should be >= 1. If max_objective_found remains at initial 0 or < 1 (e.g. all infeasible)\n",
    "             # This might indicate an issue or edge case. The definition implies h_m >= h_0 = 1.\n",
    "             # Let's default to 1 if the max calculated is less than 1, although this needs verification.\n",
    "             # A safer bet might be to return None and investigate these cases.\n",
    "             print(f\"Warning: Max objective found ({max_objective_found}) < 1 for (n={n},k={k},m={m}). Check calculation/definition. Returning None.\")\n",
    "             return (None, None) # Or consider returning 1.0 if appropriate.\n",
    "\n",
    "        return (P,max_objective_found) # Return the overall maximum finite objective value found   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- def function to store the data generated by the LP class in a .npz file ---\n",
    "def save_partial_data_npz(P_list, h_list, n, k, m, base_filename=\"m_height_data\"):\n",
    "    \"\"\"\n",
    "    Saves generated P matrices and h_m values to a uniquely named .npz file.\n",
    "    Includes n, k, m values in the saved file.\n",
    "\n",
    "    Args:\n",
    "        P_list (list): List of generated P matrices (NumPy arrays).\n",
    "        h_list (list): List of corresponding h_m values (floats).\n",
    "        n (int): n parameter used for generation.\n",
    "        k (int): k parameter used for generation.\n",
    "        m (int): m parameter used for generation.\n",
    "        base_filename (str): Base name for the output file.\n",
    "    \"\"\"\n",
    "    if not P_list or not h_list:\n",
    "        print(\"No data generated in this run, nothing to save.\")\n",
    "        return\n",
    "\n",
    "    # Convert lists to NumPy arrays\n",
    "    P_array = np.array(P_list)\n",
    "    h_array = np.array(h_list)\n",
    "\n",
    "    # Create arrays for parameters (for consistent storage in npz)\n",
    "    n_array = np.array([n])\n",
    "    k_array = np.array([k])\n",
    "    m_array = np.array([m])\n",
    "\n",
    "    # Generate a unique filename to avoid overwrites\n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"{base_filename}_n{n}_k{k}_m{m}_{timestamp}.npz\"\n",
    "\n",
    "    try:\n",
    "        # Save the arrays to a compressed .npz file\n",
    "        np.savez_compressed(\n",
    "            filename,\n",
    "            P_matrices=P_array,\n",
    "            h_values=h_array,\n",
    "            n_val=n_array, # Save n, k, m\n",
    "            k_val=k_array,\n",
    "            m_val=m_array\n",
    "        )\n",
    "        print(f\"\\nPartial dataset saved successfully to {filename}\")\n",
    "        print(f\"Saved {len(h_array)} samples from this run.\")\n",
    "        print(f\"Shape of P_matrices array: {P_array.shape}\")\n",
    "        print(f\"Shape of h_values array: {h_array.shape}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError saving data to {filename}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Iterate through parameter combinations and generate data ---\n",
    "\n",
    "# Define parameter ranges\n",
    "n_values = [9, 10]\n",
    "k_values = [4, 5, 6]\n",
    "# Define how many samples PER (n, k, m) combination\n",
    "samples_per_combination = 100  # for ~3000 we have 63000 data and for 100 we have 2100 data\n",
    "\n",
    "total_expected_combinations = 0\n",
    "parameter_combinations = []\n",
    "\n",
    "# Pre-calculate valid combinations and total count\n",
    "print(\"Calculating valid (n, k, m) combinations...\")\n",
    "for n_val in n_values:\n",
    "    for k_val in k_values:\n",
    "        if k_val >= n_val: # Ensure k < n\n",
    "            continue\n",
    "        # m ranges from 2 to n-k inclusive\n",
    "        min_m = 2\n",
    "        max_m = n_val - k_val\n",
    "        if max_m >= min_m:\n",
    "            for m_val in range(min_m, max_m + 1):\n",
    "                 # Additional check from the paper's definition: m-1 <= n-2 -> m <= n-1\n",
    "                 # This is usually covered by m <= n-k, but good to be explicit\n",
    "                 if m_val <= n_val -1 :\n",
    "                    parameter_combinations.append((n_val, k_val, m_val))\n",
    "                    total_expected_combinations += 1\n",
    "\n",
    "print(f\"Found {total_expected_combinations} valid combinations to generate data for.\")\n",
    "print(f\"Generating {samples_per_combination} samples per combination.\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- Main Generation Loop ---\n",
    "run_counter = 0\n",
    "for n_val, k_val, m_val in parameter_combinations:\n",
    "    run_counter += 1\n",
    "    print(f\"\\nStarting Run {run_counter}/{total_expected_combinations}: n={n_val}, k={k_val}, m={m_val}\")\n",
    "\n",
    "    # Initialize lists for this specific combination\n",
    "    dataset_P_current = []\n",
    "    dataset_h_current = []\n",
    "    samples_generated_this_run = 0\n",
    "\n",
    "    start_time_run = time.time()\n",
    "\n",
    "    while samples_generated_this_run < samples_per_combination:\n",
    "        # Create a new solver instance for each sample to get a new random P\n",
    "        try:\n",
    "            solver_instance = LP_based_solution(n_val, k_val, m_val)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError initializing LP_based_solution for ({n_val},{k_val},{m_val}): {e}. Skipping combination.\")\n",
    "            # Break this inner while loop and go to the next (n,k,m) combo\n",
    "            dataset_P_current = [] # Ensure no data is saved for this failed combo\n",
    "            dataset_h_current = []\n",
    "            break\n",
    "\n",
    "        # Calculate m-height for the P matrix in this instance\n",
    "        try:\n",
    "            P_matrix, h_m = solver_instance.calculate_m_height()\n",
    "        except Exception as e:\n",
    "             print(f\"\\nUnhandled error in calculate_m_height for ({n_val},{k_val},{m_val}): {e}. Skipping sample.\")\n",
    "             h_m = None # Treat as failure for this sample\n",
    "\n",
    "        if h_m is not None:\n",
    "            # Optional: Add sanity check for very large values if needed\n",
    "            if h_m > 1e7:\n",
    "                print(f\"Warning: Large m-height {h_m} found for ({n_val},{k_val},{m_val}). Skipping sample.\")\n",
    "                continue # Skip this sample\n",
    "\n",
    "            # Use the P matrix associated with the successful calculation\n",
    "            dataset_P_current.append(solver_instance.P) # Append the P matrix that yielded h_m\n",
    "            dataset_h_current.append(h_m)\n",
    "            samples_generated_this_run += 1\n",
    "            print(f\"Run {run_counter}: Sample {samples_generated_this_run}/{samples_per_combination} -> h_m = {h_m:.4f}   \", end='\\r')\n",
    "\n",
    "        else: # If h_m is None (unbounded, error, obj<1)\n",
    "            # Skip this matrix and continue to generate a new one\n",
    "            # print(f\"Skipped sample for Run {run_counter} due to invalid h_m. Generating new matrix...\", end='\\r')\n",
    "            continue\n",
    "\n",
    "    end_time_run = time.time()\n",
    "    duration_run = end_time_run - start_time_run\n",
    "    print(f\"\\nFinished Run {run_counter} ({n_val},{k_val},{m_val}). Generated {samples_generated_this_run} samples in {duration_run:.2f} seconds.\")\n",
    "\n",
    "    # --- Save the data collected in this run ---\n",
    "    if samples_generated_this_run > 0:\n",
    "        save_partial_data_npz(dataset_P_current, dataset_h_current, n_val, k_val, m_val)\n",
    "    else:\n",
    "        print(f\"No valid samples generated for Run {run_counter}, skipping save.\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "print(\"\\nAll parameter combinations processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculated m-height for the specific G: h_2 = 1.9242386\n"
     ]
    }
   ],
   "source": [
    "# --- Example usage of the LP solution on the example provided in the instruction pdf ---\n",
    "G_test = np.array([\n",
    "    [1, 0, 0.4759809, 0.9938236, 0.819425],\n",
    "    [0, 1, -0.8960798, -0.7442706, 0.3345122]\n",
    "])\n",
    "\n",
    "k_test = G_test.shape[0] # 2\n",
    "n_test = G_test.shape[1] # 5\n",
    "m_test = 2\n",
    "\n",
    "P_test = G_test[:, k_test:]\n",
    "solver_test = LP_based_solution(n=n_test, k=k_test, m=m_test)\n",
    "solver_test.P = P_test\n",
    "\n",
    "P_result, h_m_result = solver_test.calculate_m_height()\n",
    "if h_m_result is not None:\n",
    "    print(f\"\\nCalculated m-height for the specific G: h_{m_test} = {h_m_result:.7f}\")\n",
    "else:\n",
    "    print(\"\\nCalculation failed for the specific G (unbounded, error, or h_m < 1).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we got \"Calculated m-height for the specific G: h_2 = 1.9242386\"  meaning the LP-based algorithm should work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sample 1/1 for (n=9, k=4, m=2) -> h_m = 223.6242 with P = [[-56.78169812  19.61006987  57.36989704 -58.13407204  10.38663567]\n",
      " [ 92.02518455 -46.76778659  90.76362264 -17.30368471 -53.82621988]\n",
      " [ 51.14222307 -46.99184709  94.49832538  90.73061774 -54.09476517]\n",
      " [ 23.31461216 -35.81438581 -94.35229399  53.80837945  -9.45712277]]\n"
     ]
    }
   ],
   "source": [
    "# --- Example use on a random generated P matrix ---\n",
    "n_val, k_val, m_val = 9, 4, 2 \n",
    "solver = LP_based_solution(n_val, k_val, m_val)\n",
    "\n",
    "dataset_P = []\n",
    "dataset_h = []\n",
    "num_samples_needed = 1 \n",
    "\n",
    "while len(dataset_h) < num_samples_needed:\n",
    "    P_matrix, h_m = solver.calculate_m_height()\n",
    "\n",
    "    if h_m is not None: # Check if m-height is finite and calculation succeeded\n",
    "         # Check if h_m is realistic (e.g., not excessively large if unexpected)\n",
    "         if h_m > 1e6: # Example threshold for sanity check\n",
    "             print(f\"Warning: Large m-height {h_m} found. May be correct or indicate issue.\")\n",
    "\n",
    "         dataset_P.append(P_matrix)\n",
    "         dataset_h.append(h_m)\n",
    "         print(f\"Generated sample {len(dataset_h)}/{num_samples_needed} for (n={n_val}, k={k_val}, m={m_val}) -> h_m = {h_m:.4f} with P = {P_matrix}\")\n",
    "\n",
    "    else:\n",
    "        print(\"Skipped a P matrix due to infinite m-height or error.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to create one set of P_matrix with n = 9 and k = 4 and its results for m = 2 take around 1m30 in average and 9min for m = 3. We can see why we want to use a deep neural network to resolve this problem instead of LP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, it is very computational to generate data, that why, I decided to use HPRC to generate those data, the cell below is used for HPRC jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LP-based algorithm and storage function data generation for HPRC with different number of sample per combinations---\n",
    "# --- Class Definition ---\n",
    "# create_generator_matrix, build_lp_problem, and the parallel calculate_m_height)\n",
    "class LP_based_solution:\n",
    "    def __init__(self,n : int ,k : int,m : int):\n",
    "        \"\"\" Initializes... \"\"\"\n",
    "        self.n = n\n",
    "        self.k = k\n",
    "        self.m = m\n",
    "        if not (k < n and 2 <= m <= n - k and m <= n - 1):\n",
    "             raise ValueError(f\"Invalid parameters: n={n}, k={k}, m={m}\")\n",
    "        self.P = self.create_generator_matrix()\n",
    "\n",
    "    def create_generator_matrix(self):\n",
    "        \"\"\" Create the P matrix... \"\"\"\n",
    "        if self.n - self.k <= 0:\n",
    "            raise ValueError(f\"n-k must be > 0, got n={self.n}, k={self.k}\")\n",
    "        P = np.random.uniform(-100, 100, (self.k, self.n - self.k))\n",
    "        # Ensure no all-zero columns if n-k > 0\n",
    "        if P.shape[1] > 0 and np.any(np.all(P == 0, axis=0)):\n",
    "            for j in range(P.shape[1]):\n",
    "                while np.allclose(P[:, j], 0):\n",
    "                    if self.k <= 0:\n",
    "                         raise ValueError(f\"k must be > 0, got k={self.k}\")\n",
    "                    P[:, j] = np.random.uniform(-100, 100, self.k)\n",
    "        return P\n",
    "\n",
    "    def build_lp_problem(self, G, a, b, X, psi, k, m, s, Y):\n",
    "        \"\"\" Build and return a PuLP LP problem... \"\"\"\n",
    "        X_str = '_'.join(map(str, X)); psi_str = '_'.join(map(str, psi))\n",
    "        prob_name = f\"LP_{a}_{b}_{X_str}_{psi_str}\"; prob = pulp.LpProblem(prob_name, pulp.LpMaximize)\n",
    "        u_vars = pulp.LpVariable.dicts(\"u\", range(k)); objective = pulp.lpSum(s[0] * G[i, a] * u_vars[i] for i in range(k)); prob += objective\n",
    "        X_sorted = sorted(X)\n",
    "        if m-1 < 0: raise ValueError(f\"m must be >= 1, got m={m}\")\n",
    "        s_map_X = {X_sorted[idx]: s[idx+1] for idx in range(m-1)}\n",
    "        for j in X:\n",
    "            s_j = s_map_X[j]\n",
    "            prob += pulp.lpSum((s_j * G[i, j] - s[0] * G[i, a]) * u_vars[i] for i in range(k)) <= 0, f\"Constraint1_j{j}\"\n",
    "            # Original constraint 2 was sum((-s_j * G[i, j]) * u_vars[i] for i in range(k)) <= -1\n",
    "            # Let's ensure we use the correct s_j for the second constraint as well\n",
    "            prob += pulp.lpSum((-s_j * G[i, j]) * u_vars[i] for i in range(k)) <= -1, f\"Constraint2_j{j}\"\n",
    "        prob += pulp.lpSum(G[i, b] * u_vars[i] for i in range(k)) == 1, \"Constraint3_b\"\n",
    "        for j in Y:\n",
    "            prob += pulp.lpSum(G[i, j] * u_vars[i] for i in range(k)) <= 1, f\"Constraint4_j{j}\"\n",
    "            prob += pulp.lpSum(-G[i, j] * u_vars[i] for i in range(k)) <= 1, f\"Constraint5_j{j}\"\n",
    "        return prob\n",
    "\n",
    "    def calculate_m_height(self, num_cores=1):\n",
    "        \"\"\" Compute m-height using multiprocessing for LP solves \"\"\"\n",
    "        n, k, m = self.n, self.k, self.m\n",
    "        P = self.P\n",
    "        identity_k = np.identity(k); G = np.hstack([identity_k, P])\n",
    "        max_objective_found = 1.0; lp_tasks = []\n",
    "        indices = list(range(n))\n",
    "        try:\n",
    "            for a in indices:\n",
    "                indices_minus_a = [idx for idx in indices if idx != a]\n",
    "                for b in indices_minus_a:\n",
    "                    indices_minus_ab = [idx for idx in indices_minus_a if idx != b]\n",
    "                    if len(indices_minus_ab) < m - 1: continue\n",
    "                    for X_tuple in itertools.combinations(indices_minus_ab, m - 1):\n",
    "                        X = list(X_tuple); Y = [idx for idx in indices_minus_ab if idx not in X]\n",
    "                        for psi in itertools.product([-1, 1], repeat=m):\n",
    "                            s = list(psi); lp_tasks.append((G, a, b, X, psi, k, m, s, Y))\n",
    "            if not lp_tasks: return (None, None)\n",
    "        except Exception as e: print(f\"Error generating LP tasks: {e}\"); return (None, None)\n",
    "\n",
    "        results = []\n",
    "        cores_to_actually_use = max(1, num_cores) # Ensure at least 1 core\n",
    "        try:\n",
    "            # print(f\"DEBUG: Using {cores_to_actually_use} cores for pool\") # Debug print\n",
    "            with multiprocessing.Pool(processes=cores_to_actually_use) as pool:\n",
    "                 results = pool.starmap(_solve_single_lp_task, lp_tasks)\n",
    "        except Exception as pool_e:\n",
    "             print(f\"Multiprocessing error ({pool_e}) with {cores_to_actually_use} cores. Try reducing cores?\")\n",
    "             # Fallback or re-raise depending on desired behavior\n",
    "             return(None, None) # Or raise pool_e\n",
    "\n",
    "        found_unbounded = False\n",
    "        optimal_values = []\n",
    "        for status, value in results:\n",
    "            if status == pulp.LpStatusUnbounded:\n",
    "                found_unbounded = True\n",
    "                # print(f\"DEBUG: Unbounded found\") # Debug print\n",
    "                break\n",
    "            elif status == pulp.LpStatusOptimal and value is not None:\n",
    "                optimal_values.append(value)\n",
    "\n",
    "        if found_unbounded:\n",
    "            # print(f\"DEBUG: Returning None due to unbounded\") # Debug print\n",
    "            return (None, None)\n",
    "\n",
    "        if not optimal_values: # If no optimal solutions were found (all infeasible/error?)\n",
    "             # print(f\"DEBUG: Returning None due to no optimal values\") # Debug print\n",
    "             max_objective_found = 1.0 # Reset to default, will trigger None below\n",
    "        else:\n",
    "             max_objective_found = max(optimal_values) if optimal_values else 1.0\n",
    "\n",
    "        # Check if max is still 1.0 (or very close) or less than 1.0\n",
    "        if np.isclose(max_objective_found, 1.0) or max_objective_found < 1.0:\n",
    "            # print(f\"DEBUG: Returning None, max_obj={max_objective_found}\") # Debug print\n",
    "            return (None, None)\n",
    "\n",
    "        # print(f\"DEBUG: Returning P and h_m={max_objective_found}\") # Debug print\n",
    "        return (P, max_objective_found)\n",
    "\n",
    "\n",
    "# --- Worker function (Top Level) ---\n",
    "# (Ensure this is defined at the top level for multiprocessing)\n",
    "def _solve_single_lp_task(G, a, b, X, psi, k, m, s, Y):\n",
    "    try:\n",
    "        if k <= 0: return pulp.LpStatusUndefined, None # Avoid error in identity(k)\n",
    "        # Temporarily create an instance to call the build method\n",
    "        temp_solver = LP_based_solution(n=G.shape[1], k=k, m=m)\n",
    "        prob = temp_solver.build_lp_problem(G, a, b, X, psi, k, m, s, Y)\n",
    "\n",
    "        # Solve the problem\n",
    "        status = prob.solve(pulp.PULP_CBC_CMD(msg=0))\n",
    "        value = None\n",
    "        if status == pulp.LpStatusOptimal:\n",
    "            value = pulp.value(prob.objective)\n",
    "        # print(f\"DEBUG worker: status={status}, value={value}\") # Debug print\n",
    "        return status, value\n",
    "    except ValueError as ve: # Catch specific init errors\n",
    "        # print(f\"DEBUG Worker ValueError: {ve}\") # Debug print\n",
    "        return pulp.LpStatusUndefined, None\n",
    "    except Exception as e:\n",
    "        # print(f\"DEBUG Worker error for {a},{b},{X},{psi}: {e}\") # Debug print\n",
    "        return pulp.LpStatusUndefined, None # Indicate failure\n",
    "\n",
    "\n",
    "# --- Saving Function ---\n",
    "def save_partial_data_npz(P_list, h_list, n, k, m, output_dir=\"data\", base_filename=\"m_height_data\"):\n",
    "    \"\"\"\n",
    "    Saves generated P matrices and h_m values to a uniquely named .npz file\n",
    "    inside the specified output directory.\n",
    "    Includes n, k, m values in the saved file.\n",
    "    \"\"\"\n",
    "    if not P_list or not h_list:\n",
    "        print(\"No data generated in this run, nothing to save.\")\n",
    "        return\n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    try:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    except OSError as e:\n",
    "        print(f\"\\nError creating output directory '{output_dir}': {e}. Cannot save file.\")\n",
    "        return\n",
    "\n",
    "    # Convert lists to NumPy arrays\n",
    "    P_array = np.array(P_list)\n",
    "    h_array = np.array(h_list)\n",
    "    n_array = np.array([n])\n",
    "    k_array = np.array([k])\n",
    "    m_array = np.array([m])\n",
    "\n",
    "    # Generate a unique filename\n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    unique_id = str(uuid.uuid4())[:8]\n",
    "    filename_base = f\"{base_filename}_n{n}_k{k}_m{m}_{timestamp}_{unique_id}.npz\"\n",
    "    full_filepath = os.path.join(output_dir, filename_base)\n",
    "\n",
    "    try:\n",
    "        # Save the arrays to the specified path\n",
    "        np.savez_compressed(\n",
    "            full_filepath,\n",
    "            P_matrices=P_array,\n",
    "            h_values=h_array,\n",
    "            n_val=n_array,\n",
    "            k_val=k_array,\n",
    "            m_val=m_array\n",
    "        )\n",
    "        print(f\"\\nPartial dataset saved successfully to {full_filepath}\")\n",
    "        print(f\"Saved {len(h_array)} samples from this run.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError saving data to {full_filepath}: {e}\")\n",
    "\n",
    "\n",
    "# --- Main Generation Logic ---\n",
    "\n",
    "# --- Parameters to Set Manually ---\n",
    "n_values = [9, 10]\n",
    "k_values = [4, 5, 6]\n",
    "# output_directory: Where to save the .npz files\n",
    "output_directory = \"generated_data_notebook_dynamic\"\n",
    "# num_cores_to_request: How many CPU cores to try and use for parallel processing\n",
    "# Uses multiprocessing.cpu_count() to get available cores by default.\n",
    "# You can manually set this to a specific number, e.g., num_cores_to_request = 8\n",
    "num_cores_to_request = multiprocessing.cpu_count()\n",
    "\n",
    "# --- Dynamic Sample Count Logic ---\n",
    "def get_target_samples(m_val):\n",
    "    \"\"\"Returns the target number of samples based on m.\"\"\"\n",
    "    if m_val >= 6:\n",
    "        return 50   # Smallest target for the slowest combinations (m=6 for n=10,k=4)\n",
    "    elif m_val == 5:\n",
    "        return 200  # Moderate target for m=5\n",
    "    elif m_val == 4:\n",
    "        return 500  # Higher target for m=4\n",
    "    else: # m_val == 2 or m_val == 3\n",
    "        return 1000 # Highest target for the fastest combinations\n",
    "    # --- ADJUST THESE TARGETS AS NEEDED ---\n",
    "\n",
    "# --- Pre-calculate combinations ---\n",
    "total_expected_combinations = 0\n",
    "parameter_combinations = []\n",
    "print(\"Calculating valid (n, k, m) combinations...\")\n",
    "for n_val_loop in n_values:\n",
    "    for k_val_loop in k_values:\n",
    "        if k_val_loop >= n_val_loop: continue\n",
    "        min_m = 2\n",
    "        max_m = n_val_loop - k_val_loop\n",
    "        if max_m >= min_m:\n",
    "            for m_val_loop in range(min_m, max_m + 1):\n",
    "                 if m_val_loop <= n_val_loop -1 :\n",
    "                    parameter_combinations.append((n_val_loop, k_val_loop, m_val_loop))\n",
    "                    total_expected_combinations += 1\n",
    "print(f\"Found {total_expected_combinations} valid combinations.\")\n",
    "\n",
    "# --- Determine Cores to Use ---\n",
    "available_cores = multiprocessing.cpu_count()\n",
    "num_cores_to_use = min(num_cores_to_request, available_cores)\n",
    "if num_cores_to_use <= 0:\n",
    "    print(\"Warning: Determined 0 or fewer cores to use. Defaulting to 1 core.\")\n",
    "    num_cores_to_use = 1\n",
    "print(f\"Attempting to use {num_cores_to_use} core(s) for parallel LP solves (Requested: {num_cores_to_request}, Available: {available_cores}).\")\n",
    "print(f\"Saving results in: {output_directory}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- Main Loop ---\n",
    "overall_start_time = time.time()\n",
    "run_counter = 0\n",
    "total_samples_generated_all_runs = 0\n",
    "\n",
    "for n_val, k_val, m_val in parameter_combinations:\n",
    "    run_counter += 1\n",
    "    target_samples_this_run = get_target_samples(m_val) # Get dynamic target\n",
    "\n",
    "    print(f\"\\nStarting Run {run_counter}/{total_expected_combinations}: n={n_val}, k={k_val}, m={m_val} (Target Samples: {target_samples_this_run})\")\n",
    "\n",
    "    dataset_P_current = []\n",
    "    dataset_h_current = []\n",
    "    samples_generated_this_run = 0\n",
    "    attempts = 0\n",
    "    # Adjust max attempts based on the *dynamic* target for this run\n",
    "    max_attempts = int(target_samples_this_run * 1.5) + 20 # Slightly more leeway\n",
    "\n",
    "    start_time_run = time.time()\n",
    "\n",
    "    # Loop until the dynamic target is met or max attempts are reached\n",
    "    while samples_generated_this_run < target_samples_this_run and attempts < max_attempts :\n",
    "        attempts += 1\n",
    "        try:\n",
    "            # Create a new instance for each attempt to get a new P matrix\n",
    "            solver_instance = LP_based_solution(n_val, k_val, m_val)\n",
    "            # Pass the determined num_cores_to_use\n",
    "            P_matrix_result, h_m = solver_instance.calculate_m_height(num_cores=num_cores_to_use)\n",
    "\n",
    "            if h_m is not None: # Check if calculation was successful and h_m >= 1\n",
    "                 # Store the P matrix *from the solver instance* that yielded the valid h_m\n",
    "                 dataset_P_current.append(solver_instance.P)\n",
    "                 dataset_h_current.append(h_m)\n",
    "                 samples_generated_this_run += 1\n",
    "                 # Update progress line using the dynamic target\n",
    "                 print(f\"Run {run_counter}: Sample {samples_generated_this_run}/{target_samples_this_run} -> h_m = {h_m:.4f} (Attempt {attempts})   \", end='\\r')\n",
    "            # else: # h_m is None (unbounded, error, or < 1), just continue to next attempt\n",
    "            #    pass # No print message for failed attempts to keep output cleaner\n",
    "\n",
    "        except ValueError as init_err:\n",
    "            # Error during __init__\n",
    "            print(f\"\\nError initializing LP_based_solution for run {run_counter} ({n_val},{k_val},{m_val}): {init_err}. Stopping this combination run.\")\n",
    "            dataset_P_current, dataset_h_current = [], [] # Clear partial data\n",
    "            break # Exit the inner 'while' loop for this combination\n",
    "        except Exception as e:\n",
    "             # Catch other unexpected errors during calculation\n",
    "             print(f\"\\nUnhandled error in run {run_counter} (attempt {attempts}) for ({n_val},{k_val},{m_val}): {type(e).__name__} - {e}. Continuing attempts.\")\n",
    "             # time.sleep(0.1) # Optional small pause\n",
    "\n",
    "    # --- Loop finished for this combination ---\n",
    "    end_time_run = time.time()\n",
    "    duration_run = end_time_run - start_time_run\n",
    "    print(\" \" * 90, end='\\r') # Clear the progress line before printing summary\n",
    "    print(f\"Finished Run {run_counter} ({n_val},{k_val},{m_val}). Generated {samples_generated_this_run} samples in {duration_run:.2f} seconds ({attempts} attempts).\")\n",
    "\n",
    "    if samples_generated_this_run < target_samples_this_run and attempts >= max_attempts:\n",
    "         print(f\"Warning: Reached max attempts ({max_attempts}) but only generated {samples_generated_this_run} / {target_samples_this_run} target samples.\")\n",
    "    elif samples_generated_this_run < target_samples_this_run:\n",
    "         print(f\"Warning: Only generated {samples_generated_this_run} out of {target_samples_this_run} target samples (may indicate initialization or calculation errors).\")\n",
    "\n",
    "    # --- Save data for this run (if any samples were generated) ---\n",
    "    if samples_generated_this_run > 0:\n",
    "        # Pass the manually set output directory\n",
    "        save_partial_data_npz(dataset_P_current, dataset_h_current, n_val, k_val, m_val, output_dir=output_directory)\n",
    "        total_samples_generated_all_runs += samples_generated_this_run\n",
    "    else:\n",
    "        print(f\"No valid samples generated for Run {run_counter}, skipping save.\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "overall_end_time = time.time()\n",
    "print(f\"\\nAll parameter combinations processed.\")\n",
    "print(f\"Total samples generated across all runs: {total_samples_generated_all_runs}\")\n",
    "print(f\"Total execution time: {overall_end_time - overall_start_time:.2f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LP-based algorithm data generation and storage function for HPRC ---\n",
    "# --- Class Definition ---\n",
    "class LP_based_solution:\n",
    "    def __init__(self,n : int ,k : int,m : int):\n",
    "        \"\"\" Initializes... \"\"\"\n",
    "        self.n = n\n",
    "        self.k = k\n",
    "        self.m = m\n",
    "        if not (k < n and 2 <= m <= n - k and m <= n - 1):\n",
    "             raise ValueError(f\"Invalid parameters: n={n}, k={k}, m={m}\")\n",
    "        self.P = self.create_generator_matrix()\n",
    "\n",
    "    def create_generator_matrix(self):\n",
    "        \"\"\" Create the P matrix... \"\"\"\n",
    "        if self.n - self.k <= 0:\n",
    "            raise ValueError(f\"n-k must be > 0, got n={self.n}, k={self.k}\")\n",
    "        P = np.random.uniform(-100, 100, (self.k, self.n - self.k))\n",
    "        if P.shape[1] > 0 and np.any(np.all(P == 0, axis = 0)):\n",
    "            for j in range(P.shape[1]):\n",
    "                while np.allclose(P[:, j], 0):\n",
    "                     if self.k <= 0:\n",
    "                          raise ValueError(f\"k must be > 0, got k={self.k}\")\n",
    "                     P[:, j] = np.random.uniform(-100, 100, self.k)\n",
    "        return P\n",
    "\n",
    "    def build_lp_problem(self, G, a, b, X, psi, k, m, s, Y):\n",
    "        \"\"\" Build and return a PuLP LP problem... \"\"\"\n",
    "        X_str = '_'.join(map(str, X))\n",
    "        psi_str = '_'.join(map(str, psi))\n",
    "        prob_name = f\"LP_{a}_{b}_{X_str}_{psi_str}\"\n",
    "        prob = pulp.LpProblem(prob_name, pulp.LpMaximize)\n",
    "        u_vars = pulp.LpVariable.dicts(\"u\", range(k))\n",
    "        objective = pulp.lpSum(s[0] * G[i, a] * u_vars[i] for i in range(k))\n",
    "        prob += objective\n",
    "        X_sorted = sorted(X)\n",
    "        if m-1 < 0: raise ValueError(f\"m must be >= 1, got m={m}\")\n",
    "        s_map_X = {X_sorted[idx]: s[idx+1] for idx in range(m-1)}\n",
    "        for j in X:\n",
    "            s_j = s_map_X[j]\n",
    "            prob += pulp.lpSum((s_j * G[i, j] - s[0] * G[i, a]) * u_vars[i] for i in range(k)) <= 0, f\"Constraint1_j{j}\"\n",
    "            prob += pulp.lpSum((-s_j * G[i, j]) * u_vars[i] for i in range(k)) <= -1, f\"Constraint2_j{j}\"\n",
    "        prob += pulp.lpSum(G[i, b] * u_vars[i] for i in range(k)) == 1, \"Constraint3_b\"\n",
    "        for j in Y:\n",
    "            prob += pulp.lpSum(G[i, j] * u_vars[i] for i in range(k)) <= 1, f\"Constraint4_j{j}\"\n",
    "            prob += pulp.lpSum(-G[i, j] * u_vars[i] for i in range(k)) <= 1, f\"Constraint5_j{j}\"\n",
    "        return prob\n",
    "\n",
    "    def calculate_m_height(self, num_cores=1):\n",
    "        \"\"\" Compute m-height using multiprocessing for LP solves \"\"\"\n",
    "        n, k, m = self.n, self.k, self.m\n",
    "        P = self.P\n",
    "        identity_k = np.identity(k)\n",
    "        G = np.hstack([identity_k, P])\n",
    "        max_objective_found = 1.0\n",
    "        lp_tasks = []\n",
    "        indices = list(range(n))\n",
    "        try:\n",
    "            for a in indices:\n",
    "                indices_minus_a = [idx for idx in indices if idx != a]\n",
    "                for b in indices_minus_a:\n",
    "                    indices_minus_ab = [idx for idx in indices_minus_a if idx != b]\n",
    "                    if len(indices_minus_ab) < m - 1: continue\n",
    "                    for X_tuple in itertools.combinations(indices_minus_ab, m - 1):\n",
    "                        X = list(X_tuple)\n",
    "                        Y = [idx for idx in indices_minus_ab if idx not in X]\n",
    "                        for psi in itertools.product([-1, 1], repeat=m):\n",
    "                            s = list(psi)\n",
    "                            lp_tasks.append((G, a, b, X, psi, k, m, s, Y))\n",
    "            if not lp_tasks: return (None, None)\n",
    "        except Exception as e: print(f\"Error generating LP tasks: {e}\"); return (None, None)\n",
    "        results = []\n",
    "        try:\n",
    "            # Ensure num_cores is positive\n",
    "            if num_cores <= 0: num_cores = 1\n",
    "            with multiprocessing.Pool(processes=num_cores) as pool:\n",
    "                 results = pool.starmap(_solve_single_lp_task, lp_tasks)\n",
    "        except Exception as pool_e: print(f\"Multiprocessing error: {pool_e}\"); return(None, None)\n",
    "        found_unbounded = False\n",
    "        for status, value in results:\n",
    "            if status == pulp.LpStatusUnbounded: found_unbounded = True; break\n",
    "            elif status == pulp.LpStatusOptimal and value is not None:\n",
    "                if value > max_objective_found: max_objective_found = value\n",
    "        if found_unbounded: return (None, None)\n",
    "        if np.isclose(max_objective_found, 1.0) and max_objective_found <= 1.0: return (None, None)\n",
    "        if max_objective_found < 1.0: return (None, None)\n",
    "        return (P, max_objective_found)\n",
    "\n",
    "# --- Worker function (Top Level) ---\n",
    "def _solve_single_lp_task(G, a, b, X, psi, k, m, s, Y):\n",
    "    try:\n",
    "        # Create temporary instance ONLY to call build_lp_problem\n",
    "        # Ensure __init__ handles potential errors gracefully if k=0 etc.\n",
    "        if k <= 0: return pulp.LpStatusUndefined, None # Avoid error in identity(k)\n",
    "        temp_solver = LP_based_solution(n=G.shape[1], k=k, m=m)\n",
    "        prob = temp_solver.build_lp_problem(G, a, b, X, psi, k, m, s, Y)\n",
    "\n",
    "        # Solve the problem\n",
    "        status = prob.solve(pulp.PULP_CBC_CMD(msg=0))\n",
    "        value = None\n",
    "        if status == pulp.LpStatusOptimal:\n",
    "            value = pulp.value(prob.objective)\n",
    "        # Note: Unbounded status is handled, value remains None\n",
    "        return status, value\n",
    "    except Exception as e:\n",
    "        # print(f\"  (Worker error for {a},{b},{X},{psi}: {e})\", end='\\r') # Can be very verbose\n",
    "        return pulp.LpStatusUndefined, None # Indicate failure\n",
    "\n",
    "# --- Saving Function ---\n",
    "def save_partial_data_npz(P_list, h_list, n, k, m, output_dir=\"data\", base_filename=\"m_height_data\"): # Default output_dir=\"data\"\n",
    "    \"\"\"\n",
    "    Saves generated P matrices and h_m values to a uniquely named .npz file\n",
    "    inside the specified output directory (defaults to 'data').\n",
    "    Includes n, k, m values in the saved file.\n",
    "\n",
    "    Args:\n",
    "        P_list (list): List of generated P matrices (NumPy arrays).\n",
    "        h_list (list): List of corresponding h_m values (floats).\n",
    "        n (int): n parameter used for generation.\n",
    "        k (int): k parameter used for generation.\n",
    "        m (int): m parameter used for generation.\n",
    "        output_dir (str): Directory to save the file in, relative to script execution location. Defaults to 'data'.\n",
    "        base_filename (str): Base name for the output file.\n",
    "    \"\"\"\n",
    "    if not P_list or not h_list:\n",
    "        print(\"No data generated in this run, nothing to save.\")\n",
    "        return\n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    try:\n",
    "        os.makedirs(output_dir, exist_ok=True) # exist_ok=True prevents error if dir already exists\n",
    "    except OSError as e:\n",
    "        print(f\"\\nError creating output directory '{output_dir}': {e}. Cannot save file.\")\n",
    "        return # Stop if we can't create the directory\n",
    "\n",
    "    # Convert lists to NumPy arrays\n",
    "    P_array = np.array(P_list)\n",
    "    h_array = np.array(h_list)\n",
    "    n_array = np.array([n])\n",
    "    k_array = np.array([k])\n",
    "    m_array = np.array([m])\n",
    "\n",
    "    # Generate a unique filename\n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    unique_id = str(uuid.uuid4())[:8]\n",
    "    filename_base = f\"{base_filename}_n{n}_k{k}_m{m}_{timestamp}_{unique_id}.npz\"\n",
    "\n",
    "    # Construct the full path including the output directory\n",
    "    full_filepath = os.path.join(output_dir, filename_base)\n",
    "\n",
    "    try:\n",
    "        # Save the arrays to the specified path\n",
    "        np.savez_compressed(\n",
    "            full_filepath, # Use the full path\n",
    "            P_matrices=P_array,\n",
    "            h_values=h_array,\n",
    "            n_val=n_array,\n",
    "            k_val=k_array,\n",
    "            m_val=m_array\n",
    "        )\n",
    "        print(f\"\\nPartial dataset saved successfully to {full_filepath}\")\n",
    "        print(f\"Saved {len(h_array)} samples from this run.\")\n",
    "        # print(f\"Shape of P_matrices array: {P_array.shape}\") # Optional detail\n",
    "        # print(f\"Shape of h_values array: {h_array.shape}\") # Optional detail\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError saving data to {full_filepath}: {e}\")\n",
    "\n",
    "\n",
    "# --- Main Generation Logic (Adapted for Notebook) ---\n",
    "\n",
    "# --- Parameters to Set Manually ---\n",
    "n_values = [9, 10]\n",
    "k_values = [4, 5, 6]\n",
    "samples_per_combination = 100 # ADJUST THIS AS NEEDED - START SMALL (e.g., 10) FOR TESTING\n",
    "num_cores_to_use = 5      # ADJUST THIS - Use multiprocessing.cpu_count() to see available cores\n",
    "output_directory = \"generated_data_notebook\" # Set output folder name\n",
    "\n",
    "# --- Pre-calculate combinations ---\n",
    "total_expected_combinations = 0\n",
    "parameter_combinations = []\n",
    "print(\"Calculating valid (n, k, m) combinations...\")\n",
    "for n_val_loop in n_values:\n",
    "    for k_val_loop in k_values:\n",
    "        if k_val_loop >= n_val_loop: continue\n",
    "        min_m = 2\n",
    "        max_m = n_val_loop - k_val_loop\n",
    "        if max_m >= min_m:\n",
    "            for m_val_loop in range(min_m, max_m + 1):\n",
    "                 if m_val_loop <= n_val_loop -1 :\n",
    "                    parameter_combinations.append((n_val_loop, k_val_loop, m_val_loop))\n",
    "                    total_expected_combinations += 1\n",
    "print(f\"Found {total_expected_combinations} valid combinations.\")\n",
    "print(f\"Generating {samples_per_combination} samples per combination using up to {num_cores_to_use} cores.\")\n",
    "print(f\"Saving results in: {output_directory}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- Ensure cores don't exceed available ---\n",
    "available_cores = multiprocessing.cpu_count()\n",
    "if num_cores_to_use > available_cores:\n",
    "    print(f\"Warning: Requested {num_cores_to_use} cores, only {available_cores} available. Using {available_cores}.\")\n",
    "    num_cores_to_use = available_cores\n",
    "if num_cores_to_use <= 0: num_cores_to_use = 1\n",
    "\n",
    "# --- Main Loop ---\n",
    "overall_start_time = time.time()\n",
    "run_counter = 0\n",
    "for n_val, k_val, m_val in parameter_combinations:\n",
    "    run_counter += 1\n",
    "    print(f\"\\nStarting Run {run_counter}/{total_expected_combinations}: n={n_val}, k={k_val}, m={m_val}\")\n",
    "\n",
    "    dataset_P_current = []\n",
    "    dataset_h_current = []\n",
    "    samples_generated_this_run = 0\n",
    "    attempts = 0\n",
    "    max_attempts = int(samples_per_combination * 1.5) + 10\n",
    "\n",
    "    start_time_run = time.time()\n",
    "\n",
    "    while samples_generated_this_run < samples_per_combination and attempts < max_attempts :\n",
    "        attempts += 1\n",
    "        try:\n",
    "            solver_instance = LP_based_solution(n_val, k_val, m_val)\n",
    "            P_matrix, h_m = solver_instance.calculate_m_height(num_cores=num_cores_to_use) # Pass core count\n",
    "\n",
    "            if h_m is not None:\n",
    "                 dataset_P_current.append(solver_instance.P)\n",
    "                 dataset_h_current.append(h_m)\n",
    "                 samples_generated_this_run += 1\n",
    "                 print(f\"Run {run_counter}: Sample {samples_generated_this_run}/{samples_per_combination} -> h_m = {h_m:.4f} (Attempt {attempts})   \", end='\\r')\n",
    "\n",
    "        except ValueError as init_err:\n",
    "            print(f\"\\nError initializing for run {run_counter}: {init_err}. Stopping run.\")\n",
    "            dataset_P_current, dataset_h_current = [], []\n",
    "            break # Stop this specific (n,k,m) run\n",
    "        except Exception as e:\n",
    "             print(f\"\\nUnhandled error in run {run_counter} (attempt {attempts}): {e}. Continuing attempt.\")\n",
    "             # time.sleep(0.5) # Optional small pause\n",
    "\n",
    "    # --- Loop finished for this combination ---\n",
    "    end_time_run = time.time()\n",
    "    duration_run = end_time_run - start_time_run\n",
    "    print(f\"\\nFinished Run {run_counter} ({n_val},{k_val},{m_val}). Generated {samples_generated_this_run} samples in {duration_run:.2f} seconds ({attempts} attempts).\")\n",
    "\n",
    "    if samples_generated_this_run < samples_per_combination:\n",
    "         print(f\"Warning: Only generated {samples_generated_this_run} out of {samples_per_combination} target samples.\")\n",
    "\n",
    "    # --- Save data for this run ---\n",
    "    if samples_generated_this_run > 0:\n",
    "        save_partial_data_npz(dataset_P_current, dataset_h_current, n_val, k_val, m_val, output_dir=output_directory)\n",
    "    else:\n",
    "        print(f\"No valid samples generated for Run {run_counter}, skipping save.\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "overall_end_time = time.time()\n",
    "print(f\"\\nAll parameter combinations processed. Total time: {overall_end_time - overall_start_time:.2f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 64 CPUs from the HPRC and 2 days of computing, we only generated around 10,000 data points as the computation time increases significantly as m gets bigger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After generating the data and using the data generated by Keegan Smith shared on campuswire.com, we are going now to train different model and see which performs the best without any fine tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define the dataset class NpzFolderDatasetWithParams for npz files ---\n",
    "class NpzFolderDatasetWithParams(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for loading data from multiple .npz files in a folder.\n",
    "    Assumes each .npz file contains 'P_matrices', 'h_values', 'n_val', 'k_val', 'm_val'.\n",
    "    Handles padding P_matrices.\n",
    "    \"\"\"\n",
    "    def __init__(self, folder_path, max_k=6, max_nk=6, transform = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            folder_path (str): Path to the folder containing .npz files.\n",
    "            max_k (int): The height to pad P matrices to.\n",
    "            max_nk (int): The width to pad P matrices to.\n",
    "            transform : apply transformation on the P matrix\n",
    "        \"\"\"\n",
    "        self.folder_path = folder_path\n",
    "        self.max_k = max_k\n",
    "        self.max_nk = max_nk\n",
    "        self.file_paths = glob.glob(os.path.join(folder_path, '*.npz'))\n",
    "        self.transform = transform \n",
    "\n",
    "        if not self.file_paths:\n",
    "            raise FileNotFoundError(f\"No .npz files found in {folder_path}\")\n",
    "\n",
    "        self.all_P_matrices = []\n",
    "        self.all_h_values = []\n",
    "        self.all_n = []\n",
    "        self.all_k = []\n",
    "        self.all_m = []\n",
    "\n",
    "        print(f\"Loading data from {len(self.file_paths)} files...\")\n",
    "        for file_path in self.file_paths:\n",
    "            try:\n",
    "                with np.load(file_path) as data:\n",
    "                    if 'P_matrices' not in data or 'h_values' not in data or \\\n",
    "                       'n_val' not in data or 'k_val' not in data or 'm_val' not in data:\n",
    "                         print(f\"Warning: Skipping {file_path} - missing required keys.\")\n",
    "                         continue\n",
    "                    P_matrices = data['P_matrices']; h_values = data['h_values']\n",
    "                    if len(P_matrices) != len(h_values): continue\n",
    "                    if P_matrices.ndim < 3: continue\n",
    "\n",
    "                    self.all_P_matrices.extend(list(P_matrices))\n",
    "                    self.all_h_values.extend(list(h_values))\n",
    "\n",
    "                    # Extract n, k, m (handle scalar case)\n",
    "                    n_val = data['n_val'][0] if data['n_val'].ndim > 0 else data['n_val'].item()\n",
    "                    k_val = data['k_val'][0] if data['k_val'].ndim > 0 else data['k_val'].item()\n",
    "                    m_val = data['m_val'][0] if data['m_val'].ndim > 0 else data['m_val'].item()\n",
    "\n",
    "                    self.all_n.extend([n_val] * len(h_values))\n",
    "                    self.all_k.extend([k_val] * len(h_values))\n",
    "                    self.all_m.extend([m_val] * len(h_values))\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading or processing {file_path}: {e}\")\n",
    "\n",
    "        if not self.all_h_values:\n",
    "             raise ValueError(\"No valid data loaded.\")\n",
    "\n",
    "        print(f\"Finished loading. Total samples: {len(self.all_h_values)}\")\n",
    "\n",
    "        # Convert to tensors\n",
    "        self.all_h_values = torch.tensor(self.all_h_values, dtype=torch.float32)\n",
    "        self.all_n = torch.tensor(self.all_n, dtype=torch.float32)\n",
    "        self.all_k = torch.tensor(self.all_k, dtype=torch.float32)\n",
    "        self.all_m = torch.tensor(self.all_m, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_h_values)\n",
    "\n",
    "    def _pad_matrix(self, p_matrix):\n",
    "        \"\"\"Pads a single P matrix to the target size (max_k, max_nk).\"\"\"\n",
    "        p_tensor = torch.tensor(p_matrix, dtype=torch.float32)\n",
    "        k, nk = p_tensor.shape\n",
    "        pad_k = self.max_k - k\n",
    "        pad_nk = self.max_nk - nk\n",
    "        if pad_k < 0 or pad_nk < 0:\n",
    "             raise ValueError(f\"Matrix shape {p_tensor.shape} > target ({self.max_k},{self.max_nk})\")\n",
    "        padding = (0, pad_nk, 0, pad_k) # Pad right, bottom\n",
    "        padded_p = F.pad(p_tensor, padding, \"constant\", 0)\n",
    "        return padded_p\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        p_matrix_np = self.all_P_matrices[idx]\n",
    "        h_value = self.all_h_values[idx] # Already a tensor\n",
    "\n",
    "        # Pad the P matrix (convert to tensor inside)\n",
    "        padded_p = self._pad_matrix(p_matrix_np)\n",
    "\n",
    "        # Get n, k, m for this sample (already tensors)\n",
    "        n_val = self.all_n[idx]\n",
    "        k_val = self.all_k[idx]\n",
    "        m_val = self.all_m[idx]\n",
    "\n",
    "        # Stack parameters without normalization\n",
    "        params = torch.stack([n_val, k_val, m_val]) # Shape: (3,)\n",
    "\n",
    "        sample = {'params': params, 'h': h_value.unsqueeze(0), 'P': padded_p}\n",
    "\n",
    "        if self.transform:\n",
    "            sample['P'] = self.transform(sample['P'])\n",
    "\n",
    "        # Return params, h and  sample['P'],\n",
    "        return sample['params'], sample['h'],  sample['P']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, I used .npz files to test different models with the class 'NpzFolderDatasetWithParams'.    \n",
    "\n",
    "After training the basic model, I switched to a larger dataset from student Keegan Smith (1 million data points), from which I randomly selected 420,000 samples using a Python script called \"split_pickle_data\" (not included here)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first class \"PklDataloader\" is used for testing purposes at the beginning of the project and then I used the class \"PickleFolderDatasetWithParams\" for the rest of the project as it can loads files from different folder and combine them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PklDataLoader initialized for path: split_data/data_n9_k4_m2.pkl\n",
      "PklDataLoader initialized for path: split_data_validation/data_n9_k4_m2.pkl\n",
      "Attempting to load data from: split_data/data_n9_k4_m2.pkl\n",
      "Successfully loaded DataFrame. Shape: (10000, 5), Index sample: [1, 9, 15, 16, 36]\n",
      "Resetting index...\n",
      "Index reset. New index sample: [0, 1, 2, 3, 4]\n",
      "Attempting to load data from: split_data_validation/data_n9_k4_m2.pkl\n",
      "Successfully loaded DataFrame. Shape: (10000, 5), Index sample: [244083, 244088, 244097, 244112, 244130]\n",
      "Resetting index...\n",
      "Index reset. New index sample: [0, 1, 2, 3, 4]\n",
      "\n",
      "Loaded Training Data Head:\n",
      "   n  k  m      result                                                  P\n",
      "0  9  4  2  140.163560  [6.5178894459618135, -6.281201889271188, 99.66...\n",
      "1  9  4  2  162.300346  [-88.48172895982646, 1.92925363611036, -53.250...\n",
      "2  9  4  2  217.263508  [-62.70454405366304, 92.07945357330013, 37.450...\n",
      "3  9  4  2  146.251829  [-89.46558729229577, 59.446747639708974, -6.71...\n",
      "4  9  4  2  125.830965  [-34.137527580233765, -13.847638465166739, -67...\n",
      "\n",
      "Loaded Validation Data Head:\n",
      "   n  k  m      result                                                  P\n",
      "0  9  4  2  164.995231  [22.932083520938676, -62.10820213506806, 98.17...\n",
      "1  9  4  2  142.474431  [-63.8990295745042, 81.98832462236001, 83.1528...\n",
      "2  9  4  2  180.766265  [87.11545342507131, -89.93102834195979, -38.22...\n",
      "3  9  4  2  105.582642  [53.74350976588755, -15.991272911657873, -56.8...\n",
      "4  9  4  2  128.205327  [-96.65210851723312, -80.116266751388, -11.902...\n",
      "------------------------------\n",
      "Final Training set size: (16000, 5)\n",
      "Final Validation set size: (4000, 5)\n"
     ]
    }
   ],
   "source": [
    "# --- Define the class \"PklDataLoader\" to load the data from .pkl files ---\n",
    "class PklDataLoader:\n",
    "    \"\"\"\n",
    "    Loads pandas DataFrames from .pkl files generated by the splitting script.\n",
    "\n",
    "    Uses pd.read_pickle for loading, as the files were saved using\n",
    "    DataFrame.to_pickle().\n",
    "    \"\"\"\n",
    "    def __init__(self, file_path: str):\n",
    "        \"\"\"\n",
    "        Initializes the loader with the path to the .pkl file.\n",
    "\n",
    "        Args:\n",
    "            file_path: The full path to the .pkl file.\n",
    "        \"\"\"\n",
    "        if not isinstance(file_path, str) or not file_path:\n",
    "            raise ValueError(\"A valid file path (string) must be provided.\")\n",
    "        # You could add more robust path validation here if needed\n",
    "        # e.g., os.path.exists(file_path) before loading\n",
    "        self.file_path = file_path\n",
    "        print(f\"PklDataLoader initialized for path: {self.file_path}\")\n",
    "\n",
    "    def load_data(self, reset_index: bool = True) -> pd.DataFrame | None:\n",
    "        \"\"\"\n",
    "        Loads the DataFrame from the specified .pkl file using pandas.\n",
    "\n",
    "        Args:\n",
    "            reset_index: If True (default), resets the DataFrame index\n",
    "                         after loading, discarding the original index.\n",
    "                         Set to False to keep the original index from the\n",
    "                         split file.\n",
    "\n",
    "        Returns:\n",
    "            A pandas DataFrame if successful, otherwise None if an error occurs.\n",
    "        \"\"\"\n",
    "        print(f\"Attempting to load data from: {self.file_path}\")\n",
    "        try:\n",
    "            # Use pd.read_pickle as files were saved with df.to_pickle\n",
    "            df = pd.read_pickle(self.file_path)\n",
    "            print(f\"Successfully loaded DataFrame. Shape: {df.shape}, Index sample: {df.index[:5].tolist()}\")\n",
    "\n",
    "            if reset_index:\n",
    "                print(\"Resetting index...\")\n",
    "                df.reset_index(drop=True, inplace=True)\n",
    "                print(f\"Index reset. New index sample: {df.index[:5].tolist()}\")\n",
    "\n",
    "            return df\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: File not found at '{self.file_path}'. Cannot load data.\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            # Catch other potential errors during loading (permissions, corrupt file, etc.)\n",
    "            print(f\"An unexpected error occurred while loading '{self.file_path}': {e}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "# # Example for one file:\n",
    "train_file = \"split_data/data_n9_k4_m2.pkl\"\n",
    "val_file = \"split_data_validation/data_n9_k4_m2.pkl\"\n",
    "\n",
    "# Create loader instances\n",
    "train_loader_helper = PklDataLoader(train_file)\n",
    "val_loader_helper = PklDataLoader(val_file)\n",
    "\n",
    "# Load the data (index will be reset by default)\n",
    "df_train = train_loader_helper.load_data()\n",
    "df_val = val_loader_helper.load_data()\n",
    "\n",
    "# Check if loading was successful before proceeding\n",
    "if df_train is not None and df_val is not None:\n",
    "    print(\"\\nLoaded Training Data Head:\")\n",
    "    print(df_train.head())\n",
    "    print(\"\\nLoaded Validation Data Head:\")\n",
    "    print(df_val.head())\n",
    "\n",
    "    #--- Now you can implement the 80/20 split logic ---\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    validation_split_size = 4000 # Target size for the final validation set\n",
    "    test_fraction = validation_split_size / len(df_val)\n",
    "    \n",
    "    df_extra_train, df_final_val = train_test_split(\n",
    "        df_val, # Start with the loaded 10k validation data\n",
    "        test_size=test_fraction,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    df_final_train = pd.concat([df_train, df_extra_train], ignore_index=True)\n",
    "    \n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Final Training set size: {df_final_train.shape}\")\n",
    "    print(f\"Final Validation set size: {df_final_val.shape}\")\n",
    "    \n",
    "    # Use df_final_train and df_final_val for your PyTorch Datasets/DataLoaders\n",
    "else:\n",
    "      print(\"Error loading one or both data files. Cannot proceed with this combination.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the data from split_data and split_data_validation folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define the class \"PickleFolderDataset\" to load the data from pkl files ---\n",
    "class PickleFolderDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for loading data from a **list of .pkl file paths**.\n",
    "\n",
    "    Assumes each .pkl file contains a Pandas DataFrame with columns\n",
    "    'n', 'k', 'm', 'result', 'P'.\n",
    "    Handles cases where 'P' might be a 2D array OR a flattened 1D array.\n",
    "    Reshapes 1D 'P' arrays to 2D using 'n' and 'k' before padding.\n",
    "    Handles padding P_matrices. \n",
    "    Returns data as (params, h, P).\n",
    "    \"\"\"\n",
    "    def __init__(self, file_paths, max_k=6, max_nk=6, transform=None): \n",
    "        \"\"\"\n",
    "        Args:\n",
    "            file_paths (list[str]): A list of full paths to the .pkl files.\n",
    "            max_k (int): The height to pad P matrices to.\n",
    "            max_nk (int): The width to pad P matrices to.\n",
    "            transform (callable, optional): Optional transform applied ONLY to the P matrix AFTER padding.\n",
    "        \"\"\"\n",
    "        self.file_paths = file_paths # it is a list\n",
    "        self.max_k = max_k\n",
    "        self.max_nk = max_nk\n",
    "        self.transform = transform\n",
    "\n",
    "        if not self.file_paths:\n",
    "            raise ValueError(\"The provided file_paths list is empty.\")\n",
    "\n",
    "        # Store data directly as loaded from pickle (P can be 1D or 2D)\n",
    "        self.all_P_matrices = [] # Can contain mixed ndim arrays initially\n",
    "        self.all_h_values = []\n",
    "        # Store n, k, m as simple Python ints initially for reshaping logic\n",
    "        self.all_n = []\n",
    "        self.all_k = []\n",
    "        self.all_m = []\n",
    "\n",
    "        print(f\"Loading data from {len(self.file_paths)} specified pickle files (expecting DataFrames)...\")\n",
    "        required_columns = ['n', 'k', 'm', 'result', 'P']\n",
    "\n",
    "        for file_path in self.file_paths: # Iterate through the provided list\n",
    "            # print(f\"  Loading: {os.path.basename(file_path)}\") # Keep print concise\n",
    "            try:\n",
    "                with open(file_path, 'rb') as f:\n",
    "                    data_df = pickle.load(f)\n",
    "\n",
    "                    if not isinstance(data_df, pd.DataFrame):\n",
    "                        print(f\"Warning: Skipping {os.path.basename(file_path)} - Expected a Pandas DataFrame, found {type(data_df)}.\")\n",
    "                        continue\n",
    "                    if not all(col in data_df.columns for col in required_columns):\n",
    "                        print(f\"Warning: Skipping {os.path.basename(file_path)} - Missing required columns ({required_columns}). Found: {list(data_df.columns)}\")\n",
    "                        continue\n",
    "\n",
    "                    # Use efficient Pandas column access\n",
    "                    p_matrices_list = data_df['P'].tolist()\n",
    "                    h_values_list = data_df['result'].astype(float).tolist()\n",
    "                    n_vals_list = data_df['n'].astype(int).tolist()\n",
    "                    k_vals_list = data_df['k'].astype(int).tolist()\n",
    "                    m_vals_list = data_df['m'].astype(int).tolist()\n",
    "\n",
    "                    # Optional: Basic validation before extending\n",
    "                    list_len = len(p_matrices_list)\n",
    "                    if not (list_len == len(h_values_list) == len(n_vals_list) == len(k_vals_list) == len(m_vals_list)):\n",
    "                            print(f\"Warning: Skipping {os.path.basename(file_path)} due to inconsistent column lengths after tolist().\")\n",
    "                            continue\n",
    "\n",
    "                    # Extend lists\n",
    "                    self.all_P_matrices.extend([np.array(p) for p in p_matrices_list]) # Ensure numpy\n",
    "                    self.all_h_values.extend(h_values_list)\n",
    "                    self.all_n.extend(n_vals_list) # Keep as int\n",
    "                    self.all_k.extend(k_vals_list) # Keep as int\n",
    "                    self.all_m.extend(m_vals_list) # Keep as int\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                    print(f\"Error: File not found {file_path}. Skipping.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading/processing {file_path}: {type(e).__name__} - {e}. Skipping file.\")\n",
    "                # print(traceback.format_exc()) # Uncomment for more detail\n",
    "\n",
    "        if not self.all_h_values:\n",
    "                raise ValueError(\"No valid data loaded from any pickle files.\")\n",
    "\n",
    "        print(f\"Finished initial loading. Total samples found: {len(self.all_h_values)}\")\n",
    "\n",
    "        # --- Convert non-P lists to tensors ---\n",
    "        self.all_h_values_tensor = torch.tensor(self.all_h_values, dtype=torch.float32)\n",
    "        self.all_n_tensor = torch.tensor(self.all_n, dtype=torch.float32)\n",
    "        self.all_k_tensor = torch.tensor(self.all_k, dtype=torch.float32)\n",
    "        self.all_m_tensor = torch.tensor(self.all_m, dtype=torch.float32)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_h_values_tensor)\n",
    "\n",
    "    def _pad_matrix(self, p_matrix_2d):\n",
    "        if not isinstance(p_matrix_2d, np.ndarray) or p_matrix_2d.ndim != 2:\n",
    "            raise ValueError(f\"Input to _pad_matrix must be a 2D NumPy array, but got type {type(p_matrix_2d)} with shape {getattr(p_matrix_2d, 'shape', 'N/A')}\")\n",
    "        p_tensor = torch.tensor(p_matrix_2d, dtype=torch.float32)\n",
    "        k_actual, nk_actual = p_tensor.shape\n",
    "        pad_k = self.max_k - k_actual\n",
    "        pad_nk = self.max_nk - nk_actual\n",
    "        if pad_k < 0 or pad_nk < 0:\n",
    "                raise ValueError(f\"Matrix shape ({k_actual},{nk_actual}) exceeds target padding ({self.max_k},{self.max_nk}).\")\n",
    "        padding = (0, pad_nk, 0, pad_k)\n",
    "        padded_p = F.pad(p_tensor, padding, \"constant\", 0)\n",
    "        return padded_p\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx): idx = idx.tolist()\n",
    "\n",
    "        p_matrix_np = self.all_P_matrices[idx]\n",
    "        h_value = self.all_h_values_tensor[idx]\n",
    "        n_val = self.all_n[idx] # Get int value\n",
    "        k_val = self.all_k[idx] # Get int value\n",
    "\n",
    "        p_matrix_2d = None\n",
    "\n",
    "        if p_matrix_np.ndim == 1:\n",
    "            try:\n",
    "                target_rows = k_val\n",
    "                target_cols = n_val - k_val\n",
    "                if target_rows <= 0 or target_cols < 0:\n",
    "                        raise ValueError(f\"Invalid target shape calculated: k={target_rows}, n-k={target_cols} from n={n_val}, k={k_val}\")\n",
    "                expected_shape = (target_rows, target_cols)\n",
    "                expected_len = target_rows * target_cols\n",
    "\n",
    "                if p_matrix_np.size == 0 and expected_len == 0:\n",
    "                    p_matrix_2d = np.empty((target_rows, 0), dtype=p_matrix_np.dtype)\n",
    "                elif p_matrix_np.size != expected_len:\n",
    "                    raise ValueError(f\"Flattened P length ({p_matrix_np.size}) != k*(n-k) ({expected_len}) for n={n_val}, k={k_val}\")\n",
    "                else:\n",
    "                    p_matrix_2d = p_matrix_np.reshape(expected_shape)\n",
    "            except Exception as e:\n",
    "                print(f\"ERROR in __getitem__ (idx={idx}): Failed to reshape P with shape {p_matrix_np.shape} using n={n_val}, k={k_val}. Error: {e}\")\n",
    "                raise RuntimeError(f\"Data Error: Failed processing P matrix for sample index {idx}.\") from e\n",
    "        elif p_matrix_np.ndim == 2:\n",
    "            p_matrix_2d = p_matrix_np\n",
    "        else:\n",
    "            raise ValueError(f\"ERROR in __getitem__ (idx={idx}): P matrix has unexpected shape {p_matrix_np.shape}.\")\n",
    "\n",
    "        padded_p = self._pad_matrix(p_matrix_2d)\n",
    "        if self.transform: padded_p = self.transform(padded_p)\n",
    "\n",
    "        params = torch.stack([self.all_n_tensor[idx], self.all_k_tensor[idx], self.all_m_tensor[idx]])\n",
    "        h = h_value.unsqueeze(0)\n",
    "        return params, h, padded_p\n",
    "\n",
    "# --- Example usage ---\n",
    "# FOLDER_WITH_PICKLES = './split_data'\n",
    "# FOLDER_VALIDATION = './split_data_validation'\n",
    "# MAX_K_PADDED = 6\n",
    "# MAX_NK_PADDED = 6\n",
    "\n",
    "# try:\n",
    "#     # p_transform = transforms.Compose([...]) # Example placeholder\n",
    "#     p_transform = None # Or set to None if no transform needed\n",
    "\n",
    "#     train_dataset_df = PickleFolderDataset(FOLDER_WITH_PICKLES, MAX_K_PADDED, MAX_NK_PADDED, transform=p_transform)\n",
    "#     val_dataset_df = PickleFolderDataset(FOLDER_VALIDATION, MAX_K_PADDED, MAX_NK_PADDED, transform=p_transform) # Use same transform usually\n",
    "#     print(f\"Loaded {len(train_dataset_df)} training samples and {len(val_dataset_df)} validation samples.\")\n",
    "\n",
    "#     # Get a sample to check the output format\n",
    "#     if len(train_dataset_df) > 0:\n",
    "#         sample_params, sample_h, sample_p = train_dataset_df[0]\n",
    "#         print(\"\\nSample output format:\")\n",
    "#         print(\"  Params shape:\", sample_params.shape, \"| Params dtype:\", sample_params.dtype)\n",
    "#         print(\"  h shape:\", sample_h.shape, \"| h dtype:\", sample_h.dtype)\n",
    "#         print(\"  P shape:\", sample_p.shape, \"| P dtype:\", sample_p.dtype)\n",
    "\n",
    "# except Exception as e:\n",
    "#      print(f\"Error creating dataset: {e}\")\n",
    "#      print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define the custom MSE loss function on the log2 scale --- \n",
    "class LogMSELoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Calculates the Mean Squared Error on the log2 scale.\n",
    "    Loss = mean( (log2(y_true) - log2(y_pred))^2 )\n",
    "    Adds a small epsilon to prevent log2(0).\n",
    "    \"\"\"\n",
    "    def __init__(self, eps=1e-9):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            y_pred (torch.Tensor): Predictions from the model.\n",
    "            y_true (torch.Tensor): Ground truth values.\n",
    "        \"\"\"\n",
    "        # Clamp inputs to be positive to avoid log2(<=0)\n",
    "        y_pred_safe = torch.clamp(y_pred, min=self.eps)\n",
    "        y_true_safe = torch.clamp(y_true, min=self.eps) # Clamp true values too for safety\n",
    "\n",
    "        # Calculate log base 2\n",
    "        log2_pred = torch.log2(y_pred_safe)\n",
    "        log2_true = torch.log2(y_true_safe)\n",
    "\n",
    "        # Calculate the squared difference and mean over the batch\n",
    "        loss = torch.mean((log2_true - log2_pred) ** 2)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define dense network class --- \n",
    "class DenseNetworkWithParams(nn.Module):\n",
    "    \"\"\"\n",
    "    Dense Network accepting padded P matrix (flattened) and n, k, m parameters.\n",
    "    \"\"\"\n",
    "    def __init__(self, p_input_size, param_input_size=3, hidden_size1=128, hidden_size2=64, hidden_size3=32, output_size=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            p_input_size (int): Flattened size of the padded P matrix (e.g., 36).\n",
    "            param_input_size (int): Number of parameter inputs (n, k, m -> 3).\n",
    "            hidden_size1 (int): Neurons in first hidden layer.\n",
    "            hidden_size2 (int): Neurons in second hidden layer.\n",
    "            hidden_size3 (int): Neurons in third hidden layer.\n",
    "            output_size (int): Output neurons (1 for h_m).\n",
    "        \"\"\"\n",
    "        super(DenseNetworkWithParams, self).__init__()\n",
    "        self.p_input_size = p_input_size\n",
    "        self.param_input_size = param_input_size\n",
    "        combined_input_size = p_input_size + param_input_size # Total input size\n",
    "\n",
    "        self.fc1 = nn.Linear(combined_input_size, hidden_size1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size2, hidden_size3)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc4 = nn.Linear(hidden_size3, output_size)\n",
    "        \n",
    "\n",
    "    def forward(self, p_matrix, params):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            p_matrix (torch.Tensor): Padded P matrix. Shape: (batch, k_pad, nk_pad)\n",
    "            params (torch.Tensor): Normalized n, k, m values. Shape: (batch, 3)\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Predicted h_m value(s). Shape: (batch, 1)\n",
    "        \"\"\"\n",
    "        batch_size = p_matrix.size(0)\n",
    "        # Flatten P matrix\n",
    "        p_flat = p_matrix.view(batch_size, -1) # Shape: (batch, p_input_size)\n",
    "\n",
    "        # Validate shape\n",
    "        if p_flat.shape[1] != self.p_input_size:\n",
    "             raise ValueError(f\"P matrix flattened size ({p_flat.shape[1]}) != expected ({self.p_input_size})\")\n",
    "        if params.shape[1] != self.param_input_size:\n",
    "             raise ValueError(f\"Params size ({params.shape[1]}) != expected ({self.param_input_size})\")\n",
    "\n",
    "        # Concatenate flattened P and parameters\n",
    "        combined_input = torch.cat((p_flat, params), dim=1) # Shape: (batch, p_input_size + 3)\n",
    "\n",
    "        # Pass through layers\n",
    "        out = self.fc1(combined_input)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.relu3(out)\n",
    "        out = self.fc4(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define CNN class ---\n",
    "\n",
    "class CNNWithParams(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN accepting padded P matrix and n, k, m parameters.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels=1, input_height=6, input_width=6, param_input_size=3, output_size=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_channels (int): Channels for P matrix (1).\n",
    "            input_height (int): Padded height (max_k).\n",
    "            input_width (int): Padded width (max_nk).\n",
    "            param_input_size (int): Number of parameters (n, k, m -> 3).\n",
    "            output_size (int): Output neurons (1 for h_m).\n",
    "        \"\"\"\n",
    "        super(CNNWithParams, self).__init__()\n",
    "        self.input_h = input_height\n",
    "        self.input_w = input_width\n",
    "        self.param_input_size = param_input_size\n",
    "\n",
    "        # Convolutional layers (same as before)\n",
    "        self.conv1 = nn.Conv2d(input_channels, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) # 6x6 -> 3x3\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=1) # 3x3 -> 2x2\n",
    "\n",
    "        # Calculate flattened size after conv layers\n",
    "        with torch.no_grad(): # Use no_grad for dummy forward pass\n",
    "            dummy_input = torch.zeros(1, input_channels, input_height, input_width)\n",
    "            dummy_output = self._forward_conv(dummy_input)\n",
    "            self.conv_flattened_size = dummy_output.view(1, -1).size(1) # Calculate dynamically\n",
    "\n",
    "        # Fully Connected Layers - Input size is conv output + params\n",
    "        combined_fc_input_size = self.conv_flattened_size + param_input_size\n",
    "        self.fc1 = nn.Linear(combined_fc_input_size, 64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, output_size)\n",
    "\n",
    "    def _forward_conv(self, x):\n",
    "        \"\"\" Helper to pass input through conv layers only \"\"\"\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        return x\n",
    "\n",
    "    def forward(self, p_matrix, params):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            p_matrix (torch.Tensor): Padded P matrix. Shape: (batch, k_pad, nk_pad)\n",
    "            params (torch.Tensor): Normalized n, k, m values. Shape: (batch, 3)\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Predicted h_m value(s). Shape: (batch, 1)\n",
    "        \"\"\"\n",
    "        batch_size = p_matrix.size(0)\n",
    "        # Validate shapes\n",
    "        if p_matrix.shape[1] != self.input_h or p_matrix.shape[2] != self.input_w:\n",
    "            raise ValueError(f\"P matrix shape ({p_matrix.shape[1]}x{p_matrix.shape[2]}) != expected ({self.input_h}x{self.input_w})\")\n",
    "        if params.shape[1] != self.param_input_size:\n",
    "            raise ValueError(f\"Params size ({params.shape[1]}) != expected ({self.param_input_size})\")\n",
    "\n",
    "        # Add channel dim for CNN: (batch, H, W) -> (batch, 1, H, W)\n",
    "        p_unsqueezed = p_matrix.unsqueeze(1)\n",
    "\n",
    "        # Pass P through convolutional layers\n",
    "        conv_out = self._forward_conv(p_unsqueezed)\n",
    "\n",
    "        # Flatten conv output\n",
    "        conv_flat = conv_out.view(batch_size, -1) # Shape: (batch, conv_flattened_size)\n",
    "\n",
    "        # Concatenate flattened conv output and parameters\n",
    "        combined_input = torch.cat((conv_flat, params), dim=1) # Shape: (batch, conv_flat + 3)\n",
    "\n",
    "        # Pass through fully connected layers\n",
    "        out = self.fc1(combined_input)\n",
    "        out = self.relu3(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- RNN architecture ---\n",
    "# --- LSTM Network ---\n",
    "class LSTMNetworkWithParams(nn.Module):\n",
    "    \"\"\"\n",
    "    RNN Network using LSTM layers, accepting padded P matrix (as sequence)\n",
    "    and n, k, m parameters.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_feature_size, hidden_size, num_layers, param_input_size=3, output_size=1, dropout_prob=0.2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_feature_size (int): Number of features per timestep (padded n-k, e.g., max_nk).\n",
    "            hidden_size (int): Number of features in the hidden state h.\n",
    "            num_layers (int): Number of recurrent layers.\n",
    "            param_input_size (int): Number of parameter inputs (n, k, m -> 3).\n",
    "            output_size (int): Output neurons (1 for h_m).\n",
    "            dropout_prob (float): Dropout probability for LSTM layers (if num_layers > 1) and FC layers.\n",
    "        \"\"\"\n",
    "        super(LSTMNetworkWithParams, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.param_input_size = param_input_size\n",
    "\n",
    "        # LSTM Layer: batch_first=True means input/output tensors are (batch, seq_len, features)\n",
    "        self.lstm = nn.LSTM(input_feature_size, hidden_size, num_layers,\n",
    "                            batch_first=True, dropout=dropout_prob if num_layers > 1 else 0)\n",
    "\n",
    "        # Fully Connected Layers: Input size is LSTM hidden size + param size\n",
    "        combined_fc_input_size = hidden_size + param_input_size\n",
    "        self.fc1 = nn.Linear(combined_fc_input_size, hidden_size // 2) # Example intermediate layer\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc2 = nn.Linear(hidden_size // 2, output_size)\n",
    "\n",
    "    def forward(self, p_matrix, params):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            p_matrix (torch.Tensor): Padded P matrix. Shape: (batch, max_k, max_nk)\n",
    "            params (torch.Tensor): Normalized n, k, m values. Shape: (batch, 3)\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Predicted h_m value(s). Shape: (batch, 1)\n",
    "        \"\"\"\n",
    "        batch_size = p_matrix.size(0)\n",
    "        device = p_matrix.device # Get device from input tensor\n",
    "\n",
    "        # Initialize hidden state and cell state with zeros\n",
    "        # Shape: (num_layers, batch_size, hidden_size)\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "\n",
    "        # Pass P matrix sequence through LSTM\n",
    "        # p_matrix is already (batch, seq_len=max_k, features=max_nk) due to batch_first=True\n",
    "        lstm_out, (hn, cn) = self.lstm(p_matrix, (h0, c0))\n",
    "\n",
    "        # We only need the hidden state from the last layer of the last timestep\n",
    "        # hn has shape (num_layers, batch_size, hidden_size)\n",
    "        last_hidden_state = hn[-1] # Shape: (batch_size, hidden_size)\n",
    "\n",
    "        # Concatenate the last hidden state with the parameters\n",
    "        combined_input = torch.cat((last_hidden_state, params), dim=1) # Shape: (batch, hidden_size + 3)\n",
    "\n",
    "        # Pass through fully connected layers\n",
    "        out = self.fc1(combined_input)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# --- GRU Network ---\n",
    "class GRUNetworkWithParams(nn.Module):\n",
    "    \"\"\"\n",
    "    RNN Network using GRU layers, accepting padded P matrix (as sequence)\n",
    "    and n, k, m parameters.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_feature_size, hidden_size, num_layers, param_input_size=3, output_size=1, dropout_prob=0.2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_feature_size (int): Number of features per timestep (padded n-k, e.g., max_nk).\n",
    "            hidden_size (int): Number of features in the hidden state h.\n",
    "            num_layers (int): Number of recurrent layers.\n",
    "            param_input_size (int): Number of parameter inputs (n, k, m -> 3).\n",
    "            output_size (int): Output neurons (1 for h_m).\n",
    "            dropout_prob (float): Dropout probability for GRU layers (if num_layers > 1) and FC layers.\n",
    "        \"\"\"\n",
    "        super(GRUNetworkWithParams, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.param_input_size = param_input_size\n",
    "\n",
    "        # GRU Layer: batch_first=True means input/output tensors are (batch, seq_len, features)\n",
    "        self.gru = nn.GRU(input_feature_size, hidden_size, num_layers,\n",
    "                          batch_first=True, dropout=dropout_prob if num_layers > 1 else 0)\n",
    "\n",
    "        # Fully Connected Layers: Input size is GRU hidden size + param size\n",
    "        combined_fc_input_size = hidden_size + param_input_size\n",
    "        self.fc1 = nn.Linear(combined_fc_input_size, hidden_size // 2) # Example intermediate layer\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc2 = nn.Linear(hidden_size // 2, output_size)\n",
    "\n",
    "    def forward(self, p_matrix, params):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            p_matrix (torch.Tensor): Padded P matrix. Shape: (batch, max_k, max_nk)\n",
    "            params (torch.Tensor): Normalized n, k, m values. Shape: (batch, 3)\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Predicted h_m value(s). Shape: (batch, 1)\n",
    "        \"\"\"\n",
    "        batch_size = p_matrix.size(0)\n",
    "        device = p_matrix.device # Get device from input tensor\n",
    "\n",
    "        # Initialize hidden state with zeros\n",
    "        # Shape: (num_layers, batch_size, hidden_size)\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "\n",
    "        # Pass P matrix sequence through GRU\n",
    "        # p_matrix is already (batch, seq_len=max_k, features=max_nk) due to batch_first=True\n",
    "        gru_out, hn = self.gru(p_matrix, h0)\n",
    "\n",
    "        # We only need the hidden state from the last layer of the last timestep\n",
    "        # hn has shape (num_layers, batch_size, hidden_size)\n",
    "        last_hidden_state = hn[-1] # Shape: (batch_size, hidden_size)\n",
    "\n",
    "        # Concatenate the last hidden state with the parameters\n",
    "        combined_input = torch.cat((last_hidden_state, params), dim=1) # Shape: (batch, hidden_size + 3)\n",
    "\n",
    "        # Pass through fully connected layers\n",
    "        out = self.fc1(combined_input)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# --- Example Instantiation (Adjust parameters as needed) ---\n",
    "# INPUT_FEATURES = 6  # Should be max_nk (padded n-k dimension)\n",
    "# HIDDEN_DIM = 128    # Size of LSTM/GRU hidden state\n",
    "# NUM_RNN_LAYERS = 2  # Number of stacked LSTM/GRU layers\n",
    "# PARAMS_DIM = 3      # For n, k, m\n",
    "# OUTPUT_DIM = 1      # Predicting h_m\n",
    "# DROPOUT = 0.3\n",
    "\n",
    "# lstm_model = LSTMNetworkWithParams(INPUT_FEATURES, HIDDEN_DIM, NUM_RNN_LAYERS, PARAMS_DIM, OUTPUT_DIM, DROPOUT)\n",
    "# gru_model = GRUNetworkWithParams(INPUT_FEATURES, HIDDEN_DIM, NUM_RNN_LAYERS, PARAMS_DIM, OUTPUT_DIM, DROPOUT)\n",
    "\n",
    "# print(\"LSTM Model Architecture:\")\n",
    "# print(lstm_model)\n",
    "# print(\"\\nGRU Model Architecture:\")\n",
    "# print(gru_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define functions for training and testing the model and data pre processing, plotting---\n",
    "def train_epoch_with_params(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"Trains the model (accepting params, h, P) for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    # Make sure this unpacking order matches the Dataset's __getitem__ return order\n",
    "    for i, batch_data in enumerate(dataloader):\n",
    "        # Unpack data correctly based on Dataset return order (params, h, P)\n",
    "        params, targets, p_matrices = batch_data\n",
    "        params, targets, p_matrices = params.to(device), targets.to(device), p_matrices.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Pass data to the model in the order its forward method expects\n",
    "        # Assuming models expect (p_matrix, params)\n",
    "        outputs = model(p_matrices, params)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss correctly using the actual batch size\n",
    "        running_loss += loss.item() * params.size(0)\n",
    "        total_samples += params.size(0)\n",
    "\n",
    "        ## --- Batch-level print ---\n",
    "        # if (i + 1) % 100 == 0:\n",
    "        #      print(f'  Batch {i+1}/{len(dataloader)}, Loss: {loss.item():.4f}')\n",
    "\n",
    "    # Calculate average loss for the epoch\n",
    "    epoch_loss = running_loss / total_samples if total_samples > 0 else 0.0\n",
    "    return epoch_loss\n",
    "\n",
    "# --- Keep validate_epoch_with_params as is (it doesn't have batch printing) ---\n",
    "def validate_epoch_with_params(model, dataloader, criterion, device):\n",
    "    \"\"\"Evaluates the model (accepting params, h, P) on the validation set.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Make sure this unpacking order matches the Dataset's __getitem__ return order\n",
    "        for batch_data in dataloader:\n",
    "            # Unpack data correctly (params, h, P)\n",
    "            params, targets, p_matrices = batch_data\n",
    "            params, targets, p_matrices = params.to(device), targets.to(device), p_matrices.to(device)\n",
    "\n",
    "            # Pass data to the model in the order its forward method expects\n",
    "            # Assuming models expect (p_matrix, params)\n",
    "            outputs = model(p_matrices, params)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            running_loss += loss.item() * params.size(0) # Use actual batch size\n",
    "            total_samples += params.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total_samples if total_samples > 0 else 0.0\n",
    "    return epoch_loss\n",
    "\n",
    "\n",
    "\n",
    "def load_and_split_data(train_folders, val_folders, max_k, max_nk, batch_size, val_split_ratio=0.2, num_workers=0, pin_memory=True, dataset_class=PickleFolderDataset):\n",
    "    \"\"\"\n",
    "    Loads data from specified folders, combines them, performs a random split,\n",
    "    and returns training and validation DataLoaders.\n",
    "\n",
    "    Args:\n",
    "        train_folders (list[str]): List of paths to folders containing training .pkl files.\n",
    "        val_folders (list[str]): List of paths to folders containing validation .pkl files.\n",
    "                                  (Data will be combined before splitting).\n",
    "        max_k (int): Max height for padding P matrices.\n",
    "        max_nk (int): Max width for padding P matrices.\n",
    "        batch_size (int): Batch size for DataLoaders.\n",
    "        val_split_ratio (float): Proportion of the *combined* data to use for validation (e.g., 0.2 for 20%).\n",
    "        num_workers (int): Number of worker processes for DataLoader.\n",
    "        pin_memory (bool): Whether to use pin_memory for DataLoader.\n",
    "        dataset_class (Dataset): The Dataset class to use (e.g., PickleFolderDataset).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (train_loader, val_loader)\n",
    "    \"\"\"\n",
    "    print(\"--- Preparing Data ---\")\n",
    "    all_files = []\n",
    "    for folder in train_folders + val_folders: # Combine paths from both lists\n",
    "         files = glob.glob(os.path.join(folder, '*.pkl'))\n",
    "         if not files:\n",
    "              print(f\"Warning: No .pkl files found in folder: {folder}\")\n",
    "         all_files.extend(files)\n",
    "\n",
    "    if not all_files:\n",
    "        raise FileNotFoundError(\"No .pkl files found in any of the specified train/validation folders.\")\n",
    "\n",
    "    print(f\"Found {len(all_files)} total .pkl files.\")\n",
    "\n",
    "    # Instantiate the dataset with the combined list of files\n",
    "    # Note: This loads ALL data into memory. May be an issue for extremely large datasets.\n",
    "    combined_dataset = dataset_class(\n",
    "        file_paths=all_files,\n",
    "        max_k=max_k,\n",
    "        max_nk=max_nk\n",
    "        # transform can be added here if needed\n",
    "    )\n",
    "\n",
    "    total_samples = len(combined_dataset)\n",
    "    print(f\"Total samples loaded from combined files: {total_samples}\")\n",
    "\n",
    "    # Perform random split\n",
    "    val_size = int(total_samples * val_split_ratio)\n",
    "    train_size = total_samples - val_size\n",
    "\n",
    "    if train_size <= 0 or val_size <= 0:\n",
    "         raise ValueError(f\"Calculated train ({train_size}) or validation ({val_size}) size is zero or less. Check data or split ratio.\")\n",
    "\n",
    "    print(f\"Splitting data: Training={train_size} ({100*(1-val_split_ratio):.1f}%), Validation={val_size} ({100*val_split_ratio:.1f}%)\")\n",
    "    train_dataset, val_dataset = random_split(combined_dataset, [train_size, val_size])\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory\n",
    "    )\n",
    "    print(\"DataLoaders created.\")\n",
    "    print(f\"Training batches: {len(train_loader)}, Validation batches: {len(val_loader)}\")\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "def run_training(model, train_loader, val_loader, criterion, optimizer, epochs, device, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Runs the training and validation loop for a given model.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to train.\n",
    "        train_loader (DataLoader): DataLoader for training data.\n",
    "        val_loader (DataLoader): DataLoader for validation data.\n",
    "        criterion (nn.Module): The loss function.\n",
    "        optimizer (Optimizer): The optimizer.\n",
    "        epochs (int): Number of epochs to train.\n",
    "        device (torch.device): Device to train on ('cuda' or 'cpu').\n",
    "        model_name (str): Name of the model for printing logs.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (train_losses, val_losses) lists containing loss per epoch.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Starting Training Loop for {model_name} ---\")\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float('inf')\n",
    "    start_time_train = time.time()\n",
    "\n",
    "    # Ensure train_epoch_with_params and validate_epoch_with_params expect (params, h, P)\n",
    "    # If they don't, they need to be redefined/updated before this function is called.\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs} ({model_name})\")\n",
    "\n",
    "        # Ensure train/validate functions handle the (params, h, P) order\n",
    "        train_loss = train_epoch_with_params(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss = validate_epoch_with_params(model, val_loader, criterion, device)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        epoch_duration = time.time() - epoch_start_time\n",
    "        print(f\"Epoch {epoch+1} Summary ({model_name}): Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Duration: {epoch_duration:.2f}s\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            print(f\"  {model_name} Val loss improved ({best_val_loss:.4f} -> {val_loss:.4f}).\")\n",
    "            best_val_loss = val_loss\n",
    "            # Optional: Save model checkpoint here\n",
    "            torch.save(model.state_dict(), f'best_{model_name.lower().replace(\" \",\"_\")}_final.pth')\n",
    "\n",
    "    total_time_train = time.time() - start_time_train\n",
    "    print(f\"\\n{model_name} Training Finished. Total time: {total_time_train:.2f} seconds\")\n",
    "    return train_losses, val_losses\n",
    "\n",
    "\n",
    "def plot_losses(results_dict):\n",
    "    \"\"\"\n",
    "    Plots training and validation losses for multiple models.\n",
    "\n",
    "    Args:\n",
    "        results_dict (dict): A dictionary where keys are model names and\n",
    "                             values are tuples of (train_losses, val_losses).\n",
    "                             Example: {'Dense': ([...], [...]), 'CNN': ([...], [...])}\n",
    "    \"\"\"\n",
    "    num_models = len(results_dict)\n",
    "    if num_models == 0:\n",
    "        print(\"No results to plot.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nPlotting losses...\")\n",
    "    # Adjust layout based on number of models\n",
    "    cols = 2\n",
    "    rows = (num_models + cols - 1) // cols\n",
    "    plt.figure(figsize=(6 * cols, 5 * rows))\n",
    "\n",
    "    i = 1\n",
    "    for model_name, (train_losses, val_losses) in results_dict.items():\n",
    "        if not train_losses or not val_losses:\n",
    "            print(f\"Skipping plot for {model_name} due to missing loss data.\")\n",
    "            continue\n",
    "        plt.subplot(rows, cols, i)\n",
    "        plt.plot(train_losses, label=f'{model_name} Train Loss')\n",
    "        plt.plot(val_losses, label=f'{model_name} Val Loss')\n",
    "        plt.title(f'{model_name} Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Log2 MSE Loss') # Assuming LogMSELoss was used\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        i += 1\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a small dataset (not the final one with 420,000) to train 4 different architecture (fully connected network, CNN, RNN with LSTM and GRU) to see their performance on this small dataset that contains not all combinaisons of (n,k,m) (only 10 000 data). But I think it is enough to get an idea of which model can do the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading NPZ Data from: ./data ---\n",
      "Loading data from 16 files...\n",
      "Finished loading. Total samples: 9400\n",
      "Total NPZ samples: 9400, Training: 7520, Validation: 1880\n",
      "NPZ DataLoaders created.\n",
      "\n",
      "--- Starting Dense Model Training Loop ---\n",
      "\n",
      "Epoch 1/25 (Dense Network)\n",
      "Epoch 1 Summary (Dense): Train Loss: 16.5512, Val Loss: 9.5666\n",
      "  Dense Val loss improved (inf -> 9.5666).\n",
      "\n",
      "Epoch 2/25 (Dense Network)\n",
      "Epoch 2 Summary (Dense): Train Loss: 8.4183, Val Loss: 7.9829\n",
      "  Dense Val loss improved (9.5666 -> 7.9829).\n",
      "\n",
      "Epoch 3/25 (Dense Network)\n",
      "Epoch 3 Summary (Dense): Train Loss: 7.5857, Val Loss: 7.6198\n",
      "  Dense Val loss improved (7.9829 -> 7.6198).\n",
      "\n",
      "Epoch 4/25 (Dense Network)\n",
      "Epoch 4 Summary (Dense): Train Loss: 7.3270, Val Loss: 7.4418\n",
      "  Dense Val loss improved (7.6198 -> 7.4418).\n",
      "\n",
      "Epoch 5/25 (Dense Network)\n",
      "Epoch 5 Summary (Dense): Train Loss: 7.1474, Val Loss: 7.2736\n",
      "  Dense Val loss improved (7.4418 -> 7.2736).\n",
      "\n",
      "Epoch 6/25 (Dense Network)\n",
      "Epoch 6 Summary (Dense): Train Loss: 6.9705, Val Loss: 7.0891\n",
      "  Dense Val loss improved (7.2736 -> 7.0891).\n",
      "\n",
      "Epoch 7/25 (Dense Network)\n",
      "Epoch 7 Summary (Dense): Train Loss: 6.7753, Val Loss: 6.8784\n",
      "  Dense Val loss improved (7.0891 -> 6.8784).\n",
      "\n",
      "Epoch 8/25 (Dense Network)\n",
      "Epoch 8 Summary (Dense): Train Loss: 6.5576, Val Loss: 6.6400\n",
      "  Dense Val loss improved (6.8784 -> 6.6400).\n",
      "\n",
      "Epoch 9/25 (Dense Network)\n",
      "Epoch 9 Summary (Dense): Train Loss: 6.3155, Val Loss: 6.3669\n",
      "  Dense Val loss improved (6.6400 -> 6.3669).\n",
      "\n",
      "Epoch 10/25 (Dense Network)\n",
      "Epoch 10 Summary (Dense): Train Loss: 6.0506, Val Loss: 6.0787\n",
      "  Dense Val loss improved (6.3669 -> 6.0787).\n",
      "\n",
      "Epoch 11/25 (Dense Network)\n",
      "Epoch 11 Summary (Dense): Train Loss: 5.7944, Val Loss: 5.8072\n",
      "  Dense Val loss improved (6.0787 -> 5.8072).\n",
      "\n",
      "Epoch 12/25 (Dense Network)\n",
      "Epoch 12 Summary (Dense): Train Loss: 5.5787, Val Loss: 5.5794\n",
      "  Dense Val loss improved (5.8072 -> 5.5794).\n",
      "\n",
      "Epoch 13/25 (Dense Network)\n",
      "Epoch 13 Summary (Dense): Train Loss: 5.4034, Val Loss: 5.4008\n",
      "  Dense Val loss improved (5.5794 -> 5.4008).\n",
      "\n",
      "Epoch 14/25 (Dense Network)\n",
      "Epoch 14 Summary (Dense): Train Loss: 5.2714, Val Loss: 5.2606\n",
      "  Dense Val loss improved (5.4008 -> 5.2606).\n",
      "\n",
      "Epoch 15/25 (Dense Network)\n",
      "Epoch 15 Summary (Dense): Train Loss: 5.1476, Val Loss: 5.1294\n",
      "  Dense Val loss improved (5.2606 -> 5.1294).\n",
      "\n",
      "Epoch 16/25 (Dense Network)\n",
      "Epoch 16 Summary (Dense): Train Loss: 5.0208, Val Loss: 4.9979\n",
      "  Dense Val loss improved (5.1294 -> 4.9979).\n",
      "\n",
      "Epoch 17/25 (Dense Network)\n",
      "Epoch 17 Summary (Dense): Train Loss: 4.8837, Val Loss: 4.8018\n",
      "  Dense Val loss improved (4.9979 -> 4.8018).\n",
      "\n",
      "Epoch 18/25 (Dense Network)\n",
      "Epoch 18 Summary (Dense): Train Loss: 4.7439, Val Loss: 4.6831\n",
      "  Dense Val loss improved (4.8018 -> 4.6831).\n",
      "\n",
      "Epoch 19/25 (Dense Network)\n",
      "Epoch 19 Summary (Dense): Train Loss: 4.6162, Val Loss: 4.5568\n",
      "  Dense Val loss improved (4.6831 -> 4.5568).\n",
      "\n",
      "Epoch 20/25 (Dense Network)\n",
      "Epoch 20 Summary (Dense): Train Loss: 4.5165, Val Loss: 4.4411\n",
      "  Dense Val loss improved (4.5568 -> 4.4411).\n",
      "\n",
      "Epoch 21/25 (Dense Network)\n",
      "Epoch 21 Summary (Dense): Train Loss: 4.4299, Val Loss: 4.3580\n",
      "  Dense Val loss improved (4.4411 -> 4.3580).\n",
      "\n",
      "Epoch 22/25 (Dense Network)\n",
      "Epoch 22 Summary (Dense): Train Loss: 4.3542, Val Loss: 4.3082\n",
      "  Dense Val loss improved (4.3580 -> 4.3082).\n",
      "\n",
      "Epoch 23/25 (Dense Network)\n",
      "Epoch 23 Summary (Dense): Train Loss: 4.2793, Val Loss: 4.2087\n",
      "  Dense Val loss improved (4.3082 -> 4.2087).\n",
      "\n",
      "Epoch 24/25 (Dense Network)\n",
      "Epoch 24 Summary (Dense): Train Loss: 4.2153, Val Loss: 4.1398\n",
      "  Dense Val loss improved (4.2087 -> 4.1398).\n",
      "\n",
      "Epoch 25/25 (Dense Network)\n",
      "Epoch 25 Summary (Dense): Train Loss: 4.1626, Val Loss: 4.0821\n",
      "  Dense Val loss improved (4.1398 -> 4.0821).\n",
      "\n",
      "--- Starting CNN Model Training Loop ---\n",
      "\n",
      "Epoch 1/25 (CNN Network)\n",
      "Epoch 1 Summary (CNN): Train Loss: 10.7955, Val Loss: 7.8248\n",
      "  CNN Val loss improved (inf -> 7.8248).\n",
      "\n",
      "Epoch 2/25 (CNN Network)\n",
      "Epoch 2 Summary (CNN): Train Loss: 7.4651, Val Loss: 7.3073\n",
      "  CNN Val loss improved (7.8248 -> 7.3073).\n",
      "\n",
      "Epoch 3/25 (CNN Network)\n",
      "Epoch 3 Summary (CNN): Train Loss: 6.6673, Val Loss: 6.1812\n",
      "  CNN Val loss improved (7.3073 -> 6.1812).\n",
      "\n",
      "Epoch 4/25 (CNN Network)\n",
      "Epoch 4 Summary (CNN): Train Loss: 5.7996, Val Loss: 5.6526\n",
      "  CNN Val loss improved (6.1812 -> 5.6526).\n",
      "\n",
      "Epoch 5/25 (CNN Network)\n",
      "Epoch 5 Summary (CNN): Train Loss: 5.4834, Val Loss: 5.3605\n",
      "  CNN Val loss improved (5.6526 -> 5.3605).\n",
      "\n",
      "Epoch 6/25 (CNN Network)\n",
      "Epoch 6 Summary (CNN): Train Loss: 5.3352, Val Loss: 5.2708\n",
      "  CNN Val loss improved (5.3605 -> 5.2708).\n",
      "\n",
      "Epoch 7/25 (CNN Network)\n",
      "Epoch 7 Summary (CNN): Train Loss: 5.2665, Val Loss: 5.2133\n",
      "  CNN Val loss improved (5.2708 -> 5.2133).\n",
      "\n",
      "Epoch 8/25 (CNN Network)\n",
      "Epoch 8 Summary (CNN): Train Loss: 5.1999, Val Loss: 5.1892\n",
      "  CNN Val loss improved (5.2133 -> 5.1892).\n",
      "\n",
      "Epoch 9/25 (CNN Network)\n",
      "Epoch 9 Summary (CNN): Train Loss: 5.1536, Val Loss: 5.7480\n",
      "\n",
      "Epoch 10/25 (CNN Network)\n",
      "Epoch 10 Summary (CNN): Train Loss: 5.1125, Val Loss: 5.7205\n",
      "\n",
      "Epoch 11/25 (CNN Network)\n",
      "Epoch 11 Summary (CNN): Train Loss: 5.0826, Val Loss: 5.7073\n",
      "\n",
      "Epoch 12/25 (CNN Network)\n",
      "Epoch 12 Summary (CNN): Train Loss: 5.0662, Val Loss: 5.6668\n",
      "\n",
      "Epoch 13/25 (CNN Network)\n",
      "Epoch 13 Summary (CNN): Train Loss: 5.0231, Val Loss: 5.0400\n",
      "  CNN Val loss improved (5.1892 -> 5.0400).\n",
      "\n",
      "Epoch 14/25 (CNN Network)\n",
      "Epoch 14 Summary (CNN): Train Loss: 5.0004, Val Loss: 5.6384\n",
      "\n",
      "Epoch 15/25 (CNN Network)\n",
      "Epoch 15 Summary (CNN): Train Loss: 4.9730, Val Loss: 4.9794\n",
      "  CNN Val loss improved (5.0400 -> 4.9794).\n",
      "\n",
      "Epoch 16/25 (CNN Network)\n",
      "Epoch 16 Summary (CNN): Train Loss: 4.9490, Val Loss: 4.9869\n",
      "\n",
      "Epoch 17/25 (CNN Network)\n",
      "Epoch 17 Summary (CNN): Train Loss: 4.9312, Val Loss: 4.9772\n",
      "  CNN Val loss improved (4.9794 -> 4.9772).\n",
      "\n",
      "Epoch 18/25 (CNN Network)\n",
      "Epoch 18 Summary (CNN): Train Loss: 4.9083, Val Loss: 4.9447\n",
      "  CNN Val loss improved (4.9772 -> 4.9447).\n",
      "\n",
      "Epoch 19/25 (CNN Network)\n",
      "Epoch 19 Summary (CNN): Train Loss: 4.8997, Val Loss: 4.9511\n",
      "\n",
      "Epoch 20/25 (CNN Network)\n",
      "Epoch 20 Summary (CNN): Train Loss: 4.8712, Val Loss: 4.9209\n",
      "  CNN Val loss improved (4.9447 -> 4.9209).\n",
      "\n",
      "Epoch 21/25 (CNN Network)\n",
      "Epoch 21 Summary (CNN): Train Loss: 4.8548, Val Loss: 4.9141\n",
      "  CNN Val loss improved (4.9209 -> 4.9141).\n",
      "\n",
      "Epoch 22/25 (CNN Network)\n",
      "Epoch 22 Summary (CNN): Train Loss: 4.8314, Val Loss: 4.9413\n",
      "\n",
      "Epoch 23/25 (CNN Network)\n",
      "Epoch 23 Summary (CNN): Train Loss: 4.8275, Val Loss: 4.9243\n",
      "\n",
      "Epoch 24/25 (CNN Network)\n",
      "Epoch 24 Summary (CNN): Train Loss: 4.8167, Val Loss: 4.9437\n",
      "\n",
      "Epoch 25/25 (CNN Network)\n",
      "Epoch 25 Summary (CNN): Train Loss: 4.8053, Val Loss: 4.8952\n",
      "  CNN Val loss improved (4.9141 -> 4.8952).\n",
      "\n",
      "--- Starting LSTM Model Training Loop ---\n",
      "\n",
      "Epoch 1/25 (LSTM Network)\n",
      "Epoch 1 Summary (LSTM): Train Loss: 233.6698, Val Loss: 78.3099\n",
      "  LSTM Val loss improved (inf -> 78.3099).\n",
      "\n",
      "Epoch 2/25 (LSTM Network)\n",
      "Epoch 2 Summary (LSTM): Train Loss: 52.4815, Val Loss: 34.7814\n",
      "  LSTM Val loss improved (78.3099 -> 34.7814).\n",
      "\n",
      "Epoch 3/25 (LSTM Network)\n",
      "Epoch 3 Summary (LSTM): Train Loss: 29.9125, Val Loss: 24.8271\n",
      "  LSTM Val loss improved (34.7814 -> 24.8271).\n",
      "\n",
      "Epoch 4/25 (LSTM Network)\n",
      "Epoch 4 Summary (LSTM): Train Loss: 23.2429, Val Loss: 20.2910\n",
      "  LSTM Val loss improved (24.8271 -> 20.2910).\n",
      "\n",
      "Epoch 5/25 (LSTM Network)\n",
      "Epoch 5 Summary (LSTM): Train Loss: 19.7253, Val Loss: 17.5859\n",
      "  LSTM Val loss improved (20.2910 -> 17.5859).\n",
      "\n",
      "Epoch 6/25 (LSTM Network)\n",
      "Epoch 6 Summary (LSTM): Train Loss: 17.4638, Val Loss: 15.7690\n",
      "  LSTM Val loss improved (17.5859 -> 15.7690).\n",
      "\n",
      "Epoch 7/25 (LSTM Network)\n",
      "Epoch 7 Summary (LSTM): Train Loss: 16.0088, Val Loss: 14.4273\n",
      "  LSTM Val loss improved (15.7690 -> 14.4273).\n",
      "\n",
      "Epoch 8/25 (LSTM Network)\n",
      "Epoch 8 Summary (LSTM): Train Loss: 14.7810, Val Loss: 13.3771\n",
      "  LSTM Val loss improved (14.4273 -> 13.3771).\n",
      "\n",
      "Epoch 9/25 (LSTM Network)\n",
      "Epoch 9 Summary (LSTM): Train Loss: 13.8402, Val Loss: 12.5388\n",
      "  LSTM Val loss improved (13.3771 -> 12.5388).\n",
      "\n",
      "Epoch 10/25 (LSTM Network)\n",
      "Epoch 10 Summary (LSTM): Train Loss: 13.0130, Val Loss: 11.8476\n",
      "  LSTM Val loss improved (12.5388 -> 11.8476).\n",
      "\n",
      "Epoch 11/25 (LSTM Network)\n",
      "Epoch 11 Summary (LSTM): Train Loss: 12.2759, Val Loss: 11.2766\n",
      "  LSTM Val loss improved (11.8476 -> 11.2766).\n",
      "\n",
      "Epoch 12/25 (LSTM Network)\n",
      "Epoch 12 Summary (LSTM): Train Loss: 11.7419, Val Loss: 10.7915\n",
      "  LSTM Val loss improved (11.2766 -> 10.7915).\n",
      "\n",
      "Epoch 13/25 (LSTM Network)\n",
      "Epoch 13 Summary (LSTM): Train Loss: 11.3226, Val Loss: 10.3798\n",
      "  LSTM Val loss improved (10.7915 -> 10.3798).\n",
      "\n",
      "Epoch 14/25 (LSTM Network)\n",
      "Epoch 14 Summary (LSTM): Train Loss: 10.9732, Val Loss: 10.0259\n",
      "  LSTM Val loss improved (10.3798 -> 10.0259).\n",
      "\n",
      "Epoch 15/25 (LSTM Network)\n",
      "Epoch 15 Summary (LSTM): Train Loss: 10.5273, Val Loss: 9.7201\n",
      "  LSTM Val loss improved (10.0259 -> 9.7201).\n",
      "\n",
      "Epoch 16/25 (LSTM Network)\n",
      "Epoch 16 Summary (LSTM): Train Loss: 10.2758, Val Loss: 9.4583\n",
      "  LSTM Val loss improved (9.7201 -> 9.4583).\n",
      "\n",
      "Epoch 17/25 (LSTM Network)\n",
      "Epoch 17 Summary (LSTM): Train Loss: 9.9207, Val Loss: 9.2261\n",
      "  LSTM Val loss improved (9.4583 -> 9.2261).\n",
      "\n",
      "Epoch 18/25 (LSTM Network)\n",
      "Epoch 18 Summary (LSTM): Train Loss: 9.8164, Val Loss: 9.0280\n",
      "  LSTM Val loss improved (9.2261 -> 9.0280).\n",
      "\n",
      "Epoch 19/25 (LSTM Network)\n",
      "Epoch 19 Summary (LSTM): Train Loss: 9.4848, Val Loss: 8.8532\n",
      "  LSTM Val loss improved (9.0280 -> 8.8532).\n",
      "\n",
      "Epoch 20/25 (LSTM Network)\n",
      "Epoch 20 Summary (LSTM): Train Loss: 9.4048, Val Loss: 8.6995\n",
      "  LSTM Val loss improved (8.8532 -> 8.6995).\n",
      "\n",
      "Epoch 21/25 (LSTM Network)\n",
      "Epoch 21 Summary (LSTM): Train Loss: 9.2116, Val Loss: 8.5645\n",
      "  LSTM Val loss improved (8.6995 -> 8.5645).\n",
      "\n",
      "Epoch 22/25 (LSTM Network)\n",
      "Epoch 22 Summary (LSTM): Train Loss: 9.0820, Val Loss: 8.4470\n",
      "  LSTM Val loss improved (8.5645 -> 8.4470).\n",
      "\n",
      "Epoch 23/25 (LSTM Network)\n",
      "Epoch 23 Summary (LSTM): Train Loss: 8.9373, Val Loss: 8.3433\n",
      "  LSTM Val loss improved (8.4470 -> 8.3433).\n",
      "\n",
      "Epoch 24/25 (LSTM Network)\n",
      "Epoch 24 Summary (LSTM): Train Loss: 8.7049, Val Loss: 8.2527\n",
      "  LSTM Val loss improved (8.3433 -> 8.2527).\n",
      "\n",
      "Epoch 25/25 (LSTM Network)\n",
      "Epoch 25 Summary (LSTM): Train Loss: 8.7533, Val Loss: 8.1720\n",
      "  LSTM Val loss improved (8.2527 -> 8.1720).\n",
      "\n",
      "Epoch 26/25 (LSTM Network)\n",
      "Epoch 26 Summary (LSTM): Train Loss: 8.5693, Val Loss: 8.1001\n",
      "  LSTM Val loss improved (8.1720 -> 8.1001).\n",
      "\n",
      "Epoch 27/25 (LSTM Network)\n",
      "Epoch 27 Summary (LSTM): Train Loss: 8.5204, Val Loss: 8.0305\n",
      "  LSTM Val loss improved (8.1001 -> 8.0305).\n",
      "\n",
      "Epoch 28/25 (LSTM Network)\n",
      "Epoch 28 Summary (LSTM): Train Loss: 8.3022, Val Loss: 7.4706\n",
      "  LSTM Val loss improved (8.0305 -> 7.4706).\n",
      "\n",
      "Epoch 29/25 (LSTM Network)\n",
      "Epoch 29 Summary (LSTM): Train Loss: 7.9770, Val Loss: 7.1721\n",
      "  LSTM Val loss improved (7.4706 -> 7.1721).\n",
      "\n",
      "Epoch 30/25 (LSTM Network)\n",
      "Epoch 30 Summary (LSTM): Train Loss: 7.6421, Val Loss: 7.0238\n",
      "  LSTM Val loss improved (7.1721 -> 7.0238).\n",
      "\n",
      "Epoch 31/25 (LSTM Network)\n",
      "Epoch 31 Summary (LSTM): Train Loss: 7.4758, Val Loss: 6.9101\n",
      "  LSTM Val loss improved (7.0238 -> 6.9101).\n",
      "\n",
      "Epoch 32/25 (LSTM Network)\n",
      "Epoch 32 Summary (LSTM): Train Loss: 7.3088, Val Loss: 6.8112\n",
      "  LSTM Val loss improved (6.9101 -> 6.8112).\n",
      "\n",
      "Epoch 33/25 (LSTM Network)\n",
      "Epoch 33 Summary (LSTM): Train Loss: 7.1414, Val Loss: 6.6931\n",
      "  LSTM Val loss improved (6.8112 -> 6.6931).\n",
      "\n",
      "Epoch 34/25 (LSTM Network)\n",
      "Epoch 34 Summary (LSTM): Train Loss: 7.1306, Val Loss: 6.5991\n",
      "  LSTM Val loss improved (6.6931 -> 6.5991).\n",
      "\n",
      "Epoch 35/25 (LSTM Network)\n",
      "Epoch 35 Summary (LSTM): Train Loss: 6.9536, Val Loss: 6.5447\n",
      "  LSTM Val loss improved (6.5991 -> 6.5447).\n",
      "\n",
      "Epoch 36/25 (LSTM Network)\n",
      "Epoch 36 Summary (LSTM): Train Loss: 6.8668, Val Loss: 6.4585\n",
      "  LSTM Val loss improved (6.5447 -> 6.4585).\n",
      "\n",
      "Epoch 37/25 (LSTM Network)\n",
      "Epoch 37 Summary (LSTM): Train Loss: 6.7853, Val Loss: 6.3546\n",
      "  LSTM Val loss improved (6.4585 -> 6.3546).\n",
      "\n",
      "Epoch 38/25 (LSTM Network)\n",
      "Epoch 38 Summary (LSTM): Train Loss: 6.7005, Val Loss: 6.2867\n",
      "  LSTM Val loss improved (6.3546 -> 6.2867).\n",
      "\n",
      "Epoch 39/25 (LSTM Network)\n",
      "Epoch 39 Summary (LSTM): Train Loss: 6.6311, Val Loss: 6.1911\n",
      "  LSTM Val loss improved (6.2867 -> 6.1911).\n",
      "\n",
      "Epoch 40/25 (LSTM Network)\n",
      "Epoch 40 Summary (LSTM): Train Loss: 6.4776, Val Loss: 6.1121\n",
      "  LSTM Val loss improved (6.1911 -> 6.1121).\n",
      "\n",
      "Epoch 41/25 (LSTM Network)\n",
      "Epoch 41 Summary (LSTM): Train Loss: 6.4193, Val Loss: 6.0230\n",
      "  LSTM Val loss improved (6.1121 -> 6.0230).\n",
      "\n",
      "Epoch 42/25 (LSTM Network)\n",
      "Epoch 42 Summary (LSTM): Train Loss: 6.4369, Val Loss: 5.9512\n",
      "  LSTM Val loss improved (6.0230 -> 5.9512).\n",
      "\n",
      "Epoch 43/25 (LSTM Network)\n",
      "Epoch 43 Summary (LSTM): Train Loss: 6.1910, Val Loss: 5.9042\n",
      "  LSTM Val loss improved (5.9512 -> 5.9042).\n",
      "\n",
      "Epoch 44/25 (LSTM Network)\n",
      "Epoch 44 Summary (LSTM): Train Loss: 6.0908, Val Loss: 5.8603\n",
      "  LSTM Val loss improved (5.9042 -> 5.8603).\n",
      "\n",
      "Epoch 45/25 (LSTM Network)\n",
      "Epoch 45 Summary (LSTM): Train Loss: 6.1102, Val Loss: 5.7870\n",
      "  LSTM Val loss improved (5.8603 -> 5.7870).\n",
      "\n",
      "Epoch 46/25 (LSTM Network)\n",
      "Epoch 46 Summary (LSTM): Train Loss: 5.9349, Val Loss: 5.7044\n",
      "  LSTM Val loss improved (5.7870 -> 5.7044).\n",
      "\n",
      "Epoch 47/25 (LSTM Network)\n",
      "Epoch 47 Summary (LSTM): Train Loss: 5.9365, Val Loss: 5.6585\n",
      "  LSTM Val loss improved (5.7044 -> 5.6585).\n",
      "\n",
      "Epoch 48/25 (LSTM Network)\n",
      "Epoch 48 Summary (LSTM): Train Loss: 5.9276, Val Loss: 5.6242\n",
      "  LSTM Val loss improved (5.6585 -> 5.6242).\n",
      "\n",
      "Epoch 49/25 (LSTM Network)\n",
      "Epoch 49 Summary (LSTM): Train Loss: 5.7849, Val Loss: 5.5804\n",
      "  LSTM Val loss improved (5.6242 -> 5.5804).\n",
      "\n",
      "Epoch 50/25 (LSTM Network)\n",
      "Epoch 50 Summary (LSTM): Train Loss: 5.6962, Val Loss: 5.5501\n",
      "  LSTM Val loss improved (5.5804 -> 5.5501).\n",
      "\n",
      "--- Starting GRU Model Training Loop ---\n",
      "\n",
      "Epoch 1/25 (GRU Network)\n",
      "Epoch 1 Summary (GRU): Train Loss: 171.6858, Val Loss: 59.8535\n",
      "  GRU Val loss improved (inf -> 59.8535).\n",
      "\n",
      "Epoch 2/25 (GRU Network)\n",
      "Epoch 2 Summary (GRU): Train Loss: 51.4849, Val Loss: 42.0732\n",
      "  GRU Val loss improved (59.8535 -> 42.0732).\n",
      "\n",
      "Epoch 3/25 (GRU Network)\n",
      "Epoch 3 Summary (GRU): Train Loss: 40.6692, Val Loss: 34.2579\n",
      "  GRU Val loss improved (42.0732 -> 34.2579).\n",
      "\n",
      "Epoch 4/25 (GRU Network)\n",
      "Epoch 4 Summary (GRU): Train Loss: 34.9311, Val Loss: 29.5794\n",
      "  GRU Val loss improved (34.2579 -> 29.5794).\n",
      "\n",
      "Epoch 5/25 (GRU Network)\n",
      "Epoch 5 Summary (GRU): Train Loss: 31.1217, Val Loss: 26.2806\n",
      "  GRU Val loss improved (29.5794 -> 26.2806).\n",
      "\n",
      "Epoch 6/25 (GRU Network)\n",
      "Epoch 6 Summary (GRU): Train Loss: 27.9575, Val Loss: 23.7846\n",
      "  GRU Val loss improved (26.2806 -> 23.7846).\n",
      "\n",
      "Epoch 7/25 (GRU Network)\n",
      "Epoch 7 Summary (GRU): Train Loss: 26.6020, Val Loss: 21.8194\n",
      "  GRU Val loss improved (23.7846 -> 21.8194).\n",
      "\n",
      "Epoch 8/25 (GRU Network)\n",
      "Epoch 8 Summary (GRU): Train Loss: 24.0715, Val Loss: 20.2154\n",
      "  GRU Val loss improved (21.8194 -> 20.2154).\n",
      "\n",
      "Epoch 9/25 (GRU Network)\n",
      "Epoch 9 Summary (GRU): Train Loss: 22.5275, Val Loss: 18.8675\n",
      "  GRU Val loss improved (20.2154 -> 18.8675).\n",
      "\n",
      "Epoch 10/25 (GRU Network)\n",
      "Epoch 10 Summary (GRU): Train Loss: 21.7786, Val Loss: 17.7273\n",
      "  GRU Val loss improved (18.8675 -> 17.7273).\n",
      "\n",
      "Epoch 11/25 (GRU Network)\n",
      "Epoch 11 Summary (GRU): Train Loss: 20.3958, Val Loss: 16.7442\n",
      "  GRU Val loss improved (17.7273 -> 16.7442).\n",
      "\n",
      "Epoch 12/25 (GRU Network)\n",
      "Epoch 12 Summary (GRU): Train Loss: 19.3151, Val Loss: 15.8896\n",
      "  GRU Val loss improved (16.7442 -> 15.8896).\n",
      "\n",
      "Epoch 13/25 (GRU Network)\n",
      "Epoch 13 Summary (GRU): Train Loss: 18.2012, Val Loss: 15.1316\n",
      "  GRU Val loss improved (15.8896 -> 15.1316).\n",
      "\n",
      "Epoch 14/25 (GRU Network)\n",
      "Epoch 14 Summary (GRU): Train Loss: 17.5463, Val Loss: 14.4565\n",
      "  GRU Val loss improved (15.1316 -> 14.4565).\n",
      "\n",
      "Epoch 15/25 (GRU Network)\n",
      "Epoch 15 Summary (GRU): Train Loss: 16.8806, Val Loss: 13.8561\n",
      "  GRU Val loss improved (14.4565 -> 13.8561).\n",
      "\n",
      "Epoch 16/25 (GRU Network)\n",
      "Epoch 16 Summary (GRU): Train Loss: 16.1214, Val Loss: 13.3227\n",
      "  GRU Val loss improved (13.8561 -> 13.3227).\n",
      "\n",
      "Epoch 17/25 (GRU Network)\n",
      "Epoch 17 Summary (GRU): Train Loss: 15.4159, Val Loss: 12.8324\n",
      "  GRU Val loss improved (13.3227 -> 12.8324).\n",
      "\n",
      "Epoch 18/25 (GRU Network)\n",
      "Epoch 18 Summary (GRU): Train Loss: 15.0165, Val Loss: 12.3963\n",
      "  GRU Val loss improved (12.8324 -> 12.3963).\n",
      "\n",
      "Epoch 19/25 (GRU Network)\n",
      "Epoch 19 Summary (GRU): Train Loss: 14.6404, Val Loss: 11.9937\n",
      "  GRU Val loss improved (12.3963 -> 11.9937).\n",
      "\n",
      "Epoch 20/25 (GRU Network)\n",
      "Epoch 20 Summary (GRU): Train Loss: 14.1506, Val Loss: 11.6298\n",
      "  GRU Val loss improved (11.9937 -> 11.6298).\n",
      "\n",
      "Epoch 21/25 (GRU Network)\n",
      "Epoch 21 Summary (GRU): Train Loss: 13.4471, Val Loss: 11.2995\n",
      "  GRU Val loss improved (11.6298 -> 11.2995).\n",
      "\n",
      "Epoch 22/25 (GRU Network)\n",
      "Epoch 22 Summary (GRU): Train Loss: 13.1911, Val Loss: 10.9975\n",
      "  GRU Val loss improved (11.2995 -> 10.9975).\n",
      "\n",
      "Epoch 23/25 (GRU Network)\n",
      "Epoch 23 Summary (GRU): Train Loss: 12.8043, Val Loss: 10.7179\n",
      "  GRU Val loss improved (10.9975 -> 10.7179).\n",
      "\n",
      "Epoch 24/25 (GRU Network)\n",
      "Epoch 24 Summary (GRU): Train Loss: 12.4766, Val Loss: 10.4589\n",
      "  GRU Val loss improved (10.7179 -> 10.4589).\n",
      "\n",
      "Epoch 25/25 (GRU Network)\n",
      "Epoch 25 Summary (GRU): Train Loss: 12.2540, Val Loss: 10.2261\n",
      "  GRU Val loss improved (10.4589 -> 10.2261).\n",
      "\n",
      "Epoch 26/25 (GRU Network)\n",
      "Epoch 26 Summary (GRU): Train Loss: 12.0176, Val Loss: 10.0121\n",
      "  GRU Val loss improved (10.2261 -> 10.0121).\n",
      "\n",
      "Epoch 27/25 (GRU Network)\n",
      "Epoch 27 Summary (GRU): Train Loss: 11.9123, Val Loss: 9.8129\n",
      "  GRU Val loss improved (10.0121 -> 9.8129).\n",
      "\n",
      "Epoch 28/25 (GRU Network)\n",
      "Epoch 28 Summary (GRU): Train Loss: 11.5851, Val Loss: 9.6268\n",
      "  GRU Val loss improved (9.8129 -> 9.6268).\n",
      "\n",
      "Epoch 29/25 (GRU Network)\n",
      "Epoch 29 Summary (GRU): Train Loss: 11.3549, Val Loss: 9.4565\n",
      "  GRU Val loss improved (9.6268 -> 9.4565).\n",
      "\n",
      "Epoch 30/25 (GRU Network)\n",
      "Epoch 30 Summary (GRU): Train Loss: 10.9568, Val Loss: 9.3013\n",
      "  GRU Val loss improved (9.4565 -> 9.3013).\n",
      "\n",
      "Epoch 31/25 (GRU Network)\n",
      "Epoch 31 Summary (GRU): Train Loss: 10.8011, Val Loss: 9.1572\n",
      "  GRU Val loss improved (9.3013 -> 9.1572).\n",
      "\n",
      "Epoch 32/25 (GRU Network)\n",
      "Epoch 32 Summary (GRU): Train Loss: 10.6647, Val Loss: 9.0259\n",
      "  GRU Val loss improved (9.1572 -> 9.0259).\n",
      "\n",
      "Epoch 33/25 (GRU Network)\n",
      "Epoch 33 Summary (GRU): Train Loss: 10.2898, Val Loss: 8.9012\n",
      "  GRU Val loss improved (9.0259 -> 8.9012).\n",
      "\n",
      "Epoch 34/25 (GRU Network)\n",
      "Epoch 34 Summary (GRU): Train Loss: 10.4064, Val Loss: 8.7888\n",
      "  GRU Val loss improved (8.9012 -> 8.7888).\n",
      "\n",
      "Epoch 35/25 (GRU Network)\n",
      "Epoch 35 Summary (GRU): Train Loss: 10.2386, Val Loss: 8.6869\n",
      "  GRU Val loss improved (8.7888 -> 8.6869).\n",
      "\n",
      "Epoch 36/25 (GRU Network)\n",
      "Epoch 36 Summary (GRU): Train Loss: 9.9846, Val Loss: 8.5894\n",
      "  GRU Val loss improved (8.6869 -> 8.5894).\n",
      "\n",
      "Epoch 37/25 (GRU Network)\n",
      "Epoch 37 Summary (GRU): Train Loss: 9.7831, Val Loss: 8.5026\n",
      "  GRU Val loss improved (8.5894 -> 8.5026).\n",
      "\n",
      "Epoch 38/25 (GRU Network)\n",
      "Epoch 38 Summary (GRU): Train Loss: 10.0261, Val Loss: 8.4207\n",
      "  GRU Val loss improved (8.5026 -> 8.4207).\n",
      "\n",
      "Epoch 39/25 (GRU Network)\n",
      "Epoch 39 Summary (GRU): Train Loss: 9.5229, Val Loss: 8.3455\n",
      "  GRU Val loss improved (8.4207 -> 8.3455).\n",
      "\n",
      "Epoch 40/25 (GRU Network)\n",
      "Epoch 40 Summary (GRU): Train Loss: 9.4422, Val Loss: 8.2783\n",
      "  GRU Val loss improved (8.3455 -> 8.2783).\n",
      "\n",
      "Epoch 41/25 (GRU Network)\n",
      "Epoch 41 Summary (GRU): Train Loss: 9.6959, Val Loss: 8.2181\n",
      "  GRU Val loss improved (8.2783 -> 8.2181).\n",
      "\n",
      "Epoch 42/25 (GRU Network)\n",
      "Epoch 42 Summary (GRU): Train Loss: 9.5352, Val Loss: 8.1633\n",
      "  GRU Val loss improved (8.2181 -> 8.1633).\n",
      "\n",
      "Epoch 43/25 (GRU Network)\n",
      "Epoch 43 Summary (GRU): Train Loss: 9.0504, Val Loss: 8.1126\n",
      "  GRU Val loss improved (8.1633 -> 8.1126).\n",
      "\n",
      "Epoch 44/25 (GRU Network)\n",
      "Epoch 44 Summary (GRU): Train Loss: 9.3529, Val Loss: 8.0658\n",
      "  GRU Val loss improved (8.1126 -> 8.0658).\n",
      "\n",
      "Epoch 45/25 (GRU Network)\n",
      "Epoch 45 Summary (GRU): Train Loss: 9.3055, Val Loss: 8.0230\n",
      "  GRU Val loss improved (8.0658 -> 8.0230).\n",
      "\n",
      "Epoch 46/25 (GRU Network)\n",
      "Epoch 46 Summary (GRU): Train Loss: 8.8976, Val Loss: 7.9849\n",
      "  GRU Val loss improved (8.0230 -> 7.9849).\n",
      "\n",
      "Epoch 47/25 (GRU Network)\n",
      "Epoch 47 Summary (GRU): Train Loss: 8.7017, Val Loss: 7.9506\n",
      "  GRU Val loss improved (7.9849 -> 7.9506).\n",
      "\n",
      "Epoch 48/25 (GRU Network)\n",
      "Epoch 48 Summary (GRU): Train Loss: 8.8652, Val Loss: 7.9202\n",
      "  GRU Val loss improved (7.9506 -> 7.9202).\n",
      "\n",
      "Epoch 49/25 (GRU Network)\n",
      "Epoch 49 Summary (GRU): Train Loss: 8.7621, Val Loss: 7.8923\n",
      "  GRU Val loss improved (7.9202 -> 7.8923).\n",
      "\n",
      "Epoch 50/25 (GRU Network)\n",
      "Epoch 50 Summary (GRU): Train Loss: 8.6626, Val Loss: 7.8692\n",
      "  GRU Val loss improved (7.8923 -> 7.8692).\n",
      "\n",
      "--- Final Validation Losses (Log2 MSE) ---\n",
      "Dense Network: 4.0821\n",
      "CNN Network:   4.8952\n",
      "LSTM Network:  5.5501\n",
      "GRU Network:   7.8692\n",
      "\n",
      "Plotting losses for all models...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "DATA_FOLDER = './data' \n",
    "MAX_K = 6\n",
    "MAX_NK = 6\n",
    "PADDED_P_MATRIX_FLAT_SIZE = MAX_K * MAX_NK # 36\n",
    "PARAMS_SIZE = 3 # n, k, m\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# --- Hyperparameters ---\n",
    "LEARNING_RATE_DENSE = 0.001\n",
    "LEARNING_RATE_CNN = 0.001\n",
    "LEARNING_RATE_LSTM = 0.001 # Added for LSTM\n",
    "LEARNING_RATE_GRU = 0.001  # Added for GRU\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 25 # You might adjust this per model type later\n",
    "VALIDATION_SPLIT = 0.2\n",
    "# --- RNN Hyperparameters ---\n",
    "RNN_INPUT_FEATURES = MAX_NK  # Features per timestep (padded n-k)\n",
    "RNN_HIDDEN_DIM = 64       # Size of LSTM/GRU hidden state\n",
    "RNN_NUM_LAYERS = 2        # Number of stacked LSTM/GRU layers\n",
    "RNN_DROPOUT = 0.2         # Dropout probability\n",
    "\n",
    "# --- Initialize lists for results ---\n",
    "dense_train_losses = []\n",
    "dense_val_losses = []\n",
    "cnn_train_losses = []\n",
    "cnn_val_losses = []\n",
    "lstm_train_losses = [] # Added for LSTM\n",
    "lstm_val_losses = []   # Added for LSTM\n",
    "gru_train_losses = []  # Added for GRU\n",
    "gru_val_losses = []    # Added for GRU\n",
    "\n",
    "\n",
    "# --- Load Data ---\n",
    "try:\n",
    "    print(f\"\\n--- Loading NPZ Data from: {DATA_FOLDER} ---\")\n",
    "    # Use the NPZ Dataset class\n",
    "    full_dataset = NpzFolderDatasetWithParams(folder_path=DATA_FOLDER, max_k=MAX_K, max_nk=MAX_NK)\n",
    "\n",
    "    # Split data\n",
    "    total_size = len(full_dataset)\n",
    "    if total_size == 0:\n",
    "        raise ValueError(\"NPZ dataset is empty after loading. Check NPZ files and paths.\")\n",
    "\n",
    "    val_size = int(VALIDATION_SPLIT * total_size)\n",
    "    train_size = total_size - val_size\n",
    "    if train_size <= 0 and total_size > 0: # Ensure at least one training sample\n",
    "        train_size = 1\n",
    "        val_size = total_size - 1\n",
    "        print(f\"Warning: Small NPZ dataset. Adjusting split to Train: {train_size}, Val: {val_size}\")\n",
    "\n",
    "    print(f\"Total NPZ samples: {total_size}, Training: {train_size}, Validation: {val_size}\")\n",
    "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "    print(\"NPZ DataLoaders created.\")\n",
    "\n",
    "    # --- Model, Loss, Optimizer ---\n",
    "\n",
    "    # --- Dense Network ---\n",
    "    # print(\"\\n--- Initializing Dense Network with Params ---\")\n",
    "    dense_model_params = DenseNetworkWithParams(\n",
    "        p_input_size=PADDED_P_MATRIX_FLAT_SIZE,\n",
    "        param_input_size=PARAMS_SIZE\n",
    "    ).to(device)\n",
    "    criterion_dense = LogMSELoss()\n",
    "    optimizer_dense = optim.Adam(dense_model_params.parameters(), lr=LEARNING_RATE_DENSE)\n",
    "\n",
    "    # --- CNN Network ---\n",
    "    # print(\"\\n--- Initializing CNN Network with Params ---\")\n",
    "    cnn_model_params = CNNWithParams(\n",
    "        input_height=MAX_K,\n",
    "        input_width=MAX_NK,\n",
    "        param_input_size=PARAMS_SIZE\n",
    "    ).to(device)\n",
    "    criterion_cnn = LogMSELoss()\n",
    "    optimizer_cnn = optim.Adam(cnn_model_params.parameters(), lr=LEARNING_RATE_CNN)\n",
    "\n",
    "    # --- LSTM Network ---\n",
    "    # print(\"\\n--- Initializing LSTM Network with Params ---\")\n",
    "    lstm_model_params = LSTMNetworkWithParams( # Ensure this class is defined in a previous cell\n",
    "        input_feature_size=RNN_INPUT_FEATURES,\n",
    "        hidden_size=RNN_HIDDEN_DIM,\n",
    "        num_layers=RNN_NUM_LAYERS,\n",
    "        param_input_size=PARAMS_SIZE,\n",
    "        output_size=1,\n",
    "        dropout_prob=RNN_DROPOUT\n",
    "    ).to(device)\n",
    "    criterion_lstm = LogMSELoss()\n",
    "    optimizer_lstm = optim.Adam(lstm_model_params.parameters(), lr=LEARNING_RATE_LSTM)\n",
    "\n",
    "    # --- GRU Network ---\n",
    "    # print(\"\\n--- Initializing GRU Network with Params ---\")\n",
    "    gru_model_params = GRUNetworkWithParams( # Ensure this class is defined in a previous cell\n",
    "        input_feature_size=RNN_INPUT_FEATURES,\n",
    "        hidden_size=RNN_HIDDEN_DIM,\n",
    "        num_layers=RNN_NUM_LAYERS,\n",
    "        param_input_size=PARAMS_SIZE,\n",
    "        output_size=1,\n",
    "        dropout_prob=RNN_DROPOUT\n",
    "    ).to(device)\n",
    "    criterion_gru = LogMSELoss()\n",
    "    optimizer_gru = optim.Adam(gru_model_params.parameters(), lr=LEARNING_RATE_GRU)\n",
    "\n",
    "\n",
    "    # --- Training Loop (Dense) ---\n",
    "    print(\"\\n--- Starting Dense Model Training Loop ---\")\n",
    "    best_val_loss_dense = float('inf')\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"\\nEpoch {epoch+1}/{EPOCHS} (Dense Network)\")\n",
    "        train_loss = train_epoch_with_params(dense_model_params, train_loader, criterion_dense, optimizer_dense, device)\n",
    "        val_loss = validate_epoch_with_params(dense_model_params, val_loader, criterion_dense, device)\n",
    "        dense_train_losses.append(train_loss)\n",
    "        dense_val_losses.append(val_loss)\n",
    "        print(f\"Epoch {epoch+1} Summary (Dense): Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        if val_loss < best_val_loss_dense:\n",
    "            print(f\"  Dense Val loss improved ({best_val_loss_dense:.4f} -> {val_loss:.4f}).\") # Saving optional\n",
    "            best_val_loss_dense = val_loss\n",
    "            # torch.save(dense_model_params.state_dict(), 'best_dense_model_npz.pth')\n",
    "\n",
    "    # --- Training Loop (CNN) ---\n",
    "    print(\"\\n--- Starting CNN Model Training Loop ---\")\n",
    "    best_val_loss_cnn = float('inf')\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"\\nEpoch {epoch+1}/{EPOCHS} (CNN Network)\")\n",
    "        train_loss = train_epoch_with_params(cnn_model_params, train_loader, criterion_cnn, optimizer_cnn, device)\n",
    "        val_loss = validate_epoch_with_params(cnn_model_params, val_loader, criterion_cnn, device)\n",
    "        cnn_train_losses.append(train_loss)\n",
    "        cnn_val_losses.append(val_loss)\n",
    "        print(f\"Epoch {epoch+1} Summary (CNN): Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        if val_loss < best_val_loss_cnn:\n",
    "            print(f\"  CNN Val loss improved ({best_val_loss_cnn:.4f} -> {val_loss:.4f}).\")\n",
    "            best_val_loss_cnn = val_loss\n",
    "            # torch.save(cnn_model_params.state_dict(), 'best_cnn_model_npz.pth')\n",
    "\n",
    "\n",
    "    # --- Training Loop (LSTM) ---\n",
    "    print(\"\\n--- Starting LSTM Model Training Loop ---\")\n",
    "    best_val_loss_lstm = float('inf')\n",
    "    for epoch in range(EPOCHS+25):\n",
    "        print(f\"\\nEpoch {epoch+1}/{EPOCHS} (LSTM Network)\")\n",
    "        train_loss = train_epoch_with_params(lstm_model_params, train_loader, criterion_lstm, optimizer_lstm, device)\n",
    "        val_loss = validate_epoch_with_params(lstm_model_params, val_loader, criterion_lstm, device)\n",
    "        lstm_train_losses.append(train_loss)\n",
    "        lstm_val_losses.append(val_loss)\n",
    "        print(f\"Epoch {epoch+1} Summary (LSTM): Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        if val_loss < best_val_loss_lstm:\n",
    "            print(f\"  LSTM Val loss improved ({best_val_loss_lstm:.4f} -> {val_loss:.4f}).\")\n",
    "            best_val_loss_lstm = val_loss\n",
    "            # torch.save(lstm_model_params.state_dict(), 'best_lstm_model_npz.pth')\n",
    "\n",
    "\n",
    "    # --- Training Loop (GRU) ---\n",
    "    print(\"\\n--- Starting GRU Model Training Loop ---\")\n",
    "    best_val_loss_gru = float('inf')\n",
    "    for epoch in range(EPOCHS+25):\n",
    "        print(f\"\\nEpoch {epoch+1}/{EPOCHS} (GRU Network)\")\n",
    "        train_loss = train_epoch_with_params(gru_model_params, train_loader, criterion_gru, optimizer_gru, device)\n",
    "        val_loss = validate_epoch_with_params(gru_model_params, val_loader, criterion_gru, device)\n",
    "        gru_train_losses.append(train_loss)\n",
    "        gru_val_losses.append(val_loss)\n",
    "        print(f\"Epoch {epoch+1} Summary (GRU): Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        if val_loss < best_val_loss_gru:\n",
    "            print(f\"  GRU Val loss improved ({best_val_loss_gru:.4f} -> {val_loss:.4f}).\")\n",
    "            best_val_loss_gru = val_loss\n",
    "            # torch.save(gru_model_params.state_dict(), 'best_gru_model_npz.pth')\n",
    "\n",
    "\n",
    "# --- Error Handling ---\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\nSetup Error: {e}\")\n",
    "    print(\"Please ensure the DATA_FOLDER path is correct relative to the notebook.\")\n",
    "except ValueError as e:\n",
    "     print(f\"\\nSetup Error: {e}\")\n",
    "     print(\"Check NPZ file contents/structure or if the dataset ended up empty.\")\n",
    "except Exception as e:\n",
    "    import traceback # Make sure traceback is imported\n",
    "    print(f\"\\nAn unexpected setup error occurred: {type(e).__name__} - {e}\")\n",
    "    print(\"Traceback:\")\n",
    "    print(traceback.format_exc()) # Print traceback for debugging\n",
    "\n",
    "\n",
    "# --- Print Final Validation Losses ---\n",
    "print(\"\\n--- Final Validation Losses (Log2 MSE) ---\")\n",
    "if dense_val_losses:\n",
    "    print(f\"Dense Network: {dense_val_losses[-1]:.4f}\")\n",
    "else:\n",
    "    print(\"Dense Network: Training did not complete.\")\n",
    "\n",
    "if cnn_val_losses:\n",
    "    print(f\"CNN Network:   {cnn_val_losses[-1]:.4f}\")\n",
    "else:\n",
    "    print(\"CNN Network: Training did not complete.\")\n",
    "\n",
    "if lstm_val_losses:\n",
    "    print(f\"LSTM Network:  {lstm_val_losses[-1]:.4f}\")\n",
    "else:\n",
    "    print(\"LSTM Network: Training did not complete.\")\n",
    "\n",
    "if gru_val_losses:\n",
    "    print(f\"GRU Network:   {gru_val_losses[-1]:.4f}\")\n",
    "else:\n",
    "    print(\"GRU Network: Training did not complete.\")\n",
    "\n",
    "\n",
    "# --- Plotting (Modified for 4 models) ---\n",
    "# Check if ALL loss lists were populated before plotting\n",
    "if dense_train_losses and cnn_train_losses and lstm_train_losses and gru_train_losses:\n",
    "    print(\"\\nPlotting losses for all models...\")\n",
    "    # Use a 2x2 grid for the plots\n",
    "    plt.figure(figsize=(12, 10)) # Adjusted figure size\n",
    "\n",
    "    # Dense Plot\n",
    "    plt.subplot(2, 2, 1) # Row 1, Col 1\n",
    "    plt.plot(dense_train_losses, label='Dense Train Loss')\n",
    "    plt.plot(dense_val_losses, label='Dense Val Loss')\n",
    "    plt.title('Dense Network Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Log2 MSE Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # CNN Plot\n",
    "    plt.subplot(2, 2, 2) # Row 1, Col 2\n",
    "    plt.plot(cnn_train_losses, label='CNN Train Loss')\n",
    "    plt.plot(cnn_val_losses, label='CNN Val Loss')\n",
    "    plt.title('CNN Network Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Log2 MSE Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # LSTM Plot\n",
    "    plt.subplot(2, 2, 3) # Row 2, Col 1\n",
    "    plt.plot(lstm_train_losses, label='LSTM Train Loss')\n",
    "    plt.plot(lstm_val_losses, label='LSTM Val Loss')\n",
    "    plt.title('LSTM Network Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Log2 MSE Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # GRU Plot\n",
    "    plt.subplot(2, 2, 4) # Row 2, Col 2\n",
    "    plt.plot(gru_train_losses, label='GRU Train Loss')\n",
    "    plt.plot(gru_val_losses, label='GRU Val Loss')\n",
    "    plt.title('GRU Network Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Log2 MSE Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout() # Adjust layout to prevent overlap\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\nSkipping plotting as training did not complete successfully for all models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the following result for this small dataset:\n",
    "- Fully connected Network: 4.0821\n",
    "- CNN Network:   4.8952\n",
    "- LSTM Network:  5.5501\n",
    "- GRU Network:   7.8692\n",
    "\n",
    "we can see that FCN and CNN stands out as the best based model, we are going to test them on the bigger dataset of 420,000 data to see which one is the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below shows the result between the ground truth m-height and the output of the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Comparing Actual vs Predicted Values for Saved CNN Model ---\n",
      "Loading model state from: C:\\Users\\theo-\\OneDrive\\Documents\\VS Code project\\Deep learning\\Project\\best_cnn_model_pkl.pth\n",
      "Model state loaded successfully.\n",
      "Collecting up to 50 validation samples from val_pickle_loader...\n",
      "Collected 50 samples.\n",
      "Making predictions on the sample...\n",
      "\n",
      "Actual vs. Predicted m-height values:\n",
      "----------------------------------------\n",
      "Ground Truth   ---   Model Output\n",
      "----------------------------------------\n",
      "1.0000         ---   11.1922       \n",
      "172.5314       ---   144.4963      \n",
      "535.0997       ---   963.7664      \n",
      "230.3048       ---   231.0020      \n",
      "16540.2461     ---   324.9635      \n",
      "344.1584       ---   977.9683      \n",
      "2.4707         ---   17.5833       \n",
      "421.7233       ---   580.8188      \n",
      "242.2253       ---   108.1127      \n",
      "484.5706       ---   200.4976      \n",
      "193.3798       ---   102.2973      \n",
      "325.6187       ---   313.4016      \n",
      "1.0000         ---   101.6853      \n",
      "1.0000         ---   15.0125       \n",
      "113.5900       ---   14.4356       \n",
      "1.0000         ---   22.9017       \n",
      "252.1170       ---   209.0011      \n",
      "213.4938       ---   24.7970       \n",
      "206.4446       ---   242.3916      \n",
      "292.6647       ---   260.3709      \n",
      "169.4095       ---   477.3119      \n",
      "322.7086       ---   734.9692      \n",
      "1.0000         ---   15.5171       \n",
      "339.5338       ---   251.6689      \n",
      "725.1584       ---   350.6902      \n",
      "600.5485       ---   316.4238      \n",
      "1.0000         ---   15.2688       \n",
      "207.7909       ---   288.9526      \n",
      "18.6999        ---   12.9411       \n",
      "61.7099        ---   15.1371       \n",
      "139.0626       ---   82.1324       \n",
      "251.1672       ---   54.1191       \n",
      "63.7015        ---   11.4361       \n",
      "111.5512       ---   95.3987       \n",
      "9426.7510      ---   942.0103      \n",
      "76.5731        ---   109.8487      \n",
      "153.1427       ---   19.9920       \n",
      "93.7452        ---   340.2146      \n",
      "1.0000         ---   14.5368       \n",
      "96.7091        ---   97.9007       \n",
      "1.0000         ---   15.7330       \n",
      "19.0271        ---   15.1744       \n",
      "316.9758       ---   810.3533      \n",
      "236.2420       ---   28.7446       \n",
      "195.4067       ---   201.9234      \n",
      "904.8157       ---   687.0449      \n",
      "264.8508       ---   729.5418      \n",
      "226.2444       ---   154.7392      \n",
      "329.1310       ---   293.4111      \n",
      "343.8888       ---   345.7871      \n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- Compare Actual vs Predicted Values for Saved CNN Model --\n",
    "# --- Configuration ---\n",
    "PKL_MAX_K = 6\n",
    "PKL_MAX_NK = 6\n",
    "PKL_PARAMS_SIZE = 3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Path to the saved model state dictionary ---\n",
    "SAVED_CNN_MODEL_PATH = r'C:\\Users\\theo-\\OneDrive\\Documents\\VS Code project\\Deep learning\\Project\\best_cnn_model_pkl.pth'\n",
    "\n",
    "print(\"--- Comparing Actual vs Predicted Values for Saved CNN Model ---\")\n",
    "\n",
    "# --- 1. Instantiate and Load Model ---\n",
    "try:\n",
    "    # Ensure required variables exist\n",
    "    if 'PKL_MAX_K' not in locals() or \\\n",
    "       'PKL_MAX_NK' not in locals() or \\\n",
    "       'PKL_PARAMS_SIZE' not in locals() or \\\n",
    "       'device' not in locals() or \\\n",
    "       'val_pickle_loader' not in locals() or \\\n",
    "       'CNNWithParams' not in locals():\n",
    "           raise NameError(\"Required variables (PKL_MAX_K, PKL_MAX_NK, PKL_PARAMS_SIZE, device, val_pickle_loader, CNNWithParams class) not defined. Ensure previous cells are run.\")\n",
    "\n",
    "    # Instantiate the model structure (must match the saved model)\n",
    "    loaded_cnn_model = CNNWithParams(\n",
    "        input_height=PKL_MAX_K,\n",
    "        input_width=PKL_MAX_NK,\n",
    "        param_input_size=PKL_PARAMS_SIZE\n",
    "    )\n",
    "\n",
    "    # Load the saved state dictionary\n",
    "    if os.path.exists(SAVED_CNN_MODEL_PATH):\n",
    "        print(f\"Loading model state from: {SAVED_CNN_MODEL_PATH}\")\n",
    "        # Load state dict, making sure to map location to the current device\n",
    "        state_dict = torch.load(SAVED_CNN_MODEL_PATH, map_location=device)\n",
    "        loaded_cnn_model.load_state_dict(state_dict)\n",
    "        print(\"Model state loaded successfully.\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Saved model file not found at: {SAVED_CNN_MODEL_PATH}\")\n",
    "\n",
    "    loaded_cnn_model.to(device) # Ensure model is on the correct device\n",
    "    loaded_cnn_model.eval() # Set model to evaluation mode\n",
    "\n",
    "    # --- 2. Get Validation Sample (from pickle loader) ---\n",
    "    val_samples_p = []\n",
    "    val_samples_params = []\n",
    "    val_targets = []\n",
    "    num_samples_to_get = 50\n",
    "    samples_collected = 0\n",
    "\n",
    "    print(f\"Collecting up to {num_samples_to_get} validation samples from val_pickle_loader...\")\n",
    "    with torch.no_grad(): # Ensure no gradients are calculated\n",
    "        for p_matrices, params, targets in val_pickle_loader: # Use the pickle loader\n",
    "            num_in_batch = p_matrices.size(0)\n",
    "            samples_needed = num_samples_to_get - samples_collected\n",
    "\n",
    "            if samples_needed <= 0:\n",
    "                break\n",
    "\n",
    "            num_to_take = min(num_in_batch, samples_needed)\n",
    "\n",
    "            val_samples_p.append(p_matrices[:num_to_take].cpu())\n",
    "            val_samples_params.append(params[:num_to_take].cpu())\n",
    "            val_targets.append(targets[:num_to_take].cpu())\n",
    "\n",
    "            samples_collected += num_to_take\n",
    "    print(f\"Collected {samples_collected} samples.\")\n",
    "\n",
    "    # Concatenate the collected samples\n",
    "    if samples_collected > 0:\n",
    "        val_samples_p_tensor = torch.cat(val_samples_p, dim=0)\n",
    "        val_samples_params_tensor = torch.cat(val_samples_params, dim=0)\n",
    "        val_targets_tensor = torch.cat(val_targets, dim=0)\n",
    "\n",
    "        # --- 3. Make Predictions ---\n",
    "        print(\"Making predictions on the sample...\")\n",
    "        all_predictions = []\n",
    "        with torch.no_grad():\n",
    "            # Move sample tensors to the correct device\n",
    "            p_matrices_device = val_samples_p_tensor.to(device)\n",
    "            params_device = val_samples_params_tensor.to(device)\n",
    "\n",
    "            # Make predictions using the LOADED CNN model\n",
    "            predictions = loaded_cnn_model(p_matrices_device, params_device)\n",
    "            all_predictions.append(predictions.cpu())\n",
    "\n",
    "        # Concatenate predictions\n",
    "        predictions_tensor = torch.cat(all_predictions, dim=0)\n",
    "\n",
    "        # --- 4. Convert to NumPy Arrays ---\n",
    "        actuals_np = val_targets_tensor.numpy().flatten()\n",
    "        predictions_np = predictions_tensor.numpy().flatten()\n",
    "\n",
    "        # --- 5. Print Values ---\n",
    "        print(\"\\nActual vs. Predicted m-height values:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(\"Ground Truth   ---   Model Output\")\n",
    "        print(\"-\" * 40)\n",
    "        for actual, predicted in zip(actuals_np, predictions_np):\n",
    "            print(f\"{actual:<14.4f} ---   {predicted:<14.4f}\") # Format for better alignment\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "    else:\n",
    "        print(\"Could not retrieve any samples from the val_pickle_loader. Skipping comparison.\")\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"Error: {e}. Make sure all necessary variables and the CNNWithParams class are defined.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}. Could not load the model state.\")\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cell below : load all the data into the dataloader \"train_loader\" and \"val_loader\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "--- Preparing Data ---\n",
      "Found 42 total .pkl files.\n",
      "Loading data from 42 specified pickle files (expecting DataFrames)...\n",
      "Finished initial loading. Total samples found: 420000\n",
      "Total samples loaded from combined files: 420000\n",
      "Splitting data: Training=336000 (80.0%), Validation=84000 (20.0%)\n",
      "\n",
      "Final DataLoaders created successfully.\n",
      "Training batches: 2625, Validation batches: 657\n"
     ]
    }
   ],
   "source": [
    "# --- Data Loading and Preparation ---\n",
    "# --- Configuration ---\n",
    "TRAIN_DATA_FOLDERS = ['./split_data']\n",
    "VALIDATION_DATA_FOLDERS = ['./split_data_validation']\n",
    "max_k = 6\n",
    "max_nk = 6\n",
    "batch_size = 128 \n",
    "val_split_ratio = 0.2 # 80/20 split\n",
    "NUM_WORKERS = 0 # Safer default for Windows\n",
    "PIN_MEMORY = True # Generally good if using GPU\n",
    "\n",
    "# --- Variables to store loaders (so they are accessible by the next cell) ---\n",
    "train_loader = None\n",
    "val_loader = None\n",
    "\n",
    "# --- Device Setup ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- Load and Split Data ---\n",
    "try:\n",
    "    print(\"--- Preparing Data ---\")\n",
    "    all_files = []\n",
    "    for folder in TRAIN_DATA_FOLDERS + VALIDATION_DATA_FOLDERS:\n",
    "         files = glob.glob(os.path.join(folder, '*.pkl'))\n",
    "         if not files:\n",
    "              print(f\"Warning: No .pkl files found in folder: {folder}\")\n",
    "         all_files.extend(files)\n",
    "\n",
    "    if not all_files:\n",
    "        raise FileNotFoundError(\"No .pkl files found in any specified train/validation folders.\")\n",
    "\n",
    "    print(f\"Found {len(all_files)} total .pkl files.\")\n",
    "\n",
    "    # Instantiate the dataset with the combined list of files\n",
    "    combined_dataset = PickleFolderDataset(\n",
    "        file_paths=all_files,\n",
    "        max_k=max_k,\n",
    "        max_nk=max_nk,\n",
    "        p_normaliser = \"col_minmax\"\n",
    "    )\n",
    "\n",
    "    total_samples = len(combined_dataset)\n",
    "    print(f\"Total samples loaded from combined files: {total_samples}\")\n",
    "\n",
    "    # Perform random split\n",
    "    val_size = int(total_samples * val_split_ratio)\n",
    "    train_size = total_samples - val_size\n",
    "\n",
    "    if train_size <= 0 or val_size <= 0:\n",
    "         raise ValueError(f\"Calculated train ({train_size}) or validation ({val_size}) size is zero or less.\")\n",
    "\n",
    "    print(f\"Splitting data: Training={train_size} ({100*(1-val_split_ratio):.1f}%), Validation={val_size} ({100*val_split_ratio:.1f}%)\")\n",
    "    train_dataset, val_dataset = random_split(combined_dataset, [train_size, val_size])\n",
    "\n",
    "    # Create DataLoaders and store them in global scope for this cell block\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=PIN_MEMORY\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=PIN_MEMORY\n",
    "    )\n",
    "    print(\"\\nFinal DataLoaders created successfully.\")\n",
    "    print(f\"Training batches: {len(train_loader)}, Validation batches: {len(val_loader)}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\nData Loading Error: {e}\")\n",
    "    print(\"Please ensure the TRAIN_DATA_FOLDERS and VALIDATION_DATA_FOLDERS paths are correct.\")\n",
    "except ValueError as e:\n",
    "     print(f\"\\nData Loading/Splitting Error: {e}\")\n",
    "     print(\"Check data contents, split ratio, or if the dataset ended up empty.\")\n",
    "except NameError as e:\n",
    "     print(f\"\\nDefinition Error: {e}. Make sure 'PickleFolderDatasetWithParams' class is defined and executed first.\")\n",
    "except ImportError as e:\n",
    "     print(f\"\\nImport Error: {e}. Make sure required libraries (torch, pickle, pandas etc.) are imported.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn unexpected error occurred during data loading/splitting: {type(e).__name__} - {e}\")\n",
    "    print(\"Traceback:\")\n",
    "    print(traceback.format_exc())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize train_dataloader_norm and validate_dataloader_norm where P values are normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "--- Preparing Data ---\n",
      "Found 42 total .pkl files.\n",
      "Loading data from 42 specified pickle files (expecting DataFrames)...\n",
      "Finished initial loading. Total samples found: 420000\n",
      "Total samples loaded from combined files: 420000\n",
      "Splitting data: Training=336000 (80.0%), Validation=84000 (20.0%)\n",
      "\n",
      "Final DataLoaders created successfully.\n",
      "Training batches: 2625, Validation batches: 657\n"
     ]
    }
   ],
   "source": [
    "# --- Data Loading and Preparation ---\n",
    "# --- Configuration ---\n",
    "TRAIN_DATA_FOLDERS = ['./split_data']\n",
    "VALIDATION_DATA_FOLDERS = ['./split_data_validation']\n",
    "max_k = 6\n",
    "max_nk = 6\n",
    "batch_size = 512 \n",
    "val_split_ratio = 0.2 # 80/20 split\n",
    "NUM_WORKERS = 0 # Safer default for Windows\n",
    "PIN_MEMORY = True # Generally good if using GPU\n",
    "\n",
    "# --- Variables to store loaders (so they are accessible by the next cell) ---\n",
    "train_loader_norm = None\n",
    "val_loader_norm = None\n",
    "\n",
    "# --- Device Setup ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- Define normalization transform ---\n",
    "normalize_p = transforms.Normalize(mean=[0], std=[100])  # Maps [-100,100] to [-1,1]\n",
    "\n",
    "# --- Load and Split Data ---\n",
    "try:\n",
    "    print(\"--- Preparing Data ---\")\n",
    "    all_files = []\n",
    "    for folder in TRAIN_DATA_FOLDERS + VALIDATION_DATA_FOLDERS:\n",
    "         files = glob.glob(os.path.join(folder, '*.pkl'))\n",
    "         if not files:\n",
    "              print(f\"Warning: No .pkl files found in folder: {folder}\")\n",
    "         all_files.extend(files)\n",
    "\n",
    "    if not all_files:\n",
    "        raise FileNotFoundError(\"No .pkl files found in any specified train/validation folders.\")\n",
    "\n",
    "    print(f\"Found {len(all_files)} total .pkl files.\")\n",
    "\n",
    "    # Instantiate the dataset with the combined list of files and normalization\n",
    "    combined_dataset = PickleFolderDataset(\n",
    "        file_paths=all_files,\n",
    "        max_k=max_k,\n",
    "        max_nk=max_nk,\n",
    "        transform=normalize_p  # Add normalization transform\n",
    "    )\n",
    "\n",
    "    total_samples = len(combined_dataset)\n",
    "    print(f\"Total samples loaded from combined files: {total_samples}\")\n",
    "\n",
    "    # Perform random split\n",
    "    val_size = int(total_samples * val_split_ratio)\n",
    "    train_size = total_samples - val_size\n",
    "\n",
    "    if train_size <= 0 or val_size <= 0:\n",
    "         raise ValueError(f\"Calculated train ({train_size}) or validation ({val_size}) size is zero or less.\")\n",
    "\n",
    "    print(f\"Splitting data: Training={train_size} ({100*(1-val_split_ratio):.1f}%), Validation={val_size} ({100*val_split_ratio:.1f}%)\")\n",
    "    train_dataset_norm, val_dataset_norm = random_split(combined_dataset, [train_size, val_size])\n",
    "\n",
    "    # Create DataLoaders and store them in global scope for this cell block\n",
    "    train_loader_norm = DataLoader(\n",
    "        train_dataset_norm,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=PIN_MEMORY\n",
    "    )\n",
    "    val_loader_norm = DataLoader(\n",
    "        val_dataset_norm,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=PIN_MEMORY\n",
    "    )\n",
    "    print(\"\\nFinal DataLoaders created successfully.\")\n",
    "    print(f\"Training batches: {len(train_loader)}, Validation batches: {len(val_loader)}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\nData Loading Error: {e}\")\n",
    "    print(\"Please ensure the TRAIN_DATA_FOLDERS and VALIDATION_DATA_FOLDERS paths are correct.\")\n",
    "except ValueError as e:\n",
    "     print(f\"\\nData Loading/Splitting Error: {e}\")\n",
    "     print(\"Check data contents, split ratio, or if the dataset ended up empty.\")\n",
    "except NameError as e:\n",
    "     print(f\"\\nDefinition Error: {e}. Make sure 'PickleFolderDataset' class is defined and executed first.\")\n",
    "except ImportError as e:\n",
    "     print(f\"\\nImport Error: {e}. Make sure required libraries (torch, pickle, pandas etc.) are imported.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn unexpected error occurred during data loading/splitting: {type(e).__name__} - {e}\")\n",
    "    print(\"Traceback:\")\n",
    "    print(traceback.format_exc())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "--- Preparing Data ---\n",
      "Found 42 total .pkl files.\n",
      "Loading data from 42 specified pickle files (expecting DataFrames)...\n",
      "Finished initial loading. Total samples found: 420000\n",
      "Total samples loaded from combined files: 420000\n",
      "Splitting data: Training=336000 (80.0%), Validation=84000 (20.0%)\n",
      "DataLoaders created.\n",
      "Training batches: 2625, Validation batches: 657\n",
      "\n",
      "--- Initializing Dense Network (Final Training) ---\n",
      "\n",
      "--- Starting Training Loop for Dense (Final Data) ---\n",
      "\n",
      "Epoch 1/15 (Dense (Final Data))\n",
      "Epoch 1 Summary (Dense (Final Data)): Train Loss: 16.6144, Val Loss: 10.9389, Duration: 37.02s\n",
      "  Dense (Final Data) Val loss improved (inf -> 10.9389).\n",
      "\n",
      "Epoch 2/15 (Dense (Final Data))\n",
      "Epoch 2 Summary (Dense (Final Data)): Train Loss: 10.6975, Val Loss: 10.4549, Duration: 37.38s\n",
      "  Dense (Final Data) Val loss improved (10.9389 -> 10.4549).\n",
      "\n",
      "Epoch 3/15 (Dense (Final Data))\n",
      "Epoch 3 Summary (Dense (Final Data)): Train Loss: 9.9161, Val Loss: 8.7466, Duration: 37.60s\n",
      "  Dense (Final Data) Val loss improved (10.4549 -> 8.7466).\n",
      "\n",
      "Epoch 4/15 (Dense (Final Data))\n",
      "Epoch 4 Summary (Dense (Final Data)): Train Loss: 7.7525, Val Loss: 6.5067, Duration: 36.77s\n",
      "  Dense (Final Data) Val loss improved (8.7466 -> 6.5067).\n",
      "\n",
      "Epoch 5/15 (Dense (Final Data))\n",
      "Epoch 5 Summary (Dense (Final Data)): Train Loss: 6.0059, Val Loss: 8.0960, Duration: 37.29s\n",
      "\n",
      "Epoch 6/15 (Dense (Final Data))\n",
      "Epoch 6 Summary (Dense (Final Data)): Train Loss: 5.1490, Val Loss: 4.3128, Duration: 37.50s\n",
      "  Dense (Final Data) Val loss improved (6.5067 -> 4.3128).\n",
      "\n",
      "Epoch 7/15 (Dense (Final Data))\n",
      "Epoch 7 Summary (Dense (Final Data)): Train Loss: 3.7283, Val Loss: 3.3646, Duration: 37.65s\n",
      "  Dense (Final Data) Val loss improved (4.3128 -> 3.3646).\n",
      "\n",
      "Epoch 8/15 (Dense (Final Data))\n",
      "Epoch 8 Summary (Dense (Final Data)): Train Loss: 3.0368, Val Loss: 2.8519, Duration: 37.23s\n",
      "  Dense (Final Data) Val loss improved (3.3646 -> 2.8519).\n",
      "\n",
      "Epoch 9/15 (Dense (Final Data))\n",
      "Epoch 9 Summary (Dense (Final Data)): Train Loss: 2.5999, Val Loss: 2.4395, Duration: 36.35s\n",
      "  Dense (Final Data) Val loss improved (2.8519 -> 2.4395).\n",
      "\n",
      "Epoch 10/15 (Dense (Final Data))\n",
      "Epoch 10 Summary (Dense (Final Data)): Train Loss: 2.2601, Val Loss: 2.1755, Duration: 36.91s\n",
      "  Dense (Final Data) Val loss improved (2.4395 -> 2.1755).\n",
      "\n",
      "Epoch 11/15 (Dense (Final Data))\n",
      "Epoch 11 Summary (Dense (Final Data)): Train Loss: 2.0207, Val Loss: 1.9471, Duration: 37.35s\n",
      "  Dense (Final Data) Val loss improved (2.1755 -> 1.9471).\n",
      "\n",
      "Epoch 12/15 (Dense (Final Data))\n",
      "Epoch 12 Summary (Dense (Final Data)): Train Loss: 1.8581, Val Loss: 1.8340, Duration: 35.25s\n",
      "  Dense (Final Data) Val loss improved (1.9471 -> 1.8340).\n",
      "\n",
      "Epoch 13/15 (Dense (Final Data))\n",
      "Epoch 13 Summary (Dense (Final Data)): Train Loss: 1.7431, Val Loss: 1.7435, Duration: 35.73s\n",
      "  Dense (Final Data) Val loss improved (1.8340 -> 1.7435).\n",
      "\n",
      "Epoch 14/15 (Dense (Final Data))\n",
      "Epoch 14 Summary (Dense (Final Data)): Train Loss: 1.6636, Val Loss: 1.6556, Duration: 37.00s\n",
      "  Dense (Final Data) Val loss improved (1.7435 -> 1.6556).\n",
      "\n",
      "Epoch 15/15 (Dense (Final Data))\n",
      "Epoch 15 Summary (Dense (Final Data)): Train Loss: 1.6090, Val Loss: 1.5936, Duration: 36.53s\n",
      "  Dense (Final Data) Val loss improved (1.6556 -> 1.5936).\n",
      "\n",
      "Dense (Final Data) Training Finished. Total time: 553.65 seconds\n",
      "\n",
      "--- Initializing CNN Network (Final Training) ---\n",
      "\n",
      "--- Starting Training Loop for CNN (Final Data) ---\n",
      "\n",
      "Epoch 1/15 (CNN (Final Data))\n",
      "Epoch 1 Summary (CNN (Final Data)): Train Loss: 14.3328, Val Loss: 10.8228, Duration: 49.07s\n",
      "  CNN (Final Data) Val loss improved (inf -> 10.8228).\n",
      "\n",
      "Epoch 2/15 (CNN (Final Data))\n",
      "Epoch 2 Summary (CNN (Final Data)): Train Loss: 10.5350, Val Loss: 10.4357, Duration: 46.98s\n",
      "  CNN (Final Data) Val loss improved (10.8228 -> 10.4357).\n",
      "\n",
      "Epoch 3/15 (CNN (Final Data))\n",
      "Epoch 3 Summary (CNN (Final Data)): Train Loss: 10.4190, Val Loss: 10.3918, Duration: 47.83s\n",
      "  CNN (Final Data) Val loss improved (10.4357 -> 10.3918).\n",
      "\n",
      "Epoch 4/15 (CNN (Final Data))\n",
      "Epoch 4 Summary (CNN (Final Data)): Train Loss: 10.3702, Val Loss: 10.3338, Duration: 48.46s\n",
      "  CNN (Final Data) Val loss improved (10.3918 -> 10.3338).\n",
      "\n",
      "Epoch 5/15 (CNN (Final Data))\n",
      "Epoch 5 Summary (CNN (Final Data)): Train Loss: 10.3062, Val Loss: 10.2554, Duration: 48.78s\n",
      "  CNN (Final Data) Val loss improved (10.3338 -> 10.2554).\n",
      "\n",
      "Epoch 6/15 (CNN (Final Data))\n",
      "Epoch 6 Summary (CNN (Final Data)): Train Loss: 10.1811, Val Loss: 10.0797, Duration: 46.47s\n",
      "  CNN (Final Data) Val loss improved (10.2554 -> 10.0797).\n",
      "\n",
      "Epoch 7/15 (CNN (Final Data))\n",
      "Epoch 7 Summary (CNN (Final Data)): Train Loss: 9.9000, Val Loss: 9.6644, Duration: 47.55s\n",
      "  CNN (Final Data) Val loss improved (10.0797 -> 9.6644).\n",
      "\n",
      "Epoch 8/15 (CNN (Final Data))\n",
      "Epoch 8 Summary (CNN (Final Data)): Train Loss: 9.4299, Val Loss: 9.1986, Duration: 46.81s\n",
      "  CNN (Final Data) Val loss improved (9.6644 -> 9.1986).\n",
      "\n",
      "Epoch 9/15 (CNN (Final Data))\n",
      "Epoch 9 Summary (CNN (Final Data)): Train Loss: 9.2402, Val Loss: 8.7115, Duration: 41.77s\n",
      "  CNN (Final Data) Val loss improved (9.1986 -> 8.7115).\n",
      "\n",
      "Epoch 10/15 (CNN (Final Data))\n",
      "Epoch 10 Summary (CNN (Final Data)): Train Loss: 9.2046, Val Loss: 9.7380, Duration: 45.15s\n",
      "\n",
      "Epoch 11/15 (CNN (Final Data))\n",
      "Epoch 11 Summary (CNN (Final Data)): Train Loss: 9.3484, Val Loss: 8.9168, Duration: 46.57s\n",
      "\n",
      "Epoch 12/15 (CNN (Final Data))\n",
      "Epoch 12 Summary (CNN (Final Data)): Train Loss: 9.4141, Val Loss: 8.9936, Duration: 47.36s\n",
      "\n",
      "Epoch 13/15 (CNN (Final Data))\n",
      "Epoch 13 Summary (CNN (Final Data)): Train Loss: 9.3826, Val Loss: 10.9322, Duration: 47.96s\n",
      "\n",
      "Epoch 14/15 (CNN (Final Data))\n",
      "Epoch 14 Summary (CNN (Final Data)): Train Loss: 10.1957, Val Loss: 8.9724, Duration: 42.29s\n",
      "\n",
      "Epoch 15/15 (CNN (Final Data))\n",
      "Epoch 15 Summary (CNN (Final Data)): Train Loss: 10.2764, Val Loss: 9.4845, Duration: 43.50s\n",
      "\n",
      "CNN (Final Data) Training Finished. Total time: 696.56 seconds\n",
      "\n",
      "--- Final Validation Losses (Log2 MSE) ---\n",
      "Dense (Final Data): 1.5936\n",
      "CNN (Final Data): 9.4845\n",
      "\n",
      "Plotting losses...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Model Training and Evaluation ---\n",
    "# --- Check if DataLoaders ---\n",
    "if 'train_loader' not in locals() or 'val_loader' not in locals() or train_loader is None or val_loader is None:\n",
    "    print(\"ERROR: DataLoaders ('train_loader', 'val_loader') not found or not created.\")\n",
    "    print(\"Please run the 'Data Loading and Preparation' cell successfully first.\")\n",
    "else:\n",
    "    print(\"DataLoaders found. Proceeding with training...\")\n",
    "\n",
    "    # --- Training Hyperparameters (can be adjusted here before re-running) ---\n",
    "    learning_rate_dense = 0.0005\n",
    "    learning_rate_cnn = 0.0005\n",
    "    epochs = 25\n",
    "\n",
    "    # --- Model & Padding Parameters (should match Cell 1) ---\n",
    "    max_k = 6 # Ensure consistency\n",
    "    max_nk = 6 # Ensure consistency\n",
    "    padded_p_matrix_flat_size = max_k * max_nk\n",
    "    params_size = 3\n",
    "\n",
    "    # --- Device ---\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # --- Dictionary to store results for this run ---\n",
    "    results = {}\n",
    "\n",
    "    # --- Main Training Execution Block ---\n",
    "    try:\n",
    "        # --- Initialize & Train Dense Model ---\n",
    "        print(\"\\n--- Initializing Dense Network (Training) ---\")\n",
    "        # Create a new instance each time this cell runs\n",
    "        dense_model = DenseNetworkWithParams(\n",
    "            p_input_size=padded_p_matrix_flat_size,\n",
    "            param_input_size=params_size\n",
    "        ).to(device)\n",
    "        criterion_dense = LogMSELoss()\n",
    "        optimizer_dense = optim.Adam(dense_model.parameters(), lr=learning_rate_dense)\n",
    "\n",
    "        dense_train_losses, dense_val_losses = run_training(\n",
    "            model=dense_model,\n",
    "            train_loader=train_loader, \n",
    "            val_loader=val_loader,     \n",
    "            criterion=criterion_dense,\n",
    "            optimizer=optimizer_dense,\n",
    "            epochs=epochs,\n",
    "            device=device,\n",
    "            model_name=\"Dense (Data)\"\n",
    "        )\n",
    "        results[\"Dense (Data)\"] = (dense_train_losses, dense_val_losses)\n",
    "\n",
    "        # --- Initialize & Train CNN Model ---\n",
    "        print(\"\\n--- Initializing CNN Network (Training) ---\")\n",
    "         # Create a new instance each time this cell runs\n",
    "        cnn_model = CNNWithParams(\n",
    "            input_height=max_k,\n",
    "            input_width=max_nk,\n",
    "            param_input_size=params_size\n",
    "        ).to(device)\n",
    "        criterion_cnn = LogMSELoss()\n",
    "        optimizer_cnn = optim.Adam(cnn_model.parameters(), lr=learning_rate_cnn)\n",
    "\n",
    "        cnn_train_losses, cnn_val_losses = run_training(\n",
    "            model=cnn_model,\n",
    "            train_loader=train_loader, \n",
    "            val_loader=val_loader,     \n",
    "            criterion=criterion_cnn,\n",
    "            optimizer=optimizer_cnn,\n",
    "            epochs=epochs,\n",
    "            device=device,\n",
    "            model_name=\"CNN (Data)\"\n",
    "        )\n",
    "        results[\"CNN (Data)\"] = (cnn_train_losses, cnn_val_losses)\n",
    "\n",
    "        # --- Print Final Validation Losses ---\n",
    "        print(\"\\n--- Final Validation Losses (Log2 MSE) ---\")\n",
    "        for model_name, (train_loss_hist, val_loss_hist) in results.items():\n",
    "             if val_loss_hist:\n",
    "                 print(f\"{model_name}: {val_loss_hist[-1]:.4f}\")\n",
    "             else:\n",
    "                 print(f\"{model_name}: Training did not complete or populate losses.\")\n",
    "\n",
    "        # --- Plot Final Losses ---\n",
    "        plot_losses(results) # Assumes plot_losses function is defined\n",
    "\n",
    "    except NameError as e:\n",
    "         print(f\"\\nDefinition Error: {e}. Make sure models, loss, or helper functions (run_training, plot_losses) are defined and executed.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred during training/evaluation: {type(e).__name__} - {e}\")\n",
    "        print(\"Traceback:\")\n",
    "        print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that Fully connected network (1.6 costs) performs better than a CNN (9.5 costs). This difference could be explain by :\n",
    "\n",
    "1. Lack of Meaningful Spatial Hierarchy: CNNs excel when the input data has strong local spatial correlations and a hierarchical structure (pixels forming edges, edges forming shapes, etc.). Convolutional filters are designed to detect these localized patterns. In the P matrix, while generated from a specific process, the relationship determining h_m might not rely on the spatial arrangement of coefficients in the way CNNs expect. The value at P[i, j] doesn't necessarily have a strong predictive relationship with P[i+1, j] or P[i, j+1] that a small filter can effectively capture across all matrices.\n",
    "2. Global Relationships Matter: The h_m value likely depends on more global properties of the matrix G = [I|P] and the specific linear programming problems derived from it. An FCN, by flattening the P matrix (p_flat = p_matrix.view(batch_size, -1)) and connecting every element to the first hidden layer, immediately considers all elements and their potential interactions simultaneously. It has the capacity to learn complex, non-local relationships between any coefficients in P and the parameters n, k, m.\n",
    "3. Impact of Padding: CNNs often require padding (like the zero-padding used here) to maintain dimensions. This padding introduces artificial zeros, especially for smaller P matrices, which might disrupt or confuse the local filters operating near the edges. The FCN doesn't inherently suffer from this in the same way, as it just treats the padded zeros as additional input features.\n",
    "4. Parameter Integration: Both models integrate n, k, m. The FCN combines the flattened P and the parameters before the first hidden layer. The CNN processes P through convolutional layers first and then combines the resulting feature map with the parameters before its fully connected layers. It's possible that the earlier, more direct integration in the FCN is more effective for this problem.\n",
    "\n",
    "In essence: This problem seems to be more about the overall numerical relationships and the global structure represented by the matrix coefficients and the n, k, m parameters, rather than local spatial patterns. The FCN's architecture is inherently better suited to capturing these global dependencies directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we are going to fine tune and find the best architecture for FCN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device for FCN tuning: cuda\n",
      "Setup Complete: Flexible FCN class and tuning trial function are defined.\n"
     ]
    }
   ],
   "source": [
    "# --- fine tuning FCN ---\n",
    "# --- configuration ---\n",
    "fcn_padded_p_matrix_flat_size = max_k * max_nk\n",
    "fcn_params_size = 3\n",
    "\n",
    "# --- Device ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device for FCN tuning: {device}\")\n",
    "\n",
    "# --- Flexible Dense Network Definition ---\n",
    "class FlexibleDenseNetworkWithParams(nn.Module):\n",
    "    \"\"\"\n",
    "    Dense Network accepting flattened padded P matrix and n, k, m parameters.\n",
    "    Hidden layers are defined by a list of dimensions.\n",
    "    \"\"\"\n",
    "    def __init__(self, p_input_size, param_input_size, hidden_dims=[128, 64, 32], output_size=1, dropout_prob=0.2):\n",
    "        super().__init__()\n",
    "        self.param_input_size = param_input_size\n",
    "        combined_input_size = p_input_size + param_input_size\n",
    "\n",
    "        layers = []\n",
    "        prev_dim = combined_input_size\n",
    "        # Input layer check: Ensure first hidden dim connects to combined input\n",
    "        if not hidden_dims: # Handle case of no hidden layers (direct linear)\n",
    "             layers.append(nn.Linear(combined_input_size, output_size))\n",
    "        else:\n",
    "            # First hidden layer\n",
    "            layers.append(nn.Linear(combined_input_size, hidden_dims[0]))\n",
    "            layers.append(nn.ReLU())\n",
    "            if dropout_prob > 0:\n",
    "                layers.append(nn.Dropout(dropout_prob))\n",
    "            prev_dim = hidden_dims[0]\n",
    "\n",
    "            # Subsequent hidden layers\n",
    "            for i in range(1, len(hidden_dims)):\n",
    "                h_dim = hidden_dims[i]\n",
    "                layers.append(nn.Linear(prev_dim, h_dim))\n",
    "                layers.append(nn.ReLU())\n",
    "                if dropout_prob > 0:\n",
    "                    layers.append(nn.Dropout(dropout_prob))\n",
    "                prev_dim = h_dim\n",
    "\n",
    "            # Final output layer connects from the last hidden layer\n",
    "            layers.append(nn.Linear(prev_dim, output_size))\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        print(f\"Initialized FlexibleDenseNetworkWithParams:\")\n",
    "        print(f\"  Input Size (Flat P + Params): {combined_input_size}\")\n",
    "        print(f\"  Hidden Dims: {hidden_dims}\")\n",
    "        print(f\"  Output Size: {output_size}\")\n",
    "        # print(self.network) # Optional: print the layer structure\n",
    "\n",
    "    def forward(self, p_matrix, params):\n",
    "        batch_size = p_matrix.size(0)\n",
    "        p_flat = p_matrix.view(batch_size, -1) # Flatten P matrix\n",
    "\n",
    "        # Ensure params tensor has the correct shape (batch_size, num_params)\n",
    "        if params.dim() == 1: # If it's a single sample (batch size 1 during inference maybe?)\n",
    "             params = params.unsqueeze(0)\n",
    "        if params.size(1) != self.param_input_size:\n",
    "             raise ValueError(f\"Params tensor second dimension ({params.size(1)}) != expected param_input_size ({self.param_input_size})\")\n",
    "\n",
    "        combined_input = torch.cat((p_flat, params), dim=1)\n",
    "        return self.network(combined_input)\n",
    "\n",
    "# --- Training Function for One Tuning Trial ---\n",
    "def run_fcn_tuning_trial(config, train_loader, val_loader, p_input_size, param_input_size, epochs, device):\n",
    "    \"\"\"Trains and evaluates one FCN configuration.\"\"\"\n",
    "    print(f\"\\n--- Starting Trial: {config.get('name', config)} ---\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Extract config\n",
    "    hidden_dims = config['hidden_dims']\n",
    "    learning_rate = config['lr']\n",
    "    dropout_prob = config.get('dropout', 0.2) # Use default if not specified\n",
    "    weight_decay = config.get('weight_decay', 0) # Get weight_decay from config, default to 0\n",
    "\n",
    "    # Ensure Loss function is defined (should be LogMSELoss)\n",
    "    if 'LogMSELoss' not in globals():\n",
    "         raise NameError(\"LogMSELoss class is not defined.\")\n",
    "    criterion = LogMSELoss()\n",
    "\n",
    "    # Instantiate model, criterion, optimizer\n",
    "    model = FlexibleDenseNetworkWithParams(\n",
    "        p_input_size=p_input_size,\n",
    "        param_input_size=param_input_size,\n",
    "        hidden_dims=hidden_dims,\n",
    "        dropout_prob=dropout_prob\n",
    "    ).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay = weight_decay)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    # Check if training functions are defined\n",
    "    if 'train_epoch_with_params' not in globals() or 'validate_epoch_with_params' not in globals():\n",
    "         raise NameError(\"train_epoch_with_params or validate_epoch_with_params function is not defined.\")\n",
    "\n",
    "    print(f\"  Training for {epochs} epochs...\")\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_epoch_with_params(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss = validate_epoch_with_params(model, val_loader, criterion, device)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        print(f\"  Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"--- Trial Finished: {config.get('name', config)} ---\")\n",
    "    print(f\"  Best Val Loss during trial: {best_val_loss:.4f}\")\n",
    "    print(f\"  Total Time: {end_time - start_time:.2f}s\")\n",
    "\n",
    "    # Return the minimum validation loss achieved during this trial\n",
    "    return {'config': config, 'best_val_loss': best_val_loss, 'train_losses': train_losses, 'val_losses': val_losses}\n",
    "\n",
    "print(\"Setup Complete: Flexible FCN class and tuning trial function are defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define and Run FCN Tuning Trials ---\n",
    "\n",
    "# --- Check Prerequisites ---\n",
    "if 'train_loader' not in locals() or 'val_loader' not in locals():\n",
    "    print(\"ERROR: train_loader or val_loader not found. Ensure the main data loading cell was run.\")\n",
    "elif 'FlexibleDenseNetworkWithParams' not in locals() or 'run_fcn_tuning_trial' not in locals():\n",
    "    print(\"ERROR: Flexible FCN class or tuning trial function not defined. Ensure Cell 1 was run.\")\n",
    "elif 'train_epoch_with_params' not in locals() or 'validate_epoch_with_params' not in locals():\n",
    "    print(\"ERROR: Required training/validation epoch functions are not defined.\")\n",
    "else:\n",
    "    print(\"\\nStarting FCN architecture and hyperparameter search...\")\n",
    "\n",
    "    # --- Define Configurations to Test ---\n",
    "    tuning_configs = [ # 22 combinations\n",
    "        # --- Baseline [128, 64, 32] Variations ---\n",
    "        {'name': 'FCN_128_64_32_lr5e-4_dr0.2_wd0',    'hidden_dims': [128, 64, 32], 'lr': 0.0005, 'dropout': 0.2, 'weight_decay': 0},\n",
    "        {'name': 'FCN_128_64_32_lr1e-3_dr0.2_wd0',    'hidden_dims': [128, 64, 32], 'lr': 0.001,  'dropout': 0.2, 'weight_decay': 0},\n",
    "        {'name': 'FCN_128_64_32_lr1e-4_dr0.2_wd0',    'hidden_dims': [128, 64, 32], 'lr': 0.0001, 'dropout': 0.2, 'weight_decay': 0},\n",
    "        {'name': 'FCN_128_64_32_lr5e-4_dr0.1_wd0',    'hidden_dims': [128, 64, 32], 'lr': 0.0005, 'dropout': 0.1, 'weight_decay': 0},\n",
    "        {'name': 'FCN_128_64_32_lr5e-4_dr0.3_wd0',    'hidden_dims': [128, 64, 32], 'lr': 0.0005, 'dropout': 0.3, 'weight_decay': 0},\n",
    "        {'name': 'FCN_128_64_32_lr5e-4_dr0.2_wd1e-5', 'hidden_dims': [128, 64, 32], 'lr': 0.0005, 'dropout': 0.2, 'weight_decay': 1e-5},\n",
    "        {'name': 'FCN_128_64_32_lr5e-4_dr0.2_wd1e-4', 'hidden_dims': [128, 64, 32], 'lr': 0.0005, 'dropout': 0.2, 'weight_decay': 1e-4},\n",
    "\n",
    "        # --- Deeper Variations ---\n",
    "        {'name': 'FCN_128_64_32_16_lr5e-4_dr0.2_wd0',    'hidden_dims': [128, 64, 32, 16], 'lr': 0.0005, 'dropout': 0.2, 'weight_decay': 0},\n",
    "        {'name': 'FCN_128_64_32_16_lr1e-4_dr0.2_wd1e-5', 'hidden_dims': [128, 64, 32, 16], 'lr': 0.0001, 'dropout': 0.2, 'weight_decay': 1e-5},\n",
    "        {'name': 'FCN_256_128_64_32_lr5e-4_dr0.3_wd1e-5', 'hidden_dims': [256, 128, 64, 32], 'lr': 0.0005, 'dropout': 0.3, 'weight_decay': 1e-5},\n",
    "\n",
    "        # --- Wider Variations ---\n",
    "        {'name': 'FCN_256_128_64_lr5e-4_dr0.2_wd0',    'hidden_dims': [256, 128, 64], 'lr': 0.0005, 'dropout': 0.2, 'weight_decay': 0},\n",
    "        {'name': 'FCN_256_128_64_lr1e-4_dr0.2_wd1e-5', 'hidden_dims': [256, 128, 64], 'lr': 0.0001, 'dropout': 0.2, 'weight_decay': 1e-5},\n",
    "        {'name': 'FCN_512_256_128_lr5e-4_dr0.3_wd0',    'hidden_dims': [512, 256, 128], 'lr': 0.0005, 'dropout': 0.3, 'weight_decay': 0},\n",
    "        {'name': 'FCN_512_256_128_lr5e-4_dr0.3_wd1e-5', 'hidden_dims': [512, 256, 128], 'lr': 0.0005, 'dropout': 0.3, 'weight_decay': 1e-5},\n",
    "\n",
    "        # --- Shallower Variations ---\n",
    "        {'name': 'FCN_128_64_lr5e-4_dr0.2_wd0',    'hidden_dims': [128, 64], 'lr': 0.0005, 'dropout': 0.2, 'weight_decay': 0},\n",
    "        {'name': 'FCN_128_64_lr1e-4_dr0.1_wd1e-5', 'hidden_dims': [128, 64], 'lr': 0.0001, 'dropout': 0.1, 'weight_decay': 1e-5},\n",
    "        {'name': 'FCN_256_128_lr5e-4_dr0.2_wd0',    'hidden_dims': [256, 128], 'lr': 0.0005, 'dropout': 0.2, 'weight_decay': 0},\n",
    "        {'name': 'FCN_256_128_lr5e-4_dr0.3_wd1e-5', 'hidden_dims': [256, 128], 'lr': 0.0005, 'dropout': 0.3, 'weight_decay': 1e-5},\n",
    "\n",
    "        # --- More Combinations ---\n",
    "        {'name': 'FCN_256_128_lr1e-4_dr0.1_wd0',     'hidden_dims': [256, 128], 'lr': 0.0001, 'dropout': 0.1, 'weight_decay': 0},\n",
    "        {'name': 'FCN_256_128_64_32_lr1e-4_dr0.2_wd0','hidden_dims': [256, 128, 64, 32], 'lr': 0.0001, 'dropout': 0.2, 'weight_decay': 0},\n",
    "        {'name': 'FCN_128_64_32_16_lr5e-4_dr0.3_wd1e-4','hidden_dims': [128, 64, 32, 16], 'lr': 0.0005, 'dropout': 0.3, 'weight_decay': 1e-4},\n",
    "        {'name': 'FCN_512_256_lr5e-4_dr0.2_wd1e-5',  'hidden_dims': [512, 256], 'lr': 0.0005, 'dropout': 0.2, 'weight_decay': 1e-5},\n",
    "    ]\n",
    "    # --- Number of Epochs for Each Trial ---\n",
    "    tuning_epochs = 10 # this should be enough to determinate differences\n",
    "\n",
    "    # --- Run Trials ---\n",
    "    tuning_results = []\n",
    "    print(f\"Running {len(tuning_configs)} tuning trials, each for {tuning_epochs} epochs.\")\n",
    "    for config in tuning_configs:\n",
    "        try:\n",
    "            result = run_fcn_tuning_trial(\n",
    "                config=config,\n",
    "                train_loader=train_loader, # Use the main training loader\n",
    "                val_loader=val_loader,     # Use the main validation loader\n",
    "                p_input_size=fcn_padded_p_matrix_flat_size, # From previous cell\n",
    "                param_input_size=fcn_params_size,           # From previous cell\n",
    "                epochs=tuning_epochs,\n",
    "                device=device\n",
    "            )\n",
    "            tuning_results.append(result)\n",
    "        except Exception as e:\n",
    "            print(f\"!!! ERROR during trial {config.get('name', config)}: {type(e).__name__} - {e}\")\n",
    "            print(traceback.format_exc())\n",
    "\n",
    "    # --- Print Summary of Results ---\n",
    "    print(\"\\n--- FCN Tuning Summary ---\")\n",
    "    if not tuning_results:\n",
    "         print(\"No tuning trials completed successfully.\")\n",
    "    else:\n",
    "        # Sort results by best validation loss (ascending - lower is better)\n",
    "        tuning_results.sort(key=lambda x: x['best_val_loss'])\n",
    "        print(\"Ranked by Best Validation Loss (Lower is Better):\")\n",
    "        for i, result in enumerate(tuning_results):\n",
    "            print(f\"  {i+1}. Config: {result['config'].get('name', result['config'])} | Best Val Loss: {result['best_val_loss']:.4f}\")\n",
    "\n",
    "        best_result = tuning_results[0]\n",
    "        print(f\"\\nBEST Configuration Found:\")\n",
    "        print(f\"  Config Details: {best_result['config']}\")\n",
    "        print(f\"  Best Validation Loss Achieved: {best_result['best_val_loss']:.4f}\")\n",
    "\n",
    "        # --- Plotting ---\n",
    "        num_trials = len(tuning_results)\n",
    "        if num_trials > 0:\n",
    "            try:\n",
    "                cols = min(3, num_trials) # Max 3 plots per row\n",
    "                rows = (num_trials + cols - 1) // cols\n",
    "                fig, axes = plt.subplots(rows, cols, figsize=(7 * cols, 5 * rows), sharex=True, squeeze=False) # Ensure axes is 2D array\n",
    "                axes = axes.flatten() # Flatten to easily iterate\n",
    "\n",
    "                fig.suptitle('FCN Tuning - Validation Losses per Epoch', fontsize=16)\n",
    "                for i, result in enumerate(tuning_results):\n",
    "                     # Find best epoch index\n",
    "                     best_epoch_idx = np.argmin(result['val_losses'])\n",
    "                     best_val_loss_epoch = result['val_losses'][best_epoch_idx]\n",
    "\n",
    "                     axes[i].plot(result['val_losses'], label=f\"Val Loss (Best: {best_val_loss_epoch:.4f} at Ep {best_epoch_idx+1})\", marker='.')\n",
    "                     axes[i].plot(result['train_losses'], label='Train Loss', linestyle='--', alpha=0.7)\n",
    "                     # Mark the best validation point\n",
    "                     axes[i].scatter([best_epoch_idx], [best_val_loss_epoch], color='red', s=50, zorder=5, label='Best Val Epoch')\n",
    "                     axes[i].set_title(result['config'].get('name', str(result['config'])), fontsize=10)\n",
    "                     axes[i].set_ylabel('Log2 MSE Loss')\n",
    "                     axes[i].legend(fontsize=8)\n",
    "                     axes[i].grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "                # Hide any unused subplots if the grid isn't perfectly filled\n",
    "                for j in range(i + 1, len(axes)):\n",
    "                    fig.delaxes(axes[j])\n",
    "\n",
    "                # Common X label\n",
    "                # Find the subplot in the last row to add xlabel\n",
    "                last_row_ax_indices = range( (rows-1)*cols, min(num_trials, rows*cols) )\n",
    "                for idx in last_row_ax_indices:\n",
    "                    axes[idx].set_xlabel('Epoch')\n",
    "\n",
    "                plt.tight_layout(rect=[0, 0.03, 1, 0.96]) # Adjust layout\n",
    "                plt.show()\n",
    "            except Exception as plot_err:\n",
    "                 print(f\"\\nWarning: Plotting failed - {plot_err}\")\n",
    "        elif 'matplotlib' not in sys.modules:\n",
    "             print(\"\\nMatplotlib not imported. Skipping plots.\")\n",
    "\n",
    "\n",
    "    print(\"\\nTuning Search Complete. Identify the best configuration from the summary above.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BEST Configuration Found:\n",
    "\n",
    "  Config Details:  \n",
    "  {'name': 'FCN_512_256_128_lr5e-4_dr0.3_wd0',    \n",
    "  'hidden_dims': [512, 256, 128],      \n",
    "  'lr': 0.0005,  \n",
    "  'dropout': 0.3,  \n",
    "  'weight_decay': 0}\n",
    "\n",
    "  Best Validation Loss Achieved: 1.4056\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Final Training of the Best FCN Configuration ---\n",
    "# The BEST result printed at the end of the previous cell \n",
    "best_fcn_config = {\n",
    "    'name': 'FCN_128_64_32_lr5e-4', \n",
    "    'hidden_dims': [512, 256, 128],    \n",
    "    'lr': 0.0005,                  \n",
    "    'dropout': 0.3,                  \n",
    "    'weight_decay': 1e-5  # I added L2 regularization as it improves a little bit the generalization of the model when I test with and without it\n",
    "}\n",
    "\n",
    "# --- Training Parameters for Final Run ---\n",
    "epochs = 20 #\n",
    "model_save_path = 'best_fcn_pretrained_weights.pth' # Filename for saved weights\n",
    "\n",
    "# --- Prerequisites Check ---\n",
    "if 'FlexibleDenseNetworkWithParams' not in locals():\n",
    "    print(\"ERROR: FlexibleDenseNetworkWithParams class definition not found. Run Cell 1.\")\n",
    "elif 'LogMSELoss' not in locals():\n",
    "    print(\"ERROR: LogMSELoss class definition not found.\")\n",
    "elif 'train_epoch_with_params' not in locals() or 'validate_epoch_with_params' not in locals():\n",
    "     print(\"ERROR: Training loop epoch functions not found.\")\n",
    "elif 'train_loader' not in locals() or 'val_loader' not in locals():\n",
    "    print(\"ERROR: train_loader or val_loader not found.\")\n",
    "else:\n",
    "    print(f\"\\n--- Starting Final Training for Selected FCN ---\")\n",
    "    print(f\"Using Configuration: {best_fcn_config}\")\n",
    "    print(f\"Training for {epochs} epochs.\")\n",
    "    print(f\"Best model weights will be saved to: {model_save_path}\")\n",
    "\n",
    "    # --- Instantiate the Best Model ---\n",
    "    fcn_model = FlexibleDenseNetworkWithParams(\n",
    "        p_input_size=fcn_padded_p_matrix_flat_size, # Should be defined in previous cell\n",
    "        param_input_size=fcn_params_size,           # Should be defined in previous cell\n",
    "        hidden_dims=best_fcn_config['hidden_dims'],\n",
    "        dropout_prob=best_fcn_config.get('dropout', 0.2) # Use dropout if specified\n",
    "    ).to(device)\n",
    "\n",
    "    # --- Criterion and Optimizer ---\n",
    "    criterion = LogMSELoss()\n",
    "    optimizer = optim.Adam(fcn_model.parameters(), lr=best_fcn_config['lr'],weight_decay = best_fcn_config['weight_decay'])\n",
    "\n",
    "    # --- Training Loop (with saving best model) ---\n",
    "    best_val_loss = float('inf')\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(\"Starting final training run...\")\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        # Perform one epoch of training and validation\n",
    "        train_loss = train_epoch_with_params(fcn_model, train_loader, criterion, optimizer, device)\n",
    "        val_loss = validate_epoch_with_params(fcn_model, val_loader, criterion, device)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        epoch_duration = time.time() - epoch_start_time\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Time: {epoch_duration:.2f}s\")\n",
    "\n",
    "        # Save the model if validation loss improves\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            # Save the model's state dictionary\n",
    "            torch.save(fcn_model.state_dict(), model_save_path)\n",
    "            print(f\"  -> Val loss improved to {best_val_loss:.4f}. Model weights saved to {model_save_path}\")\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nFinal FCN Training Finished.\")\n",
    "    print(f\"  Total time: {total_time:.2f} seconds\")\n",
    "    print(f\"  Best Validation Loss achieved during training: {best_val_loss:.4f}\")\n",
    "    print(f\"  Best model weights saved to: {model_save_path}\")\n",
    "\n",
    "    # --- Optional: Plot Training Curve ---\n",
    "    if train_losses and val_losses and 'matplotlib' in sys.modules:\n",
    "        try:\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.plot(train_losses, label='Train Loss')\n",
    "            plt.plot(val_losses, label=f'Val Loss (Best: {best_val_loss:.4f})')\n",
    "            # Mark the best validation point\n",
    "            best_epoch_idx = np.argmin(val_losses)\n",
    "            plt.scatter([best_epoch_idx], [best_val_loss], color='red', s=50, zorder=5, label=f'Best Val @ Epoch {best_epoch_idx+1}')\n",
    "            plt.title(f'Final Training: Best FCN ({best_fcn_config.get(\"name\", \"Config\")})')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Log2 MSE Loss')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "        except Exception as plot_err:\n",
    "            print(f\"\\nWarning: Plotting curve failed - {plot_err}\")\n",
    "\n",
    "\n",
    "print(\"\\nStep A (FCN Pre-training) Complete. Weights are saved in:\", model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we get the following result for the best model during training :    \n",
    "- with regularization : 1.3714\n",
    "- without regularization : 1.3618  \n",
    "\n",
    "In general, we get a more regular low cost during training with regularization but with we got lucky and found out a better model without regularization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoE: Created 6 experts for (n, k) pairs: [(9, 4), (9, 5), (9, 6), (10, 4), (10, 5), (10, 6)]\n",
      "MoE: Mapping: {(9, 4): 0, (9, 5): 1, (9, 6): 2, (10, 4): 3, (10, 5): 4, (10, 6): 5}\n",
      "MoE_FCN(\n",
      "  (experts): ModuleList(\n",
      "    (0-5): 6 x DenseNetworkWithParams(\n",
      "      (fc1): Linear(in_features=39, out_features=128, bias=True)\n",
      "      (relu1): ReLU()\n",
      "      (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (relu2): ReLU()\n",
      "      (fc3): Linear(in_features=64, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "MoE Model Parameters: 80,646\n"
     ]
    }
   ],
   "source": [
    "# --- Define MoE FCN with hard gate ---\n",
    "class MoE_FCN(nn.Module):\n",
    "    \"\"\"\n",
    "    Mixture-of-Experts model using DenseNetworkWithParams as experts.\n",
    "    Routes input to a specific expert based on (n, k) values.\n",
    "    \"\"\"\n",
    "    def __init__(self, unique_nk_pairs, expert_config, params_size=3):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            unique_nk_pairs (list[tuple]): A list of unique (n, k) tuples present in the data,\n",
    "                                           determining the number and assignment of experts.\n",
    "                                           Example: [(9, 4), (9, 5), ..., (10, 6)]\n",
    "            expert_config (dict): Dictionary containing arguments for the DenseNetworkWithParams\n",
    "                                  expert (e.g., {'p_input_size': 36, 'hidden_size1': 128, ...}).\n",
    "            params_size (int): The size of the parameter vector (n, k, m -> 3).\n",
    "        \"\"\"\n",
    "        super(MoE_FCN, self).__init__()\n",
    "\n",
    "        if not unique_nk_pairs:\n",
    "            raise ValueError(\"unique_nk_pairs list cannot be empty.\")\n",
    "\n",
    "        self.unique_nk_pairs = sorted(list(set(unique_nk_pairs))) # Ensure unique and sorted\n",
    "        self.num_experts = len(self.unique_nk_pairs)\n",
    "        self.params_size = params_size # Store params_size\n",
    "\n",
    "        # Create the mapping from (n, k) tuple to expert index\n",
    "        self.nk_to_expert_idx = {pair: i for i, pair in enumerate(self.unique_nk_pairs)}\n",
    "        print(f\"MoE: Created {self.num_experts} experts for (n, k) pairs: {self.unique_nk_pairs}\")\n",
    "        print(f\"MoE: Mapping: {self.nk_to_expert_idx}\")\n",
    "\n",
    "\n",
    "        # List to hold the expert networks\n",
    "        self.experts = nn.ModuleList([\n",
    "            FlexibleDenseNetworkWithParams(**expert_config) for _ in range(self.num_experts)\n",
    "        ])\n",
    "\n",
    "    def forward(self, p_matrix, params):\n",
    "        \"\"\"\n",
    "        Forward pass for the MoE model.\n",
    "\n",
    "        Args:\n",
    "            p_matrix (torch.Tensor): Padded P matrix. Shape: (batch, max_k, max_nk)\n",
    "            params (torch.Tensor): Raw n, k, m values. Shape: (batch, 3)\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Predicted h_m value(s). Shape: (batch, 1)\n",
    "        \"\"\"\n",
    "        batch_size = params.size(0)\n",
    "        device = params.device\n",
    "\n",
    "        # --- Determine expert indices for the batch ---\n",
    "        # Extract n and k (assuming they are at index 0 and 1 in params)\n",
    "        # Convert to integers for dictionary lookup\n",
    "        n_vals = params[:, 0].long().tolist() # Use long() then tolist() for CPU lookup\n",
    "        k_vals = params[:, 1].long().tolist()\n",
    "\n",
    "        # Get expert indices using the mapping dictionary\n",
    "        try:\n",
    "            expert_indices = [self.nk_to_expert_idx[(n, k)] for n, k in zip(n_vals, k_vals)]\n",
    "        except KeyError as e:\n",
    "            raise KeyError(f\"MoE Error: Encountered an (n, k) pair {e} not in the mapping dictionary {self.nk_to_expert_idx}. Check unique_nk_pairs.\")\n",
    "\n",
    "        expert_indices_tensor = torch.tensor(expert_indices, dtype=torch.long, device=device)\n",
    "        # Shape: (batch_size,)\n",
    "\n",
    "        # --- Compute outputs from ALL experts for the batch ---\n",
    "        # List to store outputs from each expert for the whole batch\n",
    "        all_expert_outputs = []\n",
    "        for expert in self.experts:\n",
    "            # Each expert processes the full batch's p_matrix and params\n",
    "            # Note: Passing raw params (n,k,m) to DenseNetwork expects them concatenated\n",
    "            expert_output = expert(p_matrix, params) # Shape: (batch_size, 1)\n",
    "            all_expert_outputs.append(expert_output)\n",
    "\n",
    "        # Stack outputs along a new dimension: (batch_size, num_experts, 1)\n",
    "        stacked_outputs = torch.stack(all_expert_outputs, dim=1)\n",
    "\n",
    "        # --- Select the output from the chosen expert for each sample ---\n",
    "        # Prepare indices for gather: shape needs to be (batch_size, 1, 1) to match dim 1 of stacked_outputs\n",
    "        idx_for_gather = expert_indices_tensor.unsqueeze(-1).unsqueeze(-1)\n",
    "        # Expand index to match the last dimension of stacked_outputs (which is 1)\n",
    "        idx_for_gather = idx_for_gather.expand(-1, -1, stacked_outputs.size(2)) # Shape: (batch_size, 1, 1)\n",
    "\n",
    "        # Gather the outputs: selects along dim=1 using the expert indices\n",
    "        final_output = torch.gather(stacked_outputs, 1, idx_for_gather) # Shape: (batch_size, 1, 1)\n",
    "\n",
    "        # Remove the middle dimension (which had size 1 because we gathered 1 expert)\n",
    "        final_output = final_output.squeeze(1) # Shape: (batch_size, 1)\n",
    "\n",
    "        return final_output\n",
    "\n",
    "# --- Example usage ---\n",
    "# UNIQUE_NK_PAIRS = [(9, 4), (9, 5), (9, 6), (10, 4), (10, 5), (10, 6)] # Based on your data\n",
    "# PADDING_FLAT_SIZE = 36 # FINAL_PADDED_P_MATRIX_FLAT_SIZE\n",
    "# PARAMS_DIM = 3       # FINAL_PARAMS_SIZE\n",
    "# EXPERT_HIDDEN_1 = 128\n",
    "# EXPERT_HIDDEN_2 = 64\n",
    "# OUTPUT_DIM = 1\n",
    "\n",
    "# moe_expert_config = {\n",
    "#     'p_input_size': PADDING_FLAT_SIZE,\n",
    "#     'param_input_size': PARAMS_DIM,\n",
    "#     'hidden_size1': EXPERT_HIDDEN_1,\n",
    "#     'hidden_size2': EXPERT_HIDDEN_2,\n",
    "#     'output_size': OUTPUT_DIM\n",
    "# }\n",
    "\n",
    "# moe_model = MoE_FCN(unique_nk_pairs=UNIQUE_NK_PAIRS, expert_config=moe_expert_config, params_size=PARAMS_DIM)\n",
    "# print(moe_model)\n",
    "# # Check number of parameters\n",
    "# print(f\"MoE Model Parameters: {sum(p.numel() for p in moe_model.parameters() if p.requires_grad):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders found. Proceeding with training...\n",
      "Using device: cuda\n",
      "\n",
      "--- Initializing MoE FCN Network (Final Training) ---\n",
      "MoE: Created 6 experts for (n, k) pairs: [(9, 4), (9, 5), (9, 6), (10, 4), (10, 5), (10, 6)]\n",
      "MoE: Mapping: {(9, 4): 0, (9, 5): 1, (9, 6): 2, (10, 4): 3, (10, 5): 4, (10, 6): 5}\n",
      "MoE Model Parameters: 80,646\n",
      "\n",
      "--- Starting Training Loop for MoE FCN (Final Data) ---\n",
      "\n",
      "Epoch 1/15 (MoE FCN (Final Data))\n",
      "Epoch 1 Summary (MoE FCN (Final Data)): Train Loss: 18.1616, Val Loss: 10.4941, Duration: 62.83s\n",
      "  MoE FCN (Final Data) Val loss improved (inf -> 10.4941).\n",
      "\n",
      "Epoch 2/15 (MoE FCN (Final Data))\n",
      "Epoch 2 Summary (MoE FCN (Final Data)): Train Loss: 10.2650, Val Loss: 10.1264, Duration: 58.58s\n",
      "  MoE FCN (Final Data) Val loss improved (10.4941 -> 10.1264).\n",
      "\n",
      "Epoch 3/15 (MoE FCN (Final Data))\n",
      "Epoch 3 Summary (MoE FCN (Final Data)): Train Loss: 9.8877, Val Loss: 9.6089, Duration: 62.45s\n",
      "  MoE FCN (Final Data) Val loss improved (10.1264 -> 9.6089).\n",
      "\n",
      "Epoch 4/15 (MoE FCN (Final Data))\n",
      "Epoch 4 Summary (MoE FCN (Final Data)): Train Loss: 9.0843, Val Loss: 8.1254, Duration: 65.52s\n",
      "  MoE FCN (Final Data) Val loss improved (9.6089 -> 8.1254).\n",
      "\n",
      "Epoch 5/15 (MoE FCN (Final Data))\n",
      "Epoch 5 Summary (MoE FCN (Final Data)): Train Loss: 7.9772, Val Loss: 7.4234, Duration: 61.54s\n",
      "  MoE FCN (Final Data) Val loss improved (8.1254 -> 7.4234).\n",
      "\n",
      "Epoch 6/15 (MoE FCN (Final Data))\n",
      "Epoch 6 Summary (MoE FCN (Final Data)): Train Loss: 8.1005, Val Loss: 6.6604, Duration: 63.81s\n",
      "  MoE FCN (Final Data) Val loss improved (7.4234 -> 6.6604).\n",
      "\n",
      "Epoch 7/15 (MoE FCN (Final Data))\n",
      "Epoch 7 Summary (MoE FCN (Final Data)): Train Loss: 7.9400, Val Loss: 7.4342, Duration: 59.66s\n",
      "\n",
      "Epoch 8/15 (MoE FCN (Final Data))\n",
      "Epoch 8 Summary (MoE FCN (Final Data)): Train Loss: 7.7413, Val Loss: 6.9670, Duration: 63.96s\n",
      "\n",
      "Epoch 9/15 (MoE FCN (Final Data))\n",
      "Epoch 9 Summary (MoE FCN (Final Data)): Train Loss: 7.5023, Val Loss: 7.6141, Duration: 66.54s\n",
      "\n",
      "Epoch 10/15 (MoE FCN (Final Data))\n",
      "Epoch 10 Summary (MoE FCN (Final Data)): Train Loss: 6.8017, Val Loss: 6.6579, Duration: 66.64s\n",
      "  MoE FCN (Final Data) Val loss improved (6.6604 -> 6.6579).\n",
      "\n",
      "Epoch 11/15 (MoE FCN (Final Data))\n",
      "Epoch 11 Summary (MoE FCN (Final Data)): Train Loss: 6.8518, Val Loss: 5.9108, Duration: 67.55s\n",
      "  MoE FCN (Final Data) Val loss improved (6.6579 -> 5.9108).\n",
      "\n",
      "Epoch 12/15 (MoE FCN (Final Data))\n",
      "Epoch 12 Summary (MoE FCN (Final Data)): Train Loss: 6.5748, Val Loss: 6.2042, Duration: 61.22s\n",
      "\n",
      "Epoch 13/15 (MoE FCN (Final Data))\n",
      "Epoch 13 Summary (MoE FCN (Final Data)): Train Loss: 6.1653, Val Loss: 6.4497, Duration: 54.82s\n",
      "\n",
      "Epoch 14/15 (MoE FCN (Final Data))\n",
      "Epoch 14 Summary (MoE FCN (Final Data)): Train Loss: 5.6773, Val Loss: 4.8861, Duration: 57.41s\n",
      "  MoE FCN (Final Data) Val loss improved (5.9108 -> 4.8861).\n",
      "\n",
      "Epoch 15/15 (MoE FCN (Final Data))\n",
      "Epoch 15 Summary (MoE FCN (Final Data)): Train Loss: 5.8316, Val Loss: 5.3063, Duration: 55.79s\n",
      "\n",
      "MoE FCN (Final Data) Training Finished. Total time: 928.45 seconds\n",
      "\n",
      "--- Final Validation Losses (Log2 MSE) ---\n",
      "MoE FCN (Final Data): 5.3063\n",
      "\n",
      "Plotting losses...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: DataLoaders ('train_loader_final', 'val_loader_final') not found or not created.\n",
      "Please run the 'Data Loading and Preparation' cell successfully first.\n"
     ]
    }
   ],
   "source": [
    "# --- training MoE with hard gating model ---\n",
    "if 'train_loader_final' not in locals() or 'val_loader_final' not in locals() or train_loader is None or val_loader is None:\n",
    "    print(\"ERROR: DataLoaders ('train_loader_final', 'val_loader_final') not found or not created.\")\n",
    "    print(\"Please run the 'Data Loading and Preparation' cell successfully first.\")\n",
    "else:\n",
    "    print(\"DataLoaders found. Proceeding with training...\")\n",
    "\n",
    "    # --- Training Hyperparameters (can be adjusted here before re-running) ---\n",
    "    learning_rate_dense = 0.0005\n",
    "    learning_rate_cnn = 0.0005\n",
    "    learning_rate_moe = 0.0005 # Added LR for MoE\n",
    "    epochs = 30     \n",
    "\n",
    "    # --- Model & Padding Parameters ---\n",
    "    max_k = 6 # Ensure consistency\n",
    "    max_nk = 6 # Ensure consistency\n",
    "    padded_p_matrix_flat_size = max_k * max_nk\n",
    "    params_size = 3\n",
    "\n",
    "    # --- MoE Specific Configuration ---\n",
    "    # Define the unique (n, k) pairs\n",
    "    unique_nk_pairs = sorted([\n",
    "        (9, 4), (9, 5), (9, 6),\n",
    "        (10, 4), (10, 5), (10, 6)\n",
    "    ])\n",
    "    # Configuration for the FCN experts within the MoE\n",
    "    moe_expert_config = {\n",
    "        'p_input_size': padded_p_matrix_flat_size,\n",
    "        'param_input_size': params_size,\n",
    "        'hidden_dims': [512,256,128],\n",
    "        'dropout_prob': 0.3,\n",
    "    }\n",
    "\n",
    "    # --- Device ---\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # --- Dictionary to store results for this run ---\n",
    "    results = {}\n",
    "\n",
    "    # --- Main Training Execution Block ---\n",
    "    try:\n",
    "\n",
    "        # --- Initialize & Train MoE_FCN Model --- # ADDED\n",
    "        print(\"\\n--- Initializing MoE FCN Network (Final Training) ---\")\n",
    "        # Ensure MoE_FCN class is defined correctly\n",
    "        moe_model = MoE_FCN(\n",
    "            unique_nk_pairs=unique_nk_pairs,\n",
    "            expert_config=moe_expert_config,\n",
    "            params_size=params_size\n",
    "        ).to(device)\n",
    "        criterion_moe = LogMSELoss()\n",
    "        optimizer_moe = optim.Adam(moe_model.parameters(), lr=learning_rate_moe) # Use all parameters\n",
    "        print(f\"MoE Model Parameters: {sum(p.numel() for p in moe_model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "        # --- training ---\n",
    "        moe_train_losses, moe_val_losses = run_training(\n",
    "            model=moe_model,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            criterion=criterion_moe,\n",
    "            optimizer=optimizer_moe,\n",
    "            epochs=epochs,\n",
    "            device=device,\n",
    "            model_name=\"MoE FCN (Final Data)\"\n",
    "        )\n",
    "        results[\"MoE FCN (Final Data)\"] = (moe_train_losses, moe_val_losses)\n",
    "\n",
    "    # --- Error Handling ---\n",
    "    except NameError as e:\n",
    "         print(f\"\\nDefinition Error: {e}. Make sure models, loss, or helper functions (run_training, plot_losses, etc.) are defined and executed.\")\n",
    "    except KeyError as e:\n",
    "         print(f\"\\nMoE Routing Error: {e}. An (n, k) pair from the data was not found in the MoE mapping. Check unique_nk_pairs.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred during training/evaluation: {type(e).__name__} - {e}\")\n",
    "        print(\"Traceback:\")\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "\n",
    "    # --- Print Final Validation Losses (Includes MoE) ---\n",
    "    print(\"\\n--- Final Validation Losses (Log2 MSE) ---\")\n",
    "    for model_name, (train_loss_hist, val_loss_hist) in results.items():\n",
    "         if val_loss_hist:\n",
    "             print(f\"{model_name}: {val_loss_hist[-1]:.4f}\")\n",
    "         else:\n",
    "             print(f\"{model_name}: Training did not complete or populate losses.\")\n",
    "\n",
    "\n",
    "    # --- Plot Final Losses (Adjust layout for 3 models) ---\n",
    "    # Ensure plot_losses function can handle the number of models\n",
    "    # If using the provided plot_losses, it should adjust automatically to a 2x2 grid\n",
    "    plot_losses(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define mixture-of-experts (MoE) with soft gating model ---\n",
    "# --- Gating Network ---\n",
    "class GatingNetwork(nn.Module):\n",
    "    \"\"\"Outputs softmax weights for each expert based on n and k.\"\"\"\n",
    "    def __init__(self, input_dim=2, num_experts=4, hidden_dim=16):\n",
    "        super(GatingNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_experts)\n",
    "\n",
    "    def forward(self, n_k_params):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n_k_params (torch.Tensor): Tensor containing normalized n and k. Shape: (batch, 2)\n",
    "        Returns:\n",
    "            torch.Tensor: Softmax weights for experts. Shape: (batch, num_experts)\n",
    "        \"\"\"\n",
    "        x = self.relu(self.fc1(n_k_params))\n",
    "        gate_outputs = self.fc2(x)\n",
    "        gate_weights = F.softmax(gate_outputs, dim=1) # Softmax across experts\n",
    "        return gate_weights\n",
    "\n",
    "# --- Simple Feed-Forward Expert Network ---\n",
    "class Expert(nn.Module):\n",
    "    \"\"\"A simple Feed-Forward Network expert processing flattened P and m.\"\"\"\n",
    "    def __init__(self, input_dim=61, hidden_dims=[128, 64, 32], output_dim=1):\n",
    "        # IMPORTANT: Adjust input_dim based on flattened P (max_k * max_nk) + 1 (for m)\n",
    "        # Example: If max_k=10, max_nk=6 => P_flat=60 => input_dim=61\n",
    "        super(Expert, self).__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, h_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(0.2)) # Optional dropout\n",
    "            prev_dim = h_dim\n",
    "        layers.append(nn.Linear(prev_dim, output_dim))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, p_flat_m):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            p_flat_m (torch.Tensor): Flattened P matrix concatenated with m. Shape: (batch, input_dim)\n",
    "        Returns:\n",
    "            torch.Tensor: Expert's output prediction. Shape: (batch, 1)\n",
    "        \"\"\"\n",
    "        return self.network(p_flat_m)\n",
    "\n",
    "# --- MoE with Soft Gating ---\n",
    "class MoE_FCN_SoftGate(nn.Module):\n",
    "    \"\"\"Mixture of Experts model using a soft gating mechanism.\"\"\"\n",
    "    def __init__(self, num_experts=4, expert_input_dim=61, expert_hidden_dims=[128, 64, 32], gating_input_dim=2, gating_hidden_dim=16, output_dim=1):\n",
    "        super(MoE_FCN_SoftGate, self).__init__()\n",
    "        self.num_experts = num_experts\n",
    "        # Check if expert_input_dim is correctly set (should be max_k * max_nk + 1)\n",
    "        print(f\"Initializing MoE with expert_input_dim = {expert_input_dim}\")\n",
    "        self.gating_network = GatingNetwork(input_dim=gating_input_dim, num_experts=num_experts, hidden_dim=gating_hidden_dim)\n",
    "        self.experts = nn.ModuleList([\n",
    "            Expert(input_dim=expert_input_dim, hidden_dims=expert_hidden_dims, output_dim=output_dim)\n",
    "            for _ in range(num_experts)\n",
    "        ])\n",
    "\n",
    "    def forward(self, p_matrix, params):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            p_matrix (torch.Tensor): Padded P matrix. Shape: (batch, max_k, max_nk)\n",
    "            params (torch.Tensor): Normalized n, k, m values. Shape: (batch, 3)\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Final weighted prediction. Shape: (batch, 1)\n",
    "        \"\"\"\n",
    "        batch_size = p_matrix.size(0)\n",
    "        max_k = p_matrix.size(1)\n",
    "        max_nk = p_matrix.size(2)\n",
    "\n",
    "        # Prepare inputs\n",
    "        n_k_params = params[:, :2] # Extract n and k for gating\n",
    "        # m_param = params[:, 2].unsqueeze(1) # Extract m for experts, shape (batch, 1)\n",
    "        p_flat = p_matrix.view(batch_size, -1) # Flatten P matrix, shape (batch, max_k * max_nk)\n",
    "        \n",
    "        expert_input = torch.cat((p_flat, params), dim=1) # Shape: (batch, max_k * max_nk + 3)\n",
    "\n",
    "        # check expert input dimension based on actual data\n",
    "        expected_expert_input_dim = p_flat.shape[1] + params.shape[1]\n",
    "        # This check assumes the first expert's input dim is representative\n",
    "        actual_expert_input_dim = self.experts[0].network[0].in_features\n",
    "        if expected_expert_input_dim != actual_expert_input_dim:\n",
    "            # This is a critical mismatch, likely requires re-instantiating the model\n",
    "            raise ValueError(f\"Expert input dimension mismatch! Expected {expected_expert_input_dim} based on data (P_flat: {p_flat.shape[1]}, m: {m_param.shape[1]}), but model configured with {actual_expert_input_dim}. Adjust expert_input_dim during MoE_FCN_SoftGate instantiation.\")\n",
    "\n",
    "        # Get gating weights\n",
    "        gate_weights = self.gating_network(n_k_params) # Shape: (batch, num_experts)\n",
    "\n",
    "        # Get outputs from all experts\n",
    "        # Stack expert outputs along a new dimension\n",
    "        expert_outputs_list = [expert(expert_input) for expert in self.experts] # List of tensors, each (batch, 1)\n",
    "        expert_outputs = torch.stack(expert_outputs_list, dim=1) # Shape: (batch, num_experts, 1)\n",
    "\n",
    "        # Weight the expert outputs\n",
    "        # Reshape gate_weights to (batch, num_experts, 1) for broadcasting\n",
    "        gate_weights_reshaped = gate_weights.unsqueeze(-1)\n",
    "\n",
    "        # Weighted sum: (batch, num_experts, 1) * (batch, num_experts, 1) -> sum over experts dimension\n",
    "        final_output = torch.sum(gate_weights_reshaped * expert_outputs, dim=1) # Shape: (batch, 1)\n",
    "\n",
    "        return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training soft gate MoE model ---\n",
    "# --- Calculate Expert Input Dimension ---\n",
    "# Should be size of flattened P matrix (max_k * max_nk) + 3\n",
    "expert_input_dim = (max_k * max_nk) + 3\n",
    "\n",
    "# --- Define Expert Hidden Dimensions (extract from your config or define directly) ---\n",
    "# Assuming moe_expert_config was intended to define these\n",
    "# The Expert class expects a list of hidden dimensions.\n",
    "expert_hidden_dims = moe_expert_config['hidden_dims']\n",
    "\n",
    "# --- Define Gating Network Input Dimension (n, k -> 2 features) ---\n",
    "gating_input_dim = 2\n",
    "\n",
    "# --- Choose Number of Experts ---\n",
    "num_experts = 6 \n",
    "\n",
    "# --- Initialize & Train MoE_FCN Model --- # CORRECTED\n",
    "print(\"\\n--- Initializing MoE FCN Network (Soft Gate - Training) ---\")\n",
    "# Ensure MoE_FCN_SoftGate class is defined correctly in a previous cell\n",
    "moe_model = MoE_FCN_SoftGate(\n",
    "    num_experts=num_experts,              # e.g., 4\n",
    "    expert_input_dim=expert_input_dim,    # e.g., (6*6)+1 = 37\n",
    "    expert_hidden_dims=expert_hidden_dims,# e.g., [128, 64, 32]\n",
    "    gating_input_dim=gating_input_dim,    # Should be 2 (for n, k)\n",
    "    # Optional: Specify gating hidden dim, output dim if different from defaults\n",
    "    # gating_hidden_dim=16, # Default\n",
    "    # output_dim=1          # Default\n",
    ").to(device)\n",
    "\n",
    "criterion_moe = LogMSELoss()\n",
    "optimizer_moe = optim.Adam(moe_model.parameters(), lr=learning_rate_moe)\n",
    "print(f\"MoE Model Parameters: {sum(p.numel() for p in moe_model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "# --- The rest of your training call looks okay ---\n",
    "# Ensure train_epoch_with_params/validate_epoch_with_params pass (p_matrices, params) to model.forward\n",
    "moe_train_losses, moe_val_losses = run_training(\n",
    "    model=moe_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion_moe,\n",
    "    optimizer=optimizer_moe,\n",
    "    epochs=epochs,\n",
    "    device=device,\n",
    "    model_name=\"MoE_FCN_SoftGate\" # Renamed for clarity\n",
    ")\n",
    "results[\"MoE_FCN_SoftGate\"] = (moe_train_losses, moe_val_losses) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Plotting losses...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_losses(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key advantage of soft gating usually lies in how it combines information:    \n",
    "- Smoother Transitions & Knowledge Blending: Instead of abruptly switching experts based on n and k, soft gating allows for a smooth blend. An input might benefit from partial contributions from multiple experts, weighted according to relevance determined by the gating network. This can lead to more robust and generalized predictions.   \n",
    "- Improved Gradient Flow: During training, gradients can flow back through all experts (weighted by the gating outputs and their contribution), allowing all experts to learn potentially useful features even for inputs they aren't the primary \"expert\" for. In hard gating, only the selected expert gets updated for a given sample.    \n",
    "- Learned Routing: The gating network actively learns the best way to combine experts based on n and k, potentially capturing more complex relationships than a fixed hard assignment.  \n",
    "\n",
    "In summary: While it's true that soft gating involves more computation per input (engaging all experts) and has layers in its gating mechanism, the performance improvement is likely due to the more flexible and nuanced way it learns to combine the outputs of its specialized experts, leading to better generalization and potentially smoother learning dynamics. If you also increased the depth of the individual experts compared to your hard-gating model, that would further add to the model's capacity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we initialize the soft-gating Mixture of Experts (MoE) model. Instead of starting from scratch, we load the weights from the best FCN model trained in Step A into each of the MoE's expert networks. This provides a strong starting point. We will then fine-tune the entire MoE model (experts and gating network) on the full dataset, using a lower learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Initialize MoE with Pre-trained Weights & Fine-tune ---\n",
    "# --- Configuration ---\n",
    "pretrained_fcn_weights_path = 'best_fcn_pretrained_weights.pth' # Path to weights from previous step\n",
    "finetune_epochs = 20 # Number of epochs for fine-tuning MoE \n",
    "finetune_lr = 0.0001 # Use a potentially lower LR for fine-tuning\n",
    "max_k = 6\n",
    "max_nk = 6\n",
    "# --- MoE Architecture Parameters (Should match MoE class definitions) ---\n",
    "# Define these based on your MoE_FCN_SoftGate and Expert class structures\n",
    "moe_num_experts = 6\n",
    "moe_expert_input_dim = (max_k * max_nk) + 3 \n",
    "moe_expert_hidden_dims = [512, 256, 128] # MUST match the structure of the saved FCN if loading weights directly!\n",
    "moe_gating_input_dim = 2 # For n, k\n",
    "moe_gating_hidden_dim = 16\n",
    "moe_output_dim = 1\n",
    "\n",
    "# --- Device ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Should be already defined\n",
    "\n",
    "# --- Check Prerequisites ---\n",
    "if not os.path.exists(pretrained_fcn_weights_path):\n",
    "    print(f\"ERROR: Pre-trained FCN weights not found at: {pretrained_fcn_weights_path}\")\n",
    "    print(\"Please ensure Step A was completed and the weights were saved correctly.\")\n",
    "elif 'MoE_FCN_SoftGate' not in globals() or 'Expert' not in globals() or 'GatingNetwork' not in globals():\n",
    "    print(\"ERROR: MoE class definitions (MoE_FCN_SoftGate, Expert, GatingNetwork) not found. Ensure they are defined and executed.\")\n",
    "elif 'train_loader' not in locals() or 'val_loader' not in locals():\n",
    "    print(\"ERROR: train_loader or val_loader not found.\")\n",
    "elif 'LogMSELoss' not in locals():\n",
    "    print(\"ERROR: LogMSELoss class definition not found.\")\n",
    "else:\n",
    "    print(\"\\n--- Step B: Initializing MoE with Pre-trained FCN Weights ---\")\n",
    "\n",
    "    # --- Load the pre-trained state dict from the best FCN ---\n",
    "    # Note: This assumes the 'Expert' network structure within MoE_FCN_SoftGate\n",
    "    #       *exactly* matches the structure of the FlexibleDenseNetworkWithParams\n",
    "    #       whose weights were saved. If they differ, loading will fail or require mapping.\n",
    "    print(f\"Loading pre-trained weights from: {pretrained_fcn_weights_path}\")\n",
    "    pretrained_fcn_state_dict = torch.load(pretrained_fcn_weights_path, map_location=device)\n",
    "\n",
    "    # --- Instantiate the MoE Model ---\n",
    "    print(\"Instantiating MoE_FCN_SoftGate model...\")\n",
    "    moe_finetune_model = MoE_FCN_SoftGate(\n",
    "        num_experts=moe_num_experts,\n",
    "        expert_input_dim=moe_expert_input_dim,\n",
    "        expert_hidden_dims=moe_expert_hidden_dims, # Must match saved FCN structure\n",
    "        gating_input_dim=moe_gating_input_dim,\n",
    "        gating_hidden_dim=moe_gating_hidden_dim,\n",
    "        output_dim=moe_output_dim\n",
    "    ).to(device)\n",
    "\n",
    "    # --- Load weights into each expert ---\n",
    "    num_experts_loaded = 0\n",
    "    total_experts = len(moe_finetune_model.experts)\n",
    "    print(f\"Attempting to load pre-trained FCN weights into {total_experts} experts...\")\n",
    "\n",
    "    # We need to adapt the keys if the saved model was FlexibleDenseNetworkWithParams\n",
    "    # FlexibleDenseNetworkWithParams saves keys starting with 'network.LAYER...'\n",
    "    # The Expert class uses keys starting with 'network.LAYER...'\n",
    "\n",
    "    # Create a state dict mapping for one expert based on the FCN weights\n",
    "    expert_state_dict = {}\n",
    "    fcn_key_prefix = 'network.' # Assuming FlexibleDense... uses this prefix for its Sequential block\n",
    "    expert_key_prefix = 'network.' # Assuming Expert class uses this prefix\n",
    "\n",
    "    keys_matched = 0\n",
    "    for key, value in pretrained_fcn_state_dict.items():\n",
    "        if key.startswith(fcn_key_prefix):\n",
    "            # expert_key = expert_key_prefix + key[len(fcn_key_prefix):] # Keep the same sub-keys\n",
    "            expert_key = key # If both use 'network.' prefix, keys might match directly\n",
    "            expert_state_dict[expert_key] = value\n",
    "            keys_matched += 1\n",
    "        else: # Handle cases where the FCN might have other parameters not in the sequential 'network'\n",
    "            print(f\"  Skipping key '{key}' from pre-trained FCN (not part of 'network').\")\n",
    "\n",
    "    if keys_matched == 0:\n",
    "        print(\"ERROR: No keys starting with 'network.' found in the pre-trained FCN state dict. Cannot map weights to experts.\")\n",
    "        print(\"Pre-trained keys:\", pretrained_fcn_state_dict.keys())\n",
    "    else:\n",
    "        print(f\"  Mapped {keys_matched} parameter keys from FCN state dict to expert structure.\")\n",
    "        load_errors = []\n",
    "        for i, expert in enumerate(moe_finetune_model.experts):\n",
    "            try:\n",
    "                # Load the prepared state dictionary into the current expert\n",
    "                # strict=True ensures all keys in expert_state_dict must match expert keys\n",
    "                missing_keys, unexpected_keys = expert.load_state_dict(expert_state_dict, strict=True)\n",
    "\n",
    "                if not unexpected_keys and not missing_keys:\n",
    "                     num_experts_loaded += 1\n",
    "                else:\n",
    "                     print(f\"  Warning: Loading weights into Expert {i} encountered issues:\")\n",
    "                     if missing_keys: print(f\"Missing keys in Expert {i}: {missing_keys}\")\n",
    "                     if unexpected_keys: print(f\"Unexpected keys in Expert {i} state_dict: {unexpected_keys}\")\n",
    "                     load_errors.append(i)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  ERROR loading weights into Expert {i}: {e}\")\n",
    "                load_errors.append(i)\n",
    "\n",
    "        print(f\"Successfully loaded pre-trained weights into {num_experts_loaded}/{total_experts} experts.\")\n",
    "        if load_errors:\n",
    "             print(f\"Failed to load weights correctly for experts: {load_errors}. Check model structure compatibility.\")\n",
    "\n",
    "\n",
    "    # Proceed only if weights were loaded successfully\n",
    "    if num_experts_loaded == total_experts:\n",
    "        print(\"\\n--- Step C: Fine-tuning the Pre-initialized MoE Model ---\")\n",
    "\n",
    "        # --- Setup Optimizer and Criterion for Fine-tuning ---\n",
    "        optimizer_moe_finetune = optim.Adam(moe_finetune_model.parameters(), lr=finetune_lr, weight_decay = 1e-5)\n",
    "        criterion_moe_finetune = LogMSELoss()\n",
    "\n",
    "        # --- Run Fine-tuning Training ---\n",
    "        # Option 1: Use run_training function (ensure it saves the best model)\n",
    "        if 'run_training' in globals():\n",
    "            print(f\"Starting fine-tuning using 'run_training' for {finetune_epochs} epochs with LR={finetune_lr}...\")\n",
    "            moe_finetune_train_losses, moe_finetune_val_losses = run_training(\n",
    "                model=moe_finetune_model,\n",
    "                train_loader=train_loader,\n",
    "                val_loader=val_loader,\n",
    "                criterion=criterion_moe_finetune,\n",
    "                optimizer=optimizer_moe_finetune,\n",
    "                epochs=finetune_epochs,\n",
    "                device=device,\n",
    "                model_name=\"MoE_Finetuned\"\n",
    "            )\n",
    "             # Optional: Plot results if run_training doesn't plot\n",
    "             # plot_losses({\"MoE Finetuned\": (moe_finetune_train_losses, moe_finetune_val_losses)})\n",
    "\n",
    "        # Option 2: Use manual loop if run_training isn't suitable or available\n",
    "        elif 'train_epoch_with_params' in globals() and 'validate_epoch_with_params' in globals():\n",
    "            print(f\"Starting fine-tuning using manual loop for {finetune_epochs} epochs with LR={finetune_lr}...\")\n",
    "            best_finetune_val_loss = float('inf')\n",
    "            moe_finetune_train_losses = []\n",
    "            moe_finetune_val_losses = []\n",
    "            finetune_start_time = time.time()\n",
    "            finetune_save_path = f'best_moe_{moe_num_experts}experts_finetuned_weights.pth'\n",
    "\n",
    "            for epoch in range(finetune_epochs):\n",
    "                epoch_start_time = time.time()\n",
    "                train_loss = train_epoch_with_params(moe_finetune_model, train_loader, criterion_moe_finetune, optimizer_moe_finetune, device)\n",
    "                val_loss = validate_epoch_with_params(moe_finetune_model, val_loader, criterion_moe_finetune, device)\n",
    "                epoch_duration = time.time() - epoch_start_time\n",
    "\n",
    "                moe_finetune_train_losses.append(train_loss)\n",
    "                moe_finetune_val_losses.append(val_loss)\n",
    "\n",
    "                print(f\"Epoch {epoch+1}/{finetune_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Time: {epoch_duration:.2f}s\")\n",
    "\n",
    "                # Save the model if validation loss improves\n",
    "                if val_loss < best_finetune_val_loss:\n",
    "                    best_finetune_val_loss = val_loss\n",
    "                    torch.save(moe_finetune_model.state_dict(), finetune_save_path)\n",
    "                    print(f\"  -> Val loss improved to {best_finetune_val_loss:.4f}. Model weights saved to {finetune_save_path}\")\n",
    "\n",
    "            total_time_finetune = time.time() - finetune_start_time\n",
    "            print(f\"\\nMoE Fine-tuning Finished. Total time: {total_time_finetune:.2f} seconds\")\n",
    "            print(f\"Best Validation Loss achieved: {best_finetune_val_loss:.4f}\")\n",
    "            print(f\"Best fine-tuned MoE model weights saved to: {finetune_save_path}\")\n",
    "\n",
    "            # --- Plot Final Training Curve ---\n",
    "            if moe_finetune_train_losses and moe_finetune_val_losses:\n",
    "                 try:\n",
    "                      plt.figure(figsize=(10, 5))\n",
    "                      plt.plot(moe_finetune_train_losses, label='MoE Fine-tune Train Loss')\n",
    "                      plt.plot(moe_finetune_val_losses, label=f'MoE Fine-tune Val Loss (Best: {best_finetune_val_loss:.4f})')\n",
    "                      best_epoch_idx = np.argmin(moe_finetune_val_losses)\n",
    "                      plt.scatter([best_epoch_idx], [best_finetune_val_loss], color='red', s=50, zorder=5, label=f'Best Val @ Epoch {best_epoch_idx+1}')\n",
    "\n",
    "                      plt.title(f'Fine-tuning Pre-Initialized MoE (LR={finetune_lr})')\n",
    "                      plt.xlabel('Epoch')\n",
    "                      plt.ylabel('Log2 MSE Loss')\n",
    "                      plt.legend()\n",
    "                      plt.grid(True)\n",
    "                      plt.show()\n",
    "                 except Exception as plot_err:\n",
    "                      print(f\"\\nWarning: Plotting fine-tune curve failed - {plot_err}\")\n",
    "\n",
    "        else:\n",
    "             print(\"ERROR: Cannot run fine-tuning - suitable training functions not found.\")\n",
    "\n",
    "    else:\n",
    "        print(\"\\nSkipping Step (Fine-tuning) due to errors loading pre-trained weights into experts.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this technique, we go from 1.37 loss on the validation set to 1.344 loss. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FINAL TEST CELL : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of the project so far :   \n",
    "- 1st step of the project: generated data using PuLP and HPRC :   \n",
    " generated 10 000 data so far with 128 CPU but couldn't generate more due to heavy computational in particularly with bigger m.   That why, I decided to use Keegan Smith student's data. I took 420,000 data from his 1 million data and I splitted at the end in a 80/20 ratio for training and validations set.   \n",
    " \n",
    "- 2nd step:  \n",
    " it was to load all the data and preprocess it for the model using the class \"PickleFolderDataset\" to load the data from pkl files.    \n",
    " \n",
    "- 3rd step: train the model using MSE loss function on the log2 scale:     \n",
    "for this part, I decompose in multiple step:  \n",
    "    - step A: testing different basic architecture (Fully connected Network (FCN/dense layer), CNN, RNN with LSTM and GRU) on small dataset\n",
    "    - step B: test the two best architecture one the big dataset : FCN turns out to be the one\n",
    "    - step C: fine tune FCN architecture and fine-tune hyperparameters\n",
    "    - step D: test MoE architecture with hard and soft gate with dense layer : soft gates gives better results.  \n",
    "    - step E: use the weight of the best FCN model to initial the weight of the each expert of MoE with soft gates function\n",
    "    - step F: fine tune the hyperparameters to get the best models possible. \n",
    "\n",
    "Finally, you can run the final evaluation cell either by loading the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tamu_csce_636_project1 in c:\\users\\theo-\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.0.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Users\\theo-\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Users\\theo-\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Users\\theo-\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Users\\theo-\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\theo-\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tamu_csce_636_project1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Evaluator initialized successfully.\n",
      "\n",
      "--- Running Evaluator ---\n",
      "Loading model for prediction...\n",
      "Initialized GatingNetwork: input_dim=2, num_experts=6, hidden_dim=16\n",
      "Initialized Expert: input_dim=39, hidden_dims=[512, 256, 128], output_dim=1\n",
      "Initialized Expert: input_dim=39, hidden_dims=[512, 256, 128], output_dim=1\n",
      "Initialized Expert: input_dim=39, hidden_dims=[512, 256, 128], output_dim=1\n",
      "Initialized Expert: input_dim=39, hidden_dims=[512, 256, 128], output_dim=1\n",
      "Initialized Expert: input_dim=39, hidden_dims=[512, 256, 128], output_dim=1\n",
      "Initialized Expert: input_dim=39, hidden_dims=[512, 256, 128], output_dim=1\n",
      "Initialized MoE_FCN_SoftGate: num_experts=6\n",
      "Model loaded successfully for prediction.\n",
      "σ = {\n",
      "    # n, k, m\n",
      "    (5, 2, 2): 57.28731422441739,\n",
      "}\n",
      "\n",
      "Evaluator Results (sigma):\n",
      "{(5, 2, 2): 57.28731422441739}\n",
      "\n",
      "--- Evaluating on Small Test Dataset: ./split_data_small_test ---\n",
      "Loading data from 21 specified pickle files (expecting DataFrames)...\n",
      "Finished initial loading. Total samples found: 210\n",
      "Loaded 210 test samples.\n",
      "Reusing already loaded model for testing.\n",
      "\n",
      "Average LogMSELoss on './split_data_small_test': 1.523048\n",
      "\n",
      "--- Cell Execution Finished ---\n"
     ]
    }
   ],
   "source": [
    "# --- Final cell for Evaluation and Testing ---\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import traceback\n",
    "from collections import defaultdict\n",
    "from tamu_csce_636_project1 import Evaluator\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# --- Constants ---\n",
    "max_k_padded = 6  # Max height for padding P\n",
    "max_nk_padded = 6 # Max width for padding P\n",
    "model_path = \"best_moe_finetuned_final.pth\"\n",
    "test_data_folder = './split_data_small_test'\n",
    "params_size = 3 # n, k, m\n",
    "p_flat_size = max_k_padded * max_nk_padded # 36\n",
    "expert_input_dim = p_flat_size + params_size # 39\n",
    "gating_input_dim = 2 # Only n, k for gating\n",
    "num_experts = 6 # Should match the trained model\n",
    "expert_hidden_dims = [512, 256, 128] # Should match the trained model\n",
    "gating_hidden_dim = 16 # Should match the trained model\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- Evaluator Setup ---\n",
    "try:\n",
    "    evaluator = Evaluator(\n",
    "        first_name=\"Theo\",\n",
    "        last_name=\"Lin\",\n",
    "        email=\"theo.lin@tamu.edu\",\n",
    "        print=True\n",
    "    )\n",
    "    print(\"Evaluator initialized successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing Evaluator: {e}\")\n",
    "    evaluator = None # Set to None if initialization fails\n",
    "\n",
    "# --- Dataset Class Definition (Copied from your selection) ---\n",
    "class PickleFolderDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for loading data from a **list of .pkl file paths**.\n",
    "\n",
    "    Assumes each .pkl file contains a Pandas DataFrame with columns\n",
    "    'n', 'k', 'm', 'result', 'P'.\n",
    "    Handles cases where 'P' might be a 2D array OR a flattened 1D array.\n",
    "    Reshapes 1D 'P' arrays to 2D using 'n' and 'k' before padding.\n",
    "    Handles padding P_matrices.\n",
    "    Returns data as (params, h, P).\n",
    "    \"\"\"\n",
    "    def __init__(self, file_paths, max_k=6, max_nk=6):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            file_paths (list[str]): A list of full paths to the .pkl files.\n",
    "            max_k (int): The height to pad P matrices to.\n",
    "            max_nk (int): The width to pad P matrices to.\n",
    "        \"\"\"\n",
    "        self.file_paths = file_paths # it is a list\n",
    "        self.max_k = max_k\n",
    "        self.max_nk = max_nk\n",
    "\n",
    "        if not self.file_paths:\n",
    "            raise ValueError(\"The provided file_paths list is empty.\")\n",
    "\n",
    "        # Store data directly as loaded from pickle (P can be 1D or 2D)\n",
    "        self.all_p_matrices = [] # Can contain mixed ndim arrays initially\n",
    "        self.all_h_values = []\n",
    "        # Store n, k, m as simple Python ints initially for reshaping logic\n",
    "        self.all_n = []\n",
    "        self.all_k = []\n",
    "        self.all_m = []\n",
    "\n",
    "        print(f\"Loading data from {len(self.file_paths)} specified pickle files (expecting DataFrames)...\")\n",
    "        required_columns = ['n', 'k', 'm', 'result', 'P']\n",
    "\n",
    "        for file_path in self.file_paths: # Iterate through the provided list\n",
    "            # print(f\"  Loading: {os.path.basename(file_path)}\") # Keep print concise\n",
    "            try:\n",
    "                # Ensure pickle is imported before using it\n",
    "                import pickle\n",
    "                with open(file_path, 'rb') as f:\n",
    "                    data_df = pickle.load(f)\n",
    "\n",
    "                    if not isinstance(data_df, pd.DataFrame):\n",
    "                        print(f\"Warning: Skipping {os.path.basename(file_path)} - Expected a Pandas DataFrame, found {type(data_df)}.\")\n",
    "                        continue\n",
    "                    if not all(col in data_df.columns for col in required_columns):\n",
    "                        print(f\"Warning: Skipping {os.path.basename(file_path)} - Missing required columns ({required_columns}). Found: {list(data_df.columns)}\")\n",
    "                        continue\n",
    "\n",
    "                    # Use efficient Pandas column access\n",
    "                    p_matrices_list = data_df['P'].tolist()\n",
    "                    h_values_list = data_df['result'].astype(float).tolist()\n",
    "                    n_vals_list = data_df['n'].astype(int).tolist()\n",
    "                    k_vals_list = data_df['k'].astype(int).tolist()\n",
    "                    m_vals_list = data_df['m'].astype(int).tolist()\n",
    "\n",
    "                    # Optional: Basic validation before extending\n",
    "                    list_len = len(p_matrices_list)\n",
    "                    if not (list_len == len(h_values_list) == len(n_vals_list) == len(k_vals_list) == len(m_vals_list)):\n",
    "                            print(f\"Warning: Skipping {os.path.basename(file_path)} due to inconsistent column lengths after tolist().\")\n",
    "                            continue\n",
    "\n",
    "                    # Extend lists\n",
    "                    self.all_p_matrices.extend([np.array(p) for p in p_matrices_list]) # Ensure numpy\n",
    "                    self.all_h_values.extend(h_values_list)\n",
    "                    self.all_n.extend(n_vals_list) # Keep as int\n",
    "                    self.all_k.extend(k_vals_list) # Keep as int\n",
    "                    self.all_m.extend(m_vals_list) # Keep as int\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                    print(f\"Error: File not found {file_path}. Skipping.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading/processing {file_path}: {type(e).__name__} - {e}. Skipping file.\")\n",
    "                # print(traceback.format_exc()) # Uncomment for more detail\n",
    "\n",
    "        if not self.all_h_values:\n",
    "                raise ValueError(\"No valid data loaded from any pickle files.\")\n",
    "\n",
    "        print(f\"Finished initial loading. Total samples found: {len(self.all_h_values)}\")\n",
    "\n",
    "        # --- Convert non-P lists to tensors ---\n",
    "        self.all_h_values_tensor = torch.tensor(self.all_h_values, dtype=torch.float32)\n",
    "        self.all_n_tensor = torch.tensor(self.all_n, dtype=torch.float32)\n",
    "        self.all_k_tensor = torch.tensor(self.all_k, dtype=torch.float32)\n",
    "        self.all_m_tensor = torch.tensor(self.all_m, dtype=torch.float32)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_h_values_tensor)\n",
    "\n",
    "    def _pad_matrix(self, p_matrix_2d):\n",
    "        if not isinstance(p_matrix_2d, np.ndarray) or p_matrix_2d.ndim != 2:\n",
    "            raise ValueError(f\"Input to _pad_matrix must be a 2D NumPy array, but got type {type(p_matrix_2d)} with shape {getattr(p_matrix_2d, 'shape', 'N/A')}\")\n",
    "        p_tensor = torch.tensor(p_matrix_2d, dtype=torch.float32)\n",
    "        k_actual, nk_actual = p_tensor.shape\n",
    "        pad_k = self.max_k - k_actual\n",
    "        pad_nk = self.max_nk - nk_actual\n",
    "        if pad_k < 0 or pad_nk < 0:\n",
    "                raise ValueError(f\"Matrix shape ({k_actual},{nk_actual}) exceeds target padding ({self.max_k},{self.max_nk}).\")\n",
    "        # Padding format: (pad_left, pad_right, pad_top, pad_bottom)\n",
    "        padding = (0, pad_nk, 0, pad_k)\n",
    "        padded_p = F.pad(p_tensor, padding, \"constant\", 0)\n",
    "        return padded_p\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx): idx = idx.tolist()\n",
    "\n",
    "        p_matrix_np = self.all_p_matrices[idx]\n",
    "        h_value = self.all_h_values_tensor[idx]\n",
    "        n_val = self.all_n[idx] # Get int value\n",
    "        k_val = self.all_k[idx] # Get int value\n",
    "\n",
    "        p_matrix_2d = None\n",
    "\n",
    "        # --- Reshape if necessary ---\n",
    "        if p_matrix_np.ndim == 1:\n",
    "            try:\n",
    "                # Calculate target shape based on n and k ints\n",
    "                target_rows = k_val\n",
    "                target_cols = n_val - k_val\n",
    "                if target_rows < 0 or target_cols < 0: # k can be 0 if n=1, but cols should be >= 0\n",
    "                     raise ValueError(f\"Invalid target shape derived: k={target_rows}, n-k={target_cols} from n={n_val}, k={k_val}\")\n",
    "\n",
    "                expected_len = target_rows * target_cols\n",
    "\n",
    "                # Handle edge case: k=n -> P is empty (0 elements)\n",
    "                if p_matrix_np.size == 0 and expected_len == 0:\n",
    "                    # Create an empty 2D array with correct dimensions (k rows, 0 cols)\n",
    "                    p_matrix_2d = np.empty((target_rows, target_cols), dtype=p_matrix_np.dtype)\n",
    "                elif p_matrix_np.size != expected_len:\n",
    "                    raise ValueError(f\"Flattened P length ({p_matrix_np.size}) != k*(n-k) ({expected_len}) for n={n_val}, k={k_val}\")\n",
    "                else:\n",
    "                    # Reshape only if the size matches the expected length\n",
    "                    p_matrix_2d = p_matrix_np.reshape((target_rows, target_cols))\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"ERROR in __getitem__ (idx={idx}): Failed to reshape P with shape {p_matrix_np.shape} using n={n_val}, k={k_val}. Error: {e}\")\n",
    "                # Depending on severity, you might want to return None or skip this sample\n",
    "                raise RuntimeError(f\"Data Error: Failed processing P matrix for sample index {idx}.\") from e\n",
    "        elif p_matrix_np.ndim == 2:\n",
    "            p_matrix_2d = p_matrix_np\n",
    "        else:\n",
    "            # This case should ideally not happen if data generation is correct\n",
    "            raise ValueError(f\"ERROR in __getitem__ (idx={idx}): P matrix has unexpected shape {p_matrix_np.shape}.\")\n",
    "        # --- End Reshape ---\n",
    "\n",
    "        # Pad the (now guaranteed 2D) matrix\n",
    "        try:\n",
    "            padded_p = self._pad_matrix(p_matrix_2d)\n",
    "        except ValueError as e:\n",
    "            print(f\"ERROR in __getitem__ (idx={idx}): Failed to pad P matrix derived from shape {p_matrix_np.shape} (n={n_val}, k={k_val}). Error: {e}\")\n",
    "            raise RuntimeError(f\"Data Error: Failed padding P matrix for sample index {idx}.\") from e\n",
    "\n",
    "\n",
    "        # Use the tensor versions of n, k, m for stacking\n",
    "        params = torch.stack([self.all_n_tensor[idx], self.all_k_tensor[idx], self.all_m_tensor[idx]])\n",
    "        h = h_value.unsqueeze(0) # Ensure h has shape [1]\n",
    "        return params, h, padded_p\n",
    "\n",
    "# --- Model Class Definitions (Copied from your selection) ---\n",
    "class GatingNetwork(nn.Module):\n",
    "    def __init__(self, input_dim=2, num_experts=4, hidden_dim=16):\n",
    "        super(GatingNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_experts)\n",
    "        print(f\"Initialized GatingNetwork: input_dim={input_dim}, num_experts={num_experts}, hidden_dim={hidden_dim}\")\n",
    "\n",
    "\n",
    "    def forward(self, n_k_params):\n",
    "        x = self.relu(self.fc1(n_k_params.float()))\n",
    "        gate_outputs = self.fc2(x)\n",
    "        gate_weights = F.softmax(gate_outputs, dim=1)\n",
    "        return gate_weights\n",
    "\n",
    "class Expert(nn.Module):\n",
    "    def __init__(self, input_dim=39, hidden_dims=[512, 256, 128], output_dim=1):\n",
    "        super(Expert, self).__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, h_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(0.2)) \n",
    "            prev_dim = h_dim\n",
    "        layers.append(nn.Linear(prev_dim, output_dim))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        print(f\"Initialized Expert: input_dim={input_dim}, hidden_dims={hidden_dims}, output_dim={output_dim}\")\n",
    "\n",
    "\n",
    "    def forward(self, p_flat_params):\n",
    "        return self.network(p_flat_params.float())\n",
    "\n",
    "class MoE_FCN_SoftGate(nn.Module):\n",
    "    def __init__(self, num_experts=6, expert_input_dim=39, expert_hidden_dims=[512, 256, 128], gating_input_dim=2, gating_hidden_dim=16, output_dim=1):\n",
    "        super(MoE_FCN_SoftGate, self).__init__()\n",
    "        self.num_experts = num_experts\n",
    "        # Initialize sub-modules\n",
    "        self.gating_network = GatingNetwork(input_dim=gating_input_dim, num_experts=num_experts, hidden_dim=gating_hidden_dim)\n",
    "        self.experts = nn.ModuleList([\n",
    "            Expert(input_dim=expert_input_dim, hidden_dims=expert_hidden_dims, output_dim=output_dim)\n",
    "            for _ in range(num_experts)\n",
    "        ])\n",
    "        print(f\"Initialized MoE_FCN_SoftGate: num_experts={num_experts}\")\n",
    "\n",
    "\n",
    "    def forward(self, p_matrix, params):\n",
    "        # Input type and shape validation/casting\n",
    "        batch_size = p_matrix.size(0)\n",
    "        p_matrix = p_matrix.float().to(params.device) # Ensure float and same device\n",
    "        params = params.float()\n",
    "\n",
    "        # Prepare inputs for gating and experts\n",
    "        n_k_params = params[:, :2] # First two elements (n, k) for gating\n",
    "        p_flat = p_matrix.view(batch_size, -1)\n",
    "        expert_input = torch.cat((p_flat, params), dim=1)\n",
    "\n",
    "        # Dynamic dimension check (optional but good practice)\n",
    "        expected_expert_input_dim = p_flat.shape[1] + params.shape[1]\n",
    "        # Accessing internal layer requires care, assuming Expert structure is stable\n",
    "        actual_expert_input_dim = self.experts[0].network[0].in_features\n",
    "        if expected_expert_input_dim != actual_expert_input_dim:\n",
    "            raise ValueError(f\"Expert input dimension mismatch! Expected {expected_expert_input_dim}, but model configured with {actual_expert_input_dim}\")\n",
    "\n",
    "        # Get gating weights and expert outputs\n",
    "        gate_weights = self.gating_network(n_k_params)\n",
    "        expert_outputs_list = [expert(expert_input) for expert in self.experts]\n",
    "\n",
    "        # Stack expert outputs along a new dimension (batch_size, num_experts, output_dim)\n",
    "        expert_outputs = torch.stack(expert_outputs_list, dim=1)\n",
    "\n",
    "        # Reshape gate_weights for broadcasting (batch_size, num_experts, 1)\n",
    "        gate_weights_reshaped = gate_weights.unsqueeze(-1)\n",
    "\n",
    "        # Weighted sum of expert outputs\n",
    "        # Broadcasting: (batch_size, num_experts, 1) * (batch_size, num_experts, output_dim)\n",
    "        # Result before sum: (batch_size, num_experts, output_dim)\n",
    "        # Sum along dim=1 (experts): (batch_size, output_dim)\n",
    "        final_output = torch.sum(gate_weights_reshaped * expert_outputs, dim=1)\n",
    "\n",
    "        return final_output\n",
    "\n",
    "class LogMSELoss(nn.Module):\n",
    "    def __init__(self, eps=1e-9):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        # Ensure inputs are tensors and on the same device\n",
    "        y_pred = torch.as_tensor(y_pred, device=y_true.device)\n",
    "\n",
    "        # Clamp inputs to be positive before log2\n",
    "        y_pred_safe = torch.clamp(y_pred, min=self.eps)\n",
    "        y_true_safe = torch.clamp(y_true, min=self.eps)\n",
    "\n",
    "        # Calculate log base 2\n",
    "        log2_pred = torch.log2(y_pred_safe)\n",
    "        log2_true = torch.log2(y_true_safe)\n",
    "\n",
    "        # Calculate the squared difference and mean over the batch\n",
    "        loss = torch.mean((log2_true - log2_pred) ** 2)\n",
    "        return loss\n",
    "\n",
    "\n",
    "# --- Helper: Padding Function (Standalone for prediction function) ---\n",
    "def _pad_matrix_pred(p_matrix_2d, max_k, max_nk):\n",
    "    if not isinstance(p_matrix_2d, np.ndarray) or p_matrix_2d.ndim != 2:\n",
    "        raise ValueError(f\"Input must be a 2D NumPy array, got type {type(p_matrix_2d)} with shape {getattr(p_matrix_2d, 'shape', 'N/A')}\")\n",
    "    p_tensor = torch.tensor(p_matrix_2d, dtype=torch.float32)\n",
    "    k_actual, nk_actual = p_tensor.shape\n",
    "    pad_k = max_k - k_actual\n",
    "    pad_nk = max_nk - nk_actual\n",
    "    if pad_k < 0 or pad_nk < 0:\n",
    "        raise ValueError(f\"Matrix shape ({k_actual},{nk_actual}) exceeds target padding ({max_k},{max_nk}).\")\n",
    "    padding = (0, pad_nk, 0, pad_k) # Pad right, bottom\n",
    "    padded_p = F.pad(p_tensor, padding, \"constant\", 0)\n",
    "    return padded_p\n",
    "\n",
    "# --- Prediction Function for Evaluator ---\n",
    "# Global model variable to load only once\n",
    "loaded_model_for_pred = None\n",
    "\n",
    "def predicted_m_height(n, k, m, p_list):\n",
    "    \"\"\"\n",
    "    Predicts m-height for a list of P matrices using the loaded MoE model.\n",
    "\n",
    "    Parameters:\n",
    "        n (int)\n",
    "        k (int)\n",
    "        m (int)\n",
    "        p_list (list): a list of P matrices, each matrix will be a numpy array\n",
    "\n",
    "    Returns:\n",
    "        a list of scalars, e.g. the m-height value, one for each matrix\n",
    "    \"\"\"\n",
    "    global loaded_model_for_pred, device, max_k_padded, max_nk_padded, model_path\n",
    "    global num_experts, expert_input_dim, expert_hidden_dims, gating_input_dim, gating_hidden_dim\n",
    "\n",
    "    # --- Load Model (only once) ---\n",
    "    if loaded_model_for_pred is None:\n",
    "        print(\"Loading model for prediction...\")\n",
    "        try:\n",
    "            loaded_model_for_pred = MoE_FCN_SoftGate(\n",
    "                num_experts=num_experts,\n",
    "                expert_input_dim=expert_input_dim,\n",
    "                expert_hidden_dims=expert_hidden_dims,\n",
    "                gating_input_dim=gating_input_dim,\n",
    "                gating_hidden_dim=gating_hidden_dim\n",
    "            )\n",
    "            # Load state dict, mapping to the correct device\n",
    "            state_dict = torch.load(model_path, map_location=device)\n",
    "            loaded_model_for_pred.load_state_dict(state_dict)\n",
    "            loaded_model_for_pred.to(device)\n",
    "            loaded_model_for_pred.eval() # Set to evaluation mode\n",
    "            print(\"Model loaded successfully for prediction.\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"\\nERROR: Model file not found at {model_path}\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            print(f\"\\nERROR loading model: {e}\")\n",
    "            raise\n",
    "\n",
    "    # --- Process Inputs ---\n",
    "    predictions = []\n",
    "    with torch.no_grad(): # Disable gradient calculations for inference\n",
    "        for p_matrix_np in p_list:\n",
    "            try:\n",
    "                # Ensure p_matrix is a numpy array\n",
    "                if not isinstance(p_matrix_np, np.ndarray):\n",
    "                    p_matrix_np = np.array(p_matrix_np)\n",
    "\n",
    "                p_matrix_2d = None\n",
    "                # --- Reshape if necessary ---\n",
    "                if p_matrix_np.ndim == 1:\n",
    "                     target_rows = k\n",
    "                     target_cols = n - k\n",
    "                     if target_rows < 0 or target_cols < 0:\n",
    "                         raise ValueError(f\"Invalid target shape: k={target_rows}, n-k={target_cols} from n={n}, k={k}\")\n",
    "                     expected_len = target_rows * target_cols\n",
    "                     if p_matrix_np.size == 0 and expected_len == 0:\n",
    "                         p_matrix_2d = np.empty((target_rows, target_cols), dtype=p_matrix_np.dtype)\n",
    "                     elif p_matrix_np.size != expected_len:\n",
    "                         raise ValueError(f\"Flattened P length ({p_matrix_np.size}) != k*(n-k) ({expected_len}) for n={n}, k={k}\")\n",
    "                     else:\n",
    "                         p_matrix_2d = p_matrix_np.reshape((target_rows, target_cols))\n",
    "                elif p_matrix_np.ndim == 2:\n",
    "                     p_matrix_2d = p_matrix_np\n",
    "                else:\n",
    "                     raise ValueError(f\"P matrix has unexpected shape {p_matrix_np.shape}.\")\n",
    "                # --- End Reshape ---\n",
    "\n",
    "                # Pad the matrix\n",
    "                padded_p = _pad_matrix_pred(p_matrix_2d, max_k_padded, max_nk_padded)\n",
    "\n",
    "                # Prepare tensors for the model\n",
    "                # Add batch dimension (batch size = 1)\n",
    "                padded_p_tensor = padded_p.unsqueeze(0).to(device)\n",
    "                params_tensor = torch.tensor([[n, k, m]], dtype=torch.float32).to(device)\n",
    "\n",
    "                # --- Predict ---\n",
    "                output = loaded_model_for_pred(padded_p_tensor, params_tensor)\n",
    "                predictions.append(output.item()) # Get scalar value\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"ERROR predicting for one P matrix (n={n}, k={k}, m={m}): {e}\")\n",
    "                # Decide how to handle errors: append None, 0, or raise?\n",
    "                # Appending None might cause issues with the evaluator if it expects numbers.\n",
    "                # Let's append a placeholder like 0 or NaN and print a warning.\n",
    "                predictions.append(0.0) # Append 0.0 as a placeholder for failed predictions\n",
    "                # Or use float('nan') if appropriate: predictions.append(float('nan'))\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# --- Run Evaluator ---\n",
    "if evaluator:\n",
    "    print(\"\\n--- Running Evaluator ---\")\n",
    "    try:\n",
    "        sigma = evaluator.eval(func=predicted_m_height)\n",
    "        if sigma:\n",
    "            print(\"\\nEvaluator Results (sigma):\")\n",
    "            print(dict(sigma))\n",
    "        else:\n",
    "            print(\"Evaluator returned no results (potentially due to errors in predicted_m_height).\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during evaluator.eval(): {e}\")\n",
    "        print(traceback.format_exc())\n",
    "else:\n",
    "    print(\"\\nEvaluator not initialized. Skipping evaluator.eval().\")\n",
    "\n",
    "\n",
    "# --- Evaluate on Small Test Dataset ---\n",
    "print(f\"\\n--- Evaluating on Small Test Dataset: {test_data_folder} ---\")\n",
    "try:\n",
    "    # --- Load Test Data ---\n",
    "    test_files = glob.glob(os.path.join(test_data_folder, '*.pkl'))\n",
    "    if not test_files:\n",
    "        raise FileNotFoundError(f\"No .pkl files found in the test folder: {test_data_folder}\")\n",
    "\n",
    "    test_dataset = PickleFolderDataset(file_paths=test_files, max_k=max_k_padded, max_nk=max_nk_padded)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False) # Use a reasonable batch size\n",
    "    print(f\"Loaded {len(test_dataset)} test samples.\")\n",
    "\n",
    "    # --- Load Model (or reuse if already loaded) ---\n",
    "    if loaded_model_for_pred is None:\n",
    "        print(\"Loading model for testing...\")\n",
    "        test_model = MoE_FCN_SoftGate(\n",
    "            num_experts=num_experts,\n",
    "            expert_input_dim=expert_input_dim,\n",
    "            expert_hidden_dims=expert_hidden_dims,\n",
    "            gating_input_dim=gating_input_dim,\n",
    "            gating_hidden_dim=gating_hidden_dim\n",
    "        )\n",
    "        state_dict = torch.load(model_path, map_location=device)\n",
    "        test_model.load_state_dict(state_dict)\n",
    "        test_model.to(device)\n",
    "        print(\"Model loaded successfully for testing.\")\n",
    "    else:\n",
    "        print(\"Reusing already loaded model for testing.\")\n",
    "        test_model = loaded_model_for_pred # Reuse the globally loaded model\n",
    "\n",
    "    test_model.eval() # Ensure evaluation mode\n",
    "\n",
    "    # --- Calculate Loss ---\n",
    "    criterion = LogMSELoss()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for params, targets, p_matrices in test_loader:\n",
    "            params, targets, p_matrices = params.to(device), targets.to(device), p_matrices.to(device)\n",
    "\n",
    "            outputs = test_model(p_matrices, params)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            total_loss += loss.item() * params.size(0) # Accumulate loss correctly\n",
    "            total_samples += params.size(0)\n",
    "\n",
    "    if total_samples > 0:\n",
    "        average_loss = total_loss / total_samples\n",
    "        print(f\"\\nAverage LogMSELoss on '{test_data_folder}': {average_loss:.6f}\")\n",
    "    else:\n",
    "        print(\"\\nNo samples processed from the test dataset.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\nERROR loading test data: {e}\")\n",
    "except ValueError as e:\n",
    "     print(f\"\\nERROR processing test data: {e}\")\n",
    "except NameError as e:\n",
    "     print(f\"\\nDefinition Error: {e}. Make sure classes/functions are defined.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn unexpected error occurred during test set evaluation: {type(e).__name__} - {e}\")\n",
    "    print(traceback.format_exc())\n",
    "\n",
    "print(\"\\n--- Cell Execution Finished ---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have a higher loss values (1.54) compared to what we have with validation set with a loss value of 1.34"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch-env)",
   "language": "python",
   "name": "torch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
